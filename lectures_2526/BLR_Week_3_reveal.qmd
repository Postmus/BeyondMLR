---
title: "Beyond MLR - Week 3"
subtitle: "Cluter randomization and multi-level analysis of cross-sectional obervational data"
author: "Dr. Douwe Postmus"
format:
  revealjs:
    theme: [default, custom-reveal.scss]
    slide-number: true
    toc: false
    slide-level: 2
    incremental: false
    code-overflow: wrap
    scrollable: true
    smaller: true
    width: 1280
    height: 720
    margin: 0.06
    max-scale: 2
    footer: "Beyond multiple linear regression - week 3"
    logo: UMCG-logo.png
execute:
  warning: false
  message: false
  eval: true
  echo: false
---

```{r}
#| include: false
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(knitr, rmarkdown, dplyr, ggplot2, emmeans, lme4, lmerTest, broom.mixed, gridExtra)
```

## What did we learn in previous weeks - part 1

- Grouped data arise when units of analysis share common conditions defined by one or more context variables
  - Because of this shared context, units from the same group tend to be positively correlated
  - The extent of this correlation is quantified by the ICC

 - Two-level hierarchical data
   - Randomized block design: experimental units (level 1) nested in blocks (level 2)
   - Ignoring blocks (using OLS) yields unbiased treatment estimates but is inefficient because block-to-block variation is absorbed into the residual error, inflating the residual variance and lowering power 
   - The higher the ICC, the larger the loss in power

::: {.callout-warning icon=false title="Student question related to the week 2 assignment"}
Why would you use the ICC to assess the attribution of random effects to the variance? Why not also include the variation explained by the fixed effect to the total variation instead (like a R-squared for the random effects?)
:::

## Unconditional variance, conditional variance, and explained variance

- Unconditional variance: the variability of the outcome without conditioning on any covariates (i.e., the raw variance of the outcome variable)
- Conditional variance: the variability of the outcome after conditioning on covariates in a regression model (i.e. variability among units with identical covariate values)
- Explained variance (R-squared): how much the unconditional variance is reduced by including covariates
  - R-squared = (unconditional variance - conditional variance) / unconditional variance
- In multilevel models we distinguish two forms of R-squared
  - Marginal R-squared: proportion of variance explained by the fixed effects only (i.e., reduction in variability among units with identical covariate values)
  - Conditional R-squared: proportion of variance explained by both fixed and random effects (i.e., reduction in variability among units with identical covariate values and identical group membership)

## Correlation within groups

::: {style="font-size: 0.9em;"}

- In the familiar notion of correlation, we examine how two variables (X and Y) co-vary within the same unit
- In multilevel models, correlation refers to the similarity between outcomes that belong to the same group
- A useful thought experiment for two-level hierarchical data
  - Imagine repeatedly selecting a group at random and then sampling two units from that group
  - Groups with a high or low underlying effect will produce two outcomes that tend to move together across repeated samples
- We can visualise this idea by randomly selecting two observations from each group and plotting the resulting pairs in a scatterplot
  - When the between-group differences are large, the pairs tend to lie close to the diagonal
  - When the between-group differences are small, the pairs scatter widely across the plot
 - The ICC quantifies this within-group correlation
   - It is computed as the ratio of the between-group variance to the total variance
   - In a null model this uses the unconditional variance (no covariates)
   - In a model with covariates this uses the conditional variance (after adjusting for covariates)

:::

## Effects coding versus dummy coding

::: {style="font-size: 0.9em;"}

Suppose we have two groups: group A: mean = 5; group B: mean = 10

**Dummy coding**

- Choose A as the reference
- Code A as 0, code B as 1
- The intercept equals the mean of A → 5
- The coefficient for the group variable equals the difference between B and A → 10 − 5 = 5
- Interpretation: B is 5 units higher than A

**Effects coding**

- No reference group
- Code A as +1, code B as -1
- The intercept equals the grand mean → (5 + 10) / 2 = 7.5
- The coefficient shows how far A deviates from the grand mean → 5 − 7.5 = -2.5 
- Interpretation: A is 2.5 below the overall mean; B is 2.5 above the overall mean

:::

## Today's lecture

- Cluster randomization
  - Treatment as a cluster-level (level 2) variable

- Multi-level analysis of cross-sectional observational data
  - Models with both individual-level (level 1) and context-level (level 2) variables
  - Cross-level interactions
  - Three-level hierarchical models

# Part 1: Cluster randomization

```{r}
### Simulate a hypothetical cluster-randomized trial

# Set parameters
set.seed(42)
n_wards <- 12
n_patients_per_ward <- 30
treatment_effect <- 1   # Improvement in physical function score (0-12 scale)
sigma_ward <- 1.3         # SD of ward random effects
sigma_residual <- 1.5     # SD of individual-level residual variation

# Generate ward-level data
wards <- data.frame(
  ward_id = 1:n_wards,
  intervention = rep(c("standard_care", "early_mobilization"), each = n_wards/2),
  ward_effect = rnorm(n_wards, mean = 0, sd = sigma_ward)
)

# Generate patient-level data
patients <- expand.grid(
  ward_id = 1:n_wards,
  patient_within_ward = 1:n_patients_per_ward
) |>
  mutate(
    patient_id = 1:(n_wards * n_patients_per_ward),
    age = round(rnorm(n_wards * n_patients_per_ward, mean = 65, sd = 12)),
    preop_function = round(rnorm(n_wards * n_patients_per_ward, mean = 9, sd = 2))  # Pre-operative function score (0-12)
  )

# Merge ward-level information with patient-level data
patients <- merge(patients, wards, by = "ward_id")

# Simulate outcomes (physical function score at discharge: 0-12 scale)
patients <- patients |>
  mutate(
    function_score = 6 +  # Baseline post-surgery function
                     0.2 * (preop_function - 9) +  # Effect of pre-op function
                     ward_effect +
                     ifelse(intervention == "early_mobilization", treatment_effect, 0) +
                     rnorm(n_wards * n_patients_per_ward, mean = 0, sd = sigma_residual),
    function_score = round(pmin(12, pmax(0, function_score)))  # Round and bound between 0-12
  )

# Prepare final dataset
data_cluster_randomization <- patients |>
  mutate(
    intervention = factor(intervention, levels = c("standard_care", "early_mobilization")),
    ward_id = factor(ward_id)
  )
```

## Example: Early mobilization after surgery

- Research question:
  - Does implementing a structured early mobilization protocol in post-surgical wards improve patients' physical function recovery compared to standard care?

- Study design:
  - 12 post-surgical wards randomized to enhanced early mobilization (n=6) or standard care (n=6)
  - 30 patients per ward recovering from major abdominal surgery
  - Total sample: 360 patients nested within 12 wards

- Intervention:
  - Enhanced: mobilization within 6 hours post-surgery, structured progression, twice-daily physiotherapy
  - Standard care: mobilization begins day 1-2 post-operatively, mobilization as clinically indicated

- Outcome:
  - Physical function score at hospital discharge (Short Physical Performance Battery: 0-12 scale, higher = better)

## Level of randomization

:::: {.columns}

::: {.column width="50%"}
**Randomized block design**

- Blocks are a nuisance factor we control for (e.g., litters, cages)
- Treatment assigned to individual units within each block
- Each block contains multiple treatment conditions
- Treatment is an **individual-level** (level 1) variable
- Goal: increase precision
:::

::: {.column width="50%"}
**Cluster randomization**

- Clusters define the unit of randomization (e.g., wards, clinics)
- Treatment assigned to entire clusters
- All individuals in a cluster receive the same treatment
- Treatment is a **cluster-level** (level 2) variable
- Reason: practical/ethical constraints, contamination risk
:::

::::

## Exploratory data analysis

```{r}
# Calculate ward-level means
ward_summary <- data_cluster_randomization |>
  group_by(ward_id, intervention) |>
  summarise(
    mean_function = mean(function_score),
    n = n(),
    .groups = "drop"
  )

# Calculate overall and intervention-specific means
grand_mean <- mean(data_cluster_randomization$function_score)
intervention_means <- data_cluster_randomization |>
  group_by(intervention) |>
  summarise(mean_function = mean(function_score))

# Create visualization showing individual patients and ward means
ggplot(data_cluster_randomization, aes(x = ward_id, y = function_score, color = intervention)) +
  geom_hline(yintercept = grand_mean, linetype = "solid", color = "black", linewidth = 1) +
  geom_hline(data = intervention_means,
             aes(yintercept = mean_function, color = intervention),
             linetype = "dashed", linewidth = 0.8) +
  geom_jitter(alpha = 0.4, width = 0.2, size = 1.5) +
  geom_point(data = ward_summary, aes(y = mean_function),
             size = 4, shape = 18) +
  labs(
    x = "Ward",
    y = "Physical function score (0-12)",
    color = "Intervention",
    title = "Physical function scores by ward and intervention",
    subtitle = "Points = individual patients; Diamonds = ward means; Solid line = grand mean; Dashed lines = intervention means"
  ) +
  scale_color_manual(
    values = c("standard_care" = "#E69F00", "early_mobilization" = "#56B4E9"),
    labels = c("Standard care", "Early mobilization")
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 0, hjust = 0.5)
  )
```

## Statistical model specification

To estimate the treatment effect while accounting for clustering within wards, we use a mixed-effects model with a random intercept for ward:

$$
Y_{ij} = \mu + \alpha_{T_j} + u_j + \varepsilon_{ij}
$$

- Model components:
  - $Y_{ij}$: physical function score for patient $i$ in ward $j$
  - $\mu$: grand mean (overall average across both intervention groups)
  - $\alpha_{T_j}$: fixed effect of treatment assigned to ward $j$ (deviation from grand mean)
    - $T_j$ denotes the treatment group of ward $j$ (standard care or early mobilization)
  - $u_j \sim N(0, \sigma^2_{\text{ward}})$: random effect for ward $j$, capturing ward-to-ward variability
  - $\varepsilon_{ij} \sim N(0, \sigma^2)$: residual error for patient $i$ in ward $j$

## Results: fixed effects

```{r}
#| echo: false
options(contrasts = c("contr.sum", "contr.poly"))  # Effects coding
model_cluster <- lmer(function_score ~ intervention + (1 | ward_id),
                      data = data_cluster_randomization)
```

**Estimated marginal means**

```{r}
#| echo: false
emm <- emmeans(model_cluster, ~ intervention)
kable(
  data.frame(emm),
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 90%; margin-left: 0; margin-right: auto"'
)
```

::: {style="margin-top:1.0em;"}
:::

**ANOVA table**

```{r}
#| echo: false
anova_table <- anova(model_cluster)
kable(
  anova_table,
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 90%; margin-left: 0; margin-right: auto"'
)
```

::: {style="margin-top:1.0em;"}
:::

- Early mobilization results in a mean physical function score of `r round(summary(emm)$emmean[2], 2)` (95% CI: [`r round(summary(emm)$lower.CL[2], 2)`, `r round(summary(emm)$upper.CL[2], 2)`])

- Standard care results in a mean physical function score of `r round(summary(emm)$emmean[1], 2)` (95% CI: [`r round(summary(emm)$lower.CL[1], 2)`, `r round(summary(emm)$upper.CL[1], 2)`])

- The `r round(summary(emm)$emmean[2] - summary(emm)$emmean[1], 2)` points difference in mean physical function score between early mobilization and standard care is statistically significant (F = `r round(anova_table$"F value"[1], 2)`, p < 0.001)

## Results: variance components

```{r}
#| echo: false
re <- broom.mixed::tidy(model_cluster, effects = "ran_pars") |>
  mutate(variance = estimate^2)
kable(
  re[, c("group", "term", "estimate", "variance")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 80%; margin-left: 0; margin-right: auto"'
)
```

::: {style="margin-top:1.0em;"}
:::

- **Ward-level variance ($\sigma^2_{\text{ward}}$):** `r round(as.data.frame(VarCorr(model_cluster))$vcov[1], 2)`
  - Captures the variability between wards

- **Residual variance ($\sigma^2$):** `r round(as.data.frame(VarCorr(model_cluster))$vcov[2], 2)`
  - Captures the variability between patients within the same ward

- **Intraclass correlation coefficient (ICC):**
$$\text{ICC} = \frac{\sigma^2_{\text{ward}}}{\sigma^2_{\text{ward}} + \sigma^2} = \frac{`r round(as.data.frame(VarCorr(model_cluster))$vcov[1], 2)`}{`r round(as.data.frame(VarCorr(model_cluster))$vcov[1], 2)` + `r round(as.data.frame(VarCorr(model_cluster))$vcov[2], 2)`} = `r round(as.data.frame(VarCorr(model_cluster))$vcov[1] / sum(as.data.frame(VarCorr(model_cluster))$vcov), 2)`$$

- About `r round(100 * as.data.frame(VarCorr(model_cluster))$vcov[1] / sum(as.data.frame(VarCorr(model_cluster))$vcov), 0)`% of total variance in physical function scores is attributable to differences between wards, indicating moderate clustering of outcomes within wards

## Ordinary linear regression ignoring clustering

```{r}
#| echo: false
model_ols <- lm(function_score ~ intervention, data = data_cluster_randomization)
```

**Estimated marginal means**

```{r}
#| echo: false
emm_ols <- emmeans(model_ols, ~ intervention)
kable(
  data.frame(emm_ols),
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 90%; margin-left: 0; margin-right: auto"'
)
```

::: {style="margin-top:1.0em;"}
:::

**ANOVA table**

```{r}
#| echo: false
anova_ols <- anova(model_ols)
kable(
  anova_ols,
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 90%; margin-left: 0; margin-right: auto"'
)
```

::: {style="margin-top:1.0em;"}
:::

- The estimated treatment effect is similar (`r round(summary(emm_ols)$emmean[2] - summary(emm_ols)$emmean[1], 2)` vs. `r round(summary(emm)$emmean[2] - summary(emm)$emmean[1], 2)` points)

- However, the standard errors are **too small** (SE = `r round(summary(emm_ols)$SE[1], 3)` vs. `r round(summary(emm)$SE[1], 3)` in the mixed model)

- This leads to overly narrow confidence intervals and **inflated Type I error rates**

- The F-statistic is much larger (F = `r round(anova_ols$"F value"[1], 2)` vs. F = `r round(anova_table$"F value"[1], 2)`), falsely suggesting stronger evidence

## Effective sample size

- When the ICC is large, wards vary substantially in their baseline performance
  - The observed treatment effect may partly reflect random differences in which wards received the intervention
  - With only 12 wards randomized, we have limited ability to separate true treatment effects from block-level variation that happened to align with the treatment assignment

- This decrease in precision with cluster-level variables is reflected in the notion of **effective sample size**
  - Because outcomes are correlated within wards, the effective sample size is much smaller than 360
  - Think of it as having information equivalent to somewhere between 12 wards and 360 independent patients

- The mixed model accounts for this by correctly modelling between-ward variation instead of pooling it into the fixed treatment effect, producing larger standard errors and wider confidence intervals

- Ordinary linear regression incorrectly treats all 360 patients as independent, pools ward-level differences into the fixed effect, and therefore gives overly optimistic conclusions



## Consequences of ignoring the grouping structure {style="font-size: 0.9em;"}

:::: {.columns}

::: {.column width="50%"}
**Randomized block design**

- Treatment is assigned at the **individual level** (level 1)
- Accounting for blocks **increases precision**
  - Removes block-to-block variation from the residual
  - Leads to smaller standard errors for treatment effects
  - Increases statistical power to detect treatment differences
- Ignoring blocks is **inefficient but valid**
  - Treatment effect estimates remain unbiased
  - Standard errors are larger (loss of power)
  - No inflation of Type I error (false positive) rates
:::

::: {.column width="50%"}
**Cluster randomization**

- Treatment is assigned at the **cluster level** (level 2)
- Accounting for clusters **decreases precision**
  - Reduces the effective sample size
  - Leads to larger standard errors for treatment effects
  - Provides less power than individual-level randomization
- Ignoring clusters is **invalid** for inference
  - Treatment effect estimates remain unbiased
  - Standard errors are too small (anti-conservative)
  - Inflated Type I error (false positive) rates
:::

::::

## What did we learn in previous weeks - part 2 {style="font-size: 0.9em;"}

- Three-level hierarchical data
  - Replicated randomized block design: experimental units (level 1) nested in treatment conditions (level 2) nested in blocks (level 3)
  - Treatment is a level-2 variable because each block has its own set of treatment conditions
  - Ignoring the treatment–block interaction changes the validity of treatment inferences
    - If a random block effect is included but the treatment–block interaction is omitted, block-specific treatment differences are incorrectly pooled into the fixed treatment effect, resulting in overly optimistic standard errors
    - This is conceptually the same mistake as ignoring clustering in a cluster randomized trial, where cluster-level variation is pooled into the fixed effect and leads to anti-conservative inference
  - Including random block and treatment–block effects correctly partitions variation across levels and gives valid uncertainty estimates for treatment effects
    - The number of truly independent pieces of information is determined by the number of blocks and treatment conditions, not by the total number of experimental units (effective sample size)  

# Part 2: Multi-level analysis of cross-sectional observational data

```{r}
### Simulate observational hierarchical data

# Set parameters
set.seed(123)
n_hospitals <- 18
n_patients_per_hospital <- 40
beta_age <- 0.15           # Effect of patient age (per year)
beta_severity <- 1.2       # Effect of disease severity (per point)
beta_teaching <- -2.0      # Effect of teaching hospital status
beta_size <- -0.01         # Effect of hospital size (per bed)
sigma_hospital <- 2.5      # SD of hospital random effects
sigma_residual <- 3.0      # SD of individual-level residual variation

# Generate hospital-level data
hospitals <- data.frame(
  hospital_id = 1:n_hospitals,
  academic_status = sample(c("non_academic", "academic"), n_hospitals, replace = TRUE, prob = c(0.67, 0.33)),
  hospital_size = round(rnorm(n_hospitals, mean = 400, sd = 150)),
  hospital_effect = rnorm(n_hospitals, mean = 0, sd = sigma_hospital)
)

# Generate patient-level data
patients_obs <- expand.grid(
  hospital_id = 1:n_hospitals,
  patient_within_hospital = 1:n_patients_per_hospital
) |>
  mutate(
    patient_id = 1:(n_hospitals * n_patients_per_hospital),
    age = round(rnorm(n_hospitals * n_patients_per_hospital, mean = 68, sd = 12)),
    cci_score = round(rnorm(n_hospitals * n_patients_per_hospital, mean = 4, sd = 2))  # Charlson Comorbidity Index (0-10+)
  )

# Merge hospital-level information with patient-level data
patients_obs <- merge(patients_obs, hospitals, by = "hospital_id")

# Simulate outcomes (length of stay in days)
patients_obs <- patients_obs |>
  mutate(
    length_of_stay = 8 +                                    # Baseline length of stay
                     beta_age * (age - 68) +                # Effect of age
                     beta_severity * (cci_score - 4) +      # Effect of comorbidity burden (CCI)
                     beta_teaching * (academic_status == "academic") +  # Effect of academic status
                     beta_size * (hospital_size - 400) +    # Effect of hospital size
                     hospital_effect +                       # Hospital random effect
                     rnorm(n_hospitals * n_patients_per_hospital, mean = 0, sd = sigma_residual),
    length_of_stay = round(pmax(1, length_of_stay))        # Minimum 1 day
  )

# Prepare final dataset
data_observational <- patients_obs |>
  mutate(
    academic_status = factor(academic_status, levels = c("non_academic", "academic")),
    hospital_id = factor(hospital_id)
  ) |>
  select(patient_id, hospital_id, age, cci_score, academic_status, hospital_size, length_of_stay)
```

## Example: Hospital length of stay

- Research questions:
  - How much of the variation in length of stay is attributable to hospitals?
  - Which patient-level and hospital-level characteristics are associated with length of stay?

- Study design:
  - Cross-sectional observational study
  - 720 patients nested within 18 hospitals
  - Varying hospital sizes (non-academic and academic hospitals)

- Variables:
  - **Patient-level** (level 1): age, comorbidity burden (Charlson Comorbidity Index)
  - **Hospital-level** (level 2): academic status, hospital size (number of beds)
  - **Outcome**: length of stay (days)

## Exploratory data analysis - outcome variable

```{r}
# Create histogram of length of stay
ggplot(data_observational, aes(x = length_of_stay)) +
  geom_histogram(binwidth = 2, fill = "steelblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = mean(data_observational$length_of_stay),
             color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    x = "Length of stay (days)",
    y = "Frequency",
    title = "Distribution of hospital length of stay",
    subtitle = paste0("Mean = ", round(mean(data_observational$length_of_stay), 1), " days; ",
                     "SD = ", round(sd(data_observational$length_of_stay), 1), " days")
  ) +
  theme_minimal()
```

## Exploratory data analysis - variance components {style="font-size: 0.9em;"}

```{r}
# Calculate hospital-level means
hospital_summary <- data_observational |>
  group_by(hospital_id) |>
  summarise(
    mean_los = mean(length_of_stay),
    sd_los = sd(length_of_stay),
    n = n(),
    .groups = "drop"
  ) |>
  arrange(mean_los)

# Calculate overall mean
grand_mean_obs <- mean(data_observational$length_of_stay)

# Order hospitals by mean
hospital_order <- hospital_summary |>
  arrange(mean_los) |>
  pull(hospital_id)

data_observational_ordered <- data_observational |>
  mutate(hospital_id = factor(hospital_id, levels = hospital_order))

# Create visualization showing variation within and between hospitals
ggplot(data_observational_ordered, aes(x = hospital_id, y = length_of_stay)) +
  geom_hline(yintercept = grand_mean_obs, linetype = "solid", color = "black", linewidth = 1) +
  geom_jitter(alpha = 0.3, width = 0.2, size = 1, color = "gray60") +
  geom_point(data = hospital_summary, aes(x = hospital_id, y = mean_los),
             size = 4, shape = 18, color = "red") +
  labs(
    x = "Hospital (ordered by mean length of stay)",
    y = "Length of stay (days)",
    title = "Variation in length of stay: within and between hospitals",
    subtitle = "Points = individual patients; Diamonds = hospital means; Solid line = grand mean"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8)
  )
```

- **Within-hospital variation**: patients in the same hospital have different lengths of stay
- **Between-hospital variation**: hospital means differ substantially from each other

## Exploratory data analysis - covariate effects

:::: {.columns}

::: {.column width="50%"}
**Patient-level covariates (level 1)**

```{r}
#| echo: false
# Scatterplot for age
p1 <- ggplot(data_observational, aes(x = age, y = length_of_stay)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "darkblue") +
  labs(
    x = "Age (years)",
    y = "Length of stay (days)",
    title = "Age vs. Length of stay"
  ) +
  theme_minimal()

# Scatterplot for CCI
p2 <- ggplot(data_observational, aes(x = cci_score, y = length_of_stay)) +
  geom_jitter(alpha = 0.3, width = 0.2, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "darkblue") +
  labs(
    x = "Charlson Comorbidity Index",
    y = "Length of stay (days)",
    title = "CCI vs. Length of stay"
  ) +
  theme_minimal()

gridExtra::grid.arrange(p1, p2, ncol = 1)
```
:::

::: {.column width="50%"}
**Hospital-level covariates (level 2)**

```{r}
#| echo: false
# Boxplot for academic status
p3 <- ggplot(data_observational, aes(x = academic_status, y = length_of_stay, fill = academic_status)) +
  geom_boxplot(alpha = 0.6) +
  scale_fill_manual(values = c("non_academic" = "#E69F00", "academic" = "#56B4E9")) +
  labs(
    x = "Hospital type",
    y = "Length of stay (days)",
    title = "Academic status vs. Length of stay"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Scatterplot for hospital size (aggregate by hospital)
hospital_data <- data_observational |>
  group_by(hospital_id, hospital_size) |>
  summarise(mean_los = mean(length_of_stay), .groups = "drop")

p4 <- ggplot(hospital_data, aes(x = hospital_size, y = mean_los)) +
  geom_point(size = 3, color = "steelblue") +
  geom_smooth(method = "lm", se = FALSE, color = "darkblue") +
  labs(
    x = "Hospital size (beds)",
    y = "Mean length of stay (days)",
    title = "Hospital size vs. Mean length of stay"
  ) +
  theme_minimal()

gridExtra::grid.arrange(p3, p4, ncol = 1)
```
:::

::::

::: {style="margin-top:1.0em;"}
:::

- Older patients and those with higher comorbidity burden tend to have longer hospital stays
- Academic hospitals appear to have slightly shorter stays on average
- Larger hospitals tend to have shorter average length of stay

## Null model: variance partitioning

The **null model** (or **unconditional model**) contains only random intercepts for hospitals, without any covariates:

$$
Y_{ij} = \mu + u_j + \varepsilon_{ij}
$$

where $u_j \sim N(0, \sigma^2_{\text{hospital}})$ and $\varepsilon_{ij} \sim N(0, \sigma^2)$

```{r}
#| echo: false
model_null <- lmer(length_of_stay ~ 1 + (1 | hospital_id), data = data_observational)
```

::: {style="margin-top:1.0em;"}
:::

:::: {.columns}

::: {.column width="50%"}
**Fixed effects:**

```{r}
#| echo: false
fe_null <- broom.mixed::tidy(model_null, effects = "fixed")
kable(
  fe_null[, c("term", "estimate", "std.error")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 80%; margin-left: 0; margin-right: auto"',
  col.names = c("Term", "Estimate", "SE")
)
```
:::

::: {.column width="50%"}
**Variance components:**

```{r}
#| echo: false
vc_null <- broom.mixed::tidy(model_null, effects = "ran_pars") |>
  mutate(variance = estimate^2)
kable(
  vc_null[, c("group", "estimate", "variance")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 80%; margin-left: 0; margin-right: auto"',
  col.names = c("Group", "SD", "Variance")
)
```
:::

::::

::: {style="margin-top:1.0em;"}
:::

- Grand mean: `r round(fixef(model_null), 2)` days
- ICC = `r round(as.data.frame(VarCorr(model_null))$vcov[1] / sum(as.data.frame(VarCorr(model_null))$vcov), 3)`: about `r round(100 * as.data.frame(VarCorr(model_null))$vcov[1] / sum(as.data.frame(VarCorr(model_null))$vcov), 0)`% of variance in length of stay is attributable to differences between hospitals
- This ICC reflects the correlation in length of stay among patients from the same hospital, measured before adjusting for any patient or hospital characteristics

## Adding patient-level characteristics

Model with patient characteristics (age, comorbidity burden):

$$
Y_{ij} = \mu + \beta_1 \text{Age_centered}_{ij} + \beta_2 \text{CCI_centered}_{ij} + u_j + \varepsilon_{ij}
$$

```{r}
#| echo: false
# Center patient-level predictors at grand mean
data_observational <- data_observational |>
  mutate(
    age_centered = age - mean(age),
    cci_centered = cci_score - mean(cci_score)
  )

model_patient <- lmer(length_of_stay ~ age_centered + cci_centered + (1 | hospital_id),
                      data = data_observational)
```

::: {style="margin-top:1.0em;"}
:::

:::: {.columns}

::: {.column width="60%"}
**Coefficient estimates:**

```{r}
#| echo: false
fe_patient <- broom.mixed::tidy(model_patient, effects = "fixed")
kable(
  fe_patient[, c("term", "estimate", "std.error", "statistic", "p.value")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 70%; margin-left: 0; margin-right: auto"'
)
```
:::

::: {.column width="40%"}
**Variance components:**

```{r}
#| echo: false
vc_patient <- broom.mixed::tidy(model_patient, effects = "ran_pars") |>
  mutate(variance = estimate^2)
kable(
  vc_patient[, c("group", "estimate", "variance")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 70%; margin-left: 0; margin-right: auto"',
  col.names = c("Group", "SD", "Variance")
)
```
:::

::::

::: {style="margin-top:1.0em;"}
:::

- Intercept (`r round(fixef(model_patient)["(Intercept)"], 2)` days) represents the expected length of stay for a patient with average age and average comorbidity burden

- Each additional year of age is associated with a `r round(fixef(model_patient)["age_centered"], 2)` day increase in length of stay

- Each additional point on the CCI is associated with a `r round(fixef(model_patient)["cci_centered"], 2)` day increase in length of stay

- Adding patient-level characteristics reduces residual (within-hospital) variance and may also reduce between-hospital variance if hospitals differ in their patient mix

## Adding hospital-level characteristics

Model with both patient and hospital characteristics:

$$
Y_{ij} = \mu + \beta_1 \text{Age_centered}_{ij} + \beta_2 \text{CCI_centered}_{ij} + \alpha_j + \beta_3 \text{Size_centered}_j + u_j + \varepsilon_{ij}
$$

- $\alpha_j$: fixed effect of academic status for hospital $j$ (effects coding: $\alpha_{\text{academic}} + \alpha_{\text{non-academic}} = 0$)

```{r}
#| echo: false
# Center hospital-level predictors and use effects coding
data_observational <- data_observational |>
  mutate(
    size_centered = hospital_size - mean(hospital_size)
  )

options(contrasts = c("contr.sum", "contr.poly"))  # Effects coding
model_full <- lmer(length_of_stay ~ age_centered + cci_centered + academic_status + size_centered + (1 | hospital_id),
                   data = data_observational)
```

```{r}
#| echo: false
#| include: false
emm_academic <- emmeans(model_full, ~ academic_status)
```

:::: {.columns}

::: {.column width="60%"}
**Coefficient estimates:**

```{r}
#| echo: false
fe_full <- broom.mixed::tidy(model_full, effects = "fixed")
kable(
  fe_full[, c("term", "estimate", "std.error", "statistic", "p.value")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 50%; margin-left: 0; margin-right: auto"'
)
```
:::

::: {.column width="40%"}
**Variance components:**

```{r}
#| echo: false
vc_full <- broom.mixed::tidy(model_full, effects = "ran_pars") |>
  mutate(variance = estimate^2)
kable(
  vc_full[, c("group", "estimate", "variance")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 50%; margin-left: 0; margin-right: auto"',
  col.names = c("Group", "SD", "Variance")
)
```
:::

::::

::: {style="margin-top:1.0em;"}
:::

- Academic hospitals have a mean length of stay of `r round(summary(emm_academic)$emmean[1], 2)` days, while non-academic hospitals have `r round(summary(emm_academic)$emmean[2], 2)` days

- Each 100-bed increase in hospital size is associated with a `r round(100 * fixef(model_full)["size_centered"], 2)` day change in length of stay

- Adding hospital-level characteristics reduces between-hospital variance while leaving the residual variance unchanged

## Estimating the ICC in observational versus experimental studies

- In observational studies the ICC is calculated from the null model because we want to describe the raw clustering structure in the data
  - This raw clustering structure motivates the use of multilevel models

- In experimental studies (cluster randomization or randomized blocks) the ICC is calculated from a model that includes treatment because we want to describe the residual clustering after adjusting for the design
  - This residual clustering determines power and sample size

- The guiding principle is that the ICC should reflect the type of variation that is relevant for the study objective, which differs between observational and experimental settings

## Lab 5: multi-level analysis of the Chicago AirBnB dataset

![](/R-lab.png){width="60%"  fig-align="center" alt="Lab session"}

## Three-level hierarchical model

```{r}
chicago_airbnb <- read.csv("../data/airbnb.csv")

chicago_airbnb <- chicago_airbnb |>
  mutate_if(is.character, as.factor)

chicago_airbnb <- chicago_airbnb |>
  mutate(log_price = log(price))

# Fit both models for later comparison
two_lvl_model <- lmer(log_price ~ 1 + (1 | neighborhood), data = chicago_airbnb)
three_lvl_model <- lmer(log_price ~ 1 + (1 | district/neighborhood), data = chicago_airbnb)
```

In the Chicago AirBnB dataset, neighborhoods are nested within districts, creating a three-level hierarchy: listings (level 1) within neighborhoods (level 2) within districts (level 3).

```{r}
#| echo: true
#| eval: false
three_lvl_model <- lmer(log_price ~ 1 + (1 | district/neighborhood),
 data = chicago_airbnb)
```

::: {style="margin-top:1.0em;"}
:::

:::: {.columns style="font-size: 0.8em;"}

::: {.column width="50%"}
**Variance components:**

```{r}
vc_three_level <- broom.mixed::tidy(three_lvl_model, effects = "ran_pars") |>
  mutate(variance = estimate^2)
kable(
  vc_three_level[, c("group", "estimate", "variance")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 100%; margin-left: 0; margin-right: auto"',
  col.names = c("Group", "SD", "Variance")
)
```
:::

::: {.column width="50%"}
**Intraclass correlations:**

```{r}
# Calculate ICCs for three-level model
var_district <- as.data.frame(VarCorr(three_lvl_model))$vcov[2]
var_neighborhood_3lvl <- as.data.frame(VarCorr(three_lvl_model))$vcov[1]
var_residual_3lvl <- as.data.frame(VarCorr(three_lvl_model))$vcov[3]
total_var <- var_district + var_neighborhood_3lvl + var_residual_3lvl

icc_neighborhood_3lvl <- (var_district + var_neighborhood_3lvl) / total_var
icc_district <- var_district / total_var
```

$$\text{ICC}_{\text{neighborhood}} = \frac{\sigma^2_{\text{district}} + \sigma^2_{\text{neighborhood}}}{\sigma^2_{\text{district}} + \sigma^2_{\text{neighborhood}} + \sigma^2} = `r round(icc_neighborhood_3lvl, 3)`$$

$$\text{ICC}_{\text{district}} = \frac{\sigma^2_{\text{district}}}{\sigma^2_{\text{district}} + \sigma^2_{\text{neighborhood}} + \sigma^2} = `r round(icc_district, 3)`$$
:::

::::

::: {style="margin-top:0.5em; font-size: 0.9em;"}
- **ICC_neighborhood**: correlation between two listings from the same neighborhood (= `r round(icc_neighborhood_3lvl, 3)`)
- **ICC_district**: correlation between two listings from different neighborhoods but the same district (= `r round(icc_district, 3)`)
:::

## Comparing estimated variance components {style="font-size: 0.85em;"}

:::: {.columns}

::: {.column width="50%"}
**Two-level model**

```{r}
# Calculate variance components for two-level model
var_neighborhood_2lvl <- as.data.frame(VarCorr(two_lvl_model))$vcov[1]
var_residual_2lvl <- as.data.frame(VarCorr(two_lvl_model))$vcov[2]
```

```{r}
vc_two_level <- broom.mixed::tidy(two_lvl_model, effects = "ran_pars") |>
  mutate(variance = estimate^2)
kable(
  vc_two_level[, c("group", "estimate", "variance")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 100%; margin-left: 0; margin-right: auto"',
  col.names = c("Group", "SD", "Variance")
)
```

Total between-neighborhood variance: `r round(var_neighborhood_2lvl, 3)`
:::

::: {.column width="50%"}
**Three-level model**

```{r}
# Calculate variance components for three-level model
var_district <- as.data.frame(VarCorr(three_lvl_model))$vcov[2]
var_neighborhood_3lvl <- as.data.frame(VarCorr(three_lvl_model))$vcov[1]
var_residual_3lvl <- as.data.frame(VarCorr(three_lvl_model))$vcov[3]
```

```{r}
vc_three_level_compare <- broom.mixed::tidy(three_lvl_model, effects = "ran_pars") |>
  mutate(variance = estimate^2)
kable(
  vc_three_level_compare[, c("group", "estimate", "variance")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 100%; margin-left: 0; margin-right: auto"',
  col.names = c("Group", "SD", "Variance")
)
```

Total between-neighborhood variance: `r round(var_district + var_neighborhood_3lvl, 3)`
:::

::::

::: {style="margin-top:1.0em;"}
:::

- The **residual variance** is the same in both models (`r round(var_residual_2lvl, 3)` vs. `r round(var_residual_3lvl, 3)`)
  - This represents within-neighborhood variation, which is unaffected by how we model between-neighborhood structure

- The **total between-neighborhood variance** is slightly higher in the three-level model (`r round(var_district + var_neighborhood_3lvl, 3)`) than in the two-level model (`r round(var_neighborhood_2lvl, 3)`)
  - In the two-level model, all between-neighborhood variance is attributed to neighborhoods
  - In the three-level model, this variance is partitioned into district effects (`r round(var_district, 3)`) and neighborhood-within-district effects (`r round(var_neighborhood_3lvl, 3)`)
  - The three-level model provides a more accurate decomposition when neighborhoods are nested within districts

## Comparing estimated level-1 coefficients

Let's compare models with level-1 predictors (listing characteristics) in both two-level and three-level models:

```{r}
# Center predictors
chicago_airbnb <- chicago_airbnb |>
  mutate(
    bedrooms_centered = bedrooms - mean(bedrooms, na.rm = TRUE),
    accommodates_centered = accommodates - mean(accommodates, na.rm = TRUE)
  )

# Fit models with level-1 predictors
two_lvl_l1 <- lmer(log_price ~ bedrooms_centered + accommodates_centered + (1 | neighborhood),
                   data = chicago_airbnb)
three_lvl_l1 <- lmer(log_price ~ bedrooms_centered + accommodates_centered + (1 | district/neighborhood),
                     data = chicago_airbnb)
```

:::: {.columns style="font-size: 0.75em;"}

::: {.column width="50%"}
**Two-level model**

```{r}
fe_two_l1 <- broom.mixed::tidy(two_lvl_l1, effects = "fixed")
kable(
  fe_two_l1[, c("term", "estimate", "std.error", "statistic", "p.value")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 100%; margin-left: 0; margin-right: auto"'
)
```
:::

::: {.column width="50%"}
**Three-level model**

```{r}
fe_three_l1 <- broom.mixed::tidy(three_lvl_l1, effects = "fixed")
kable(
  fe_three_l1[, c("term", "estimate", "std.error", "statistic", "p.value")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 100%; margin-left: 0; margin-right: auto"'
)
```
:::

::::

::: {style="margin-top:1.0em;"}
:::

- Level-1 coefficient estimates are nearly identical between models
  - Each additional bedroom: ~`r round(coef(summary(two_lvl_l1))["bedrooms_centered", "Estimate"], 3)` vs. ~`r round(coef(summary(three_lvl_l1))["bedrooms_centered", "Estimate"], 3)` log-price increase
  - Each additional guest capacity: ~`r round(coef(summary(two_lvl_l1))["accommodates_centered", "Estimate"], 3)` vs. ~`r round(coef(summary(three_lvl_l1))["accommodates_centered", "Estimate"], 3)` log-price increase

- Standard errors are also very similar
  - Level-1 effects are estimated from within-neighborhood variation, which is unaffected by the district-level structure

## Comparing estimated level-2 coefficients

Now let's add a level-2 predictor (neighborhood WalkScore) to both models:

```{r}
# Calculate neighborhood-level mean WalkScore
neighborhood_walkscore <- chicago_airbnb |>
  group_by(neighborhood) |>
  summarise(mean_walkscore = mean(WalkScore, na.rm = TRUE)) |>
  mutate(walkscore_centered = mean_walkscore - mean(mean_walkscore, na.rm = TRUE))

chicago_airbnb <- chicago_airbnb |>
  left_join(neighborhood_walkscore, by = "neighborhood")

# Fit models with level-2 predictor
two_lvl_l2 <- lmer(log_price ~ walkscore_centered + (1 | neighborhood),
                   data = chicago_airbnb)
three_lvl_l2 <- lmer(log_price ~ walkscore_centered + (1 | district/neighborhood),
                     data = chicago_airbnb)
```

:::: {.columns style="font-size: 0.75em;"}

::: {.column width="50%"}
**Two-level model**

```{r}
fe_two_l2 <- broom.mixed::tidy(two_lvl_l2, effects = "fixed")
kable(
  fe_two_l2[, c("term", "estimate", "std.error", "statistic", "p.value")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 100%; margin-left: 0; margin-right: auto"'
)
```
:::

::: {.column width="50%"}
**Three-level model**

```{r}
fe_three_l2 <- broom.mixed::tidy(three_lvl_l2, effects = "fixed")
kable(
  fe_three_l2[, c("term", "estimate", "std.error", "statistic", "p.value")],
  digits = 3,
  format = "html",
  table.attr = 'style="font-size: 100%; margin-left: 0; margin-right: auto"'
)
```
:::

::::

::: {style="margin-top:1.0em;"}
:::

- The level-2 coefficient estimate may differ slightly between models
  - WalkScore effect: ~`r round(coef(summary(two_lvl_l2))["walkscore_centered", "Estimate"], 3)` vs. ~`r round(coef(summary(three_lvl_l2))["walkscore_centered", "Estimate"], 3)` log-price change per unit WalkScore

- The standard error is larger in the three-level model
  - SE: `r round(coef(summary(two_lvl_l2))["walkscore_centered", "Std. Error"], 3)` vs. `r round(coef(summary(three_lvl_l2))["walkscore_centered", "Std. Error"], 3)`
  - Neighborhoods within the same district are correlated, reducing the effective number of independent observations
  - This increases uncertainty in the level-2 coefficient estimate

## Summary

- Adding a level 3 grouping reveals additional clustering at that level, which further reduces the effective number of independent units available and therefore increases the standard errors of level 2 effects

- Standard errors of level 1 coefficients change little because they are driven by within-neighborhood variation, which is only minimally affected by introducing a district level

- Standard errors of level 2 coefficients often increase because neighborhoods within the same district are correlated, reducing the amount of independent between-neighborhood information

- When the interest lies in testing individual-level hypotheses, the impact of adding a higher level is usually limited because level 1 precision is largely preserved

- When the interest lies in context-level effects or cross-level interactions, the impact is more substantial because these effects rely on between-cluster information, which becomes less independent as higher levels are introduced

