---
title: "Beyond MLR - Week 1: Experimental Design I"
subtitle: "One-way FE/RE, ANOVA, coding, ICC"
author: "Dr. Douwe Postmus"
format:
  revealjs:
    theme: [default, custom-reveal.scss]
    slide-number: true
    toc: false
    slide-level: 2
    incremental: false
    code-overflow: wrap
    scrollable: true
    smaller: true
    width: 1280
    height: 720
    margin: 0.06
    max-scale: 2
    footer: "Beyond linear regression - week 1"
    logo: UMCG-logo.png
execute:
  warning: false
  message: false
  eval: true
  echo: false
---

```{r}
#| include: false
#| message: false
#| warning: false
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(knitr, rmarkdown, dplyr, ggplot2, emmeans)
```

## Introduction

- Welcome slide (to be completed later)

## Case study — antihypertensive treatments

- Research question: do two experimental drugs (Drug A, Drug B) reduce systolic blood pressure (SBP) more than Control over 52 weeks?
- Design: 120 patients with hypertension are randomly assigned to one of three groups (n = 40 each): Control, Drug A, or Drug B
- Response (outcome): change in SBP (mmHg) from baseline to week 52

```{r}
#| echo: false
# Prepare example data once for subsequent slides (hidden)
set.seed(123)
control <- rnorm(40, mean = -3,  sd = 15)
drugA   <- rnorm(40, mean = -10, sd = 15)
drugB   <- rnorm(40, mean = -5,  sd = 15)
df_bp <- data.frame(
  Treatment = factor(rep(c("Control","DrugA","DrugB"), each = 40),
                     levels = c("Control","DrugA","DrugB")),
  SBP_change = c(control, drugA, drugB)
)
```

## Exploratory data analysis

```{r}
#| echo: false
boxplot(SBP_change ~ Treatment, data = df_bp,
        col = c("gray85","skyblue","lightgreen"),
        ylab = "Change in SBP (mmHg)", main = NULL)
```

## Statistical model specification

To compare the average change in SBP across the three treatment groups, we use the one-way ANOVA model:

$$
Y_{ij} = \mu + \tau_i + \varepsilon_{ij}
$$

- Model components:
  - $Y_{ij}$: change in SBP observed for the $j$-th subject in the $i$-th treatment group
  - $\mu$ (grand mean): the overall mean across groups (the average of the group means)
  - $\tau_i$ (treatment deviations): the deviation of the mean of group $i$ from the grand mean; constrained so $\sum_i \tau_i = 0$
  - $\varepsilon_{ij}$ (residual error): the deviation for subject $j$ from the mean of group $i$
- Statistical assumptions:
  - $\varepsilon_{ij}\sim\mathcal{N}(0,\sigma^2)$: errors are independent and identically normally distributed with mean zero and common variance $\sigma^2$ (homoscedasticity)

## Estimation using linear regression

- A one-way ANOVA model can be expressed as a linear regression with a categorical predictor, allowing us to use the regression framework for estimation and hypothesis testing
- Using dummy coding with the control group as reference, the statistically equivalent regression model is:

:::: {.columns}

::: {.column width="50%"}
$$
Y_{ij} = \beta_0 + \beta_1 D_{1,ij} + \beta_2 D_{2,ij} + \varepsilon_{ij}
$$
:::

::: {.column width="50%"}
| Treatment | Intercept | D1 (DrugA) | D2 (DrugB) |
|---|---:|:---:|:---:|
| Control | 1 | 0 | 0 |
| DrugA   | 1 | 1 | 0 |
| DrugB   | 1 | 0 | 1 |

:::

::::

- Interpretation:
  - Intercept ($\beta_0$): estimated mean for Control
  - $\beta_1$: estimated difference mean(DrugA) − mean(Control)
  - $\beta_2$: estimated difference mean(DrugB) − mean(Control)

## Estimated regression coefficients

```{r}
#| echo: false
# R (refresher): reference coding with Control as baseline
contrasts(df_bp$Treatment) <- contr.treatment(levels(df_bp$Treatment))
fit <- lm(SBP_change ~ Treatment, data = df_bp)
summary(fit)
```

## Mapping to the ANOVA model parameters

- Intercept and betas → group means:
  - mean(Control) = $\beta_0$
  - mean(DrugA)   = $\beta_0 + \beta_1$
  - mean(DrugB)   = $\beta_0 + \beta_2$

- Grand mean (ANOVA intercept):
  $\mu = \frac{\text{mean(Control)} + \text{mean(DrugA)} + \text{mean(DrugB)}}{3} = \beta_0 + \frac{\beta_1 + \beta_2}{3}$

- Treatment deviations (ANOVA $\tau_i$) written in terms of the regression coefficients:
  - $\tau_{\text{Control}} = \text{mean(Control)} - \mu = -\frac{\beta_1 + \beta_2}{3}$
  - $\tau_{\text{DrugA}}   = \text{mean(DrugA)} - \mu = \beta_1 - \frac{\beta_1 + \beta_2}{3}$
  - $\tau_{\text{DrugB}}   = \text{mean(DrugB)} - \mu = \beta_2 - \frac{\beta_1 + \beta_2}{3}$

## Estimated marginal means (EMMs)

- Regression coefficients describe differences relative to a reference group
- Estimated marginal means (EMMs) express the same model in terms of predicted group means
- EMMs provide a direct and interpretable summary of group outcomes implied by the model
- In a one-way ANOVA model, the EMMs equal the observed group means
- In more complex models, EMMs give adjusted or conditional means that make comparisons fairer
  - With covariates (ANCOVA): EMMs adjust group means to a common covariate value, such as the overall mean
  - With interactions: EMMs provide conditional means for specific combinations of factors, allowing group comparisons at chosen settings

```{r}
#| echo: false
# Compute and display estimated marginal means
emms <- emmeans(fit, ~ Treatment)
summary(emms)
```

## F-test and explained variation

- Hypotheses (global) 
  - $H_0$: all group means are equal ($\tau_{Control} = \tau_{DrugA} = \tau_{DrugB} = 0$)  
  - $H_1$: at least one group mean differs ($\exists\, \tau_i \ne 0$)

- The total variation in the response can be decomposed as 
  
  $$SS_{Total} = SS_{Treatment} + SS_{Residual}$$  

  - $SS_{Treatment}$ represents variation explained by differences between treatment means  
  - $SS_{Residual}$ represents unexplained variation within treatments

- The F statistic compares the variance explained by treatment to the residual variance  
  $$
  F = \frac{MS_{Treatment}}{MS_{Residual}} = \frac{SS_{Treatment}/df_{Treatment}}{SS_{Residual}/df_{Residual}}
  $$

- A large F value indicates that the treatment explains a substantial part of the total variation relative to the residual variation

## Global hypothesis testing - results

```{r}
#| echo: false
anova(fit)
```

- The p-value is $\leq 0.05$, so we reject $H_0$ and conclude that the treatment has a significant effect on the change in SBP

## Post-hoc comparisons

- Since we found a significant effect of treatment, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another
- To account for the increased Type I error risk due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled

```{r}
# Performing post-hoc analysis with emmeans
emms <- emmeans(fit, ~ Treatment)
contrast(emms, method="pairwise", adjust="Bonferroni")
```

## Model diagnostics

- To assess the adequacy of the fitted model, we create two diagnostic plots:
  - **Normal Q-Q Plot**: Used to assess normality of the errors
  - **Residuals vs Fitted Plot**: Used to assess homoscedasticity (constant variance) for the errors

:::: {.columns}

::: {.column width="50%"}
```{r}
# Normal Q-Q
plot(fit, which = 2, main = "Normal Q-Q")
```
:::

::: {.column width="50%"}
```{r}
# Residuals vs Fitted
plot(fit, which = 1, main = "Residuals vs Fitted")
```
:::

::::

# Part II

## Nuisance variables

- Nuisance variables are factors that influence the response but are not of primary interest  
- Examples include age, baseline blood pressure, comorbidity, or study center  
- If not controlled, they can  
  - increase random variation → more noise, less precision  
  - introduce systematic differences between treatment groups → biased estimates of treatment effects  
- Randomization helps balance nuisance variables across treatments on average  
- Additional control can be achieved through blocking or covariate adjustment to separate their influence from the treatment effect

## Reducing residual variation: blocking

- Design stage
  - Group experimental units that are similar on a known nuisance factor (e.g., study center, sex, baseline severity)  
  - Randomize treatments within each block to ensure balance across levels of the nuisance variable  (this is known as an orthogonal design) 
  
- Analysis stage
  - Include the block term in the statistical model (two-way ANOVA) 

  $$Y_{ijk} = \mu + \tau_i + \beta_j + \varepsilon_{ijk}$$  

  - This analysis separates block effects from the residual error and therefore allows treatment effects to be estimated with increased precision  
  
## Example: stratified randomization

- Research question: do two new antihypertensive drugs reduce systolic blood pressure (SBP) more than control after 52 weeks?  
- Study population: 135 patients with baseline SBP ≥140 mmHg, classified into three hypertension grades  
  - Grade 1: 140–159 mmHg  
  - Grade 2: 160–179 mmHg  
  - Grade 3: ≥180 mmHg  
- Randomization: performed separately within each grade to ensure that all treatments are represented equally across hypertension categories (stratified randomization)  
- Treatments: Control, Drug A, Drug B (n = 45 per group; 15 per grade)  
- Outcome: change in SBP (mmHg) from baseline to week 52  

```{r}
set.seed(431)

# design
trt_levels  <- c("Control","DrugA","DrugB")
grades      <- c("Grade1","Grade2","Grade3")              # SBP-only grading
n_per_trt   <- 45                                          # divisible by 3 grades 
n_per_cell  <- n_per_trt / length(grades)                  
sd_eps      <- 8

# treatment means (overall), mmHg change over 12 weeks (plausible magnitudes)
trt_mean <- c(Control = -4, DrugA = -11, DrugB = -8)

# strong baseline grade effect on change (higher baseline → larger drop)
grade_effect <- c(Grade1 = 0, Grade2 = -6, Grade3 = -12)

# helper to simulate baseline SBP within each grade
r_sbp <- function(grade, n) {
  if (grade == "Grade1") rnorm(n, mean = 148, sd = 6)     # 140–159
  else if (grade == "Grade2") rnorm(n, mean = 168, sd = 6) # 160–179
  else rnorm(n, mean = 185, sd = 7)                        # ≥180
}

# build stratified dataset: equal n per grade × treatment
df_bp_strat <- do.call(
  rbind,
  lapply(grades, function(g) {
    do.call(
      rbind,
      lapply(trt_levels, function(t) {
        mu <- trt_mean[[t]] + grade_effect[[g]]
        n  <- n_per_cell
        data.frame(
          HypertensionGrade = g,
          Treatment = t,
          Baseline_SBP = r_sbp(g, n),
          SBP_change  = rnorm(n, mean = mu, sd = sd_eps)
        )
      })
    )
  })
)

df_bp_strat$HypertensionGrade <- factor(df_bp_strat$HypertensionGrade, levels = grades)
df_bp_strat$Treatment <- factor(df_bp_strat$Treatment, levels = trt_levels)
```

## Exploratory data analysis 

```{r}
eda_sum <- df_bp_strat %>%
  group_by(Treatment, HypertensionGrade) %>%
  summarise(
    n    = n(),
    mean = mean(SBP_change),
    sd   = sd(SBP_change),
    se   = sd / sqrt(n),
    tcrt = qt(0.975, df = n - 1),
    ci   = tcrt * se,
    .groups = "drop"
  )

ggplot(eda_sum, aes(x = Treatment, y = mean,
                    group = HypertensionGrade,
                    color = HypertensionGrade, shape = HypertensionGrade)) +
  geom_line() +
  geom_point(size = 3) +
  #geom_errorbar(aes(ymin = mean - ci, ymax = mean + ci), width = 0.12) +
  labs(
    x = "Treatment",
    y = "Mean change in SBP (mmHg)",
    title = "Interaction plot: Treatment by hypertension grade"
  ) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom")
```

## Results

:::: {.columns}

::: {.column width="50%"}

**One-way ANOVA (ignoring hypertension grade)**

```{r}
fit_oneway <- lm(SBP_change ~ Treatment, data = df_bp_strat)
anova(fit_oneway)
```
:::

::: {.column width="50%"}

**Two-way ANOVA (additive model)**

```{r}
# Residuals vs Fitted
fit_adj <- lm(SBP_change ~ Treatment + HypertensionGrade, data = df_bp_strat)
anova(fit_adj)
```
:::

::::

## Interpreting the ANOVA results

- The F statistic compares the variation explained by treatment with the unexplained residual variation  
  $$
  F = \frac{MS_{Treatment}}{MS_{Residual}}
  $$
- When hypertension grade is ignored, all between-grade differences are absorbed into the residual variance ($MS_{Residual}$)  
- Including hypertension grade in the model (two-way ANOVA) separates this systematic variation from the residual error  
- This lowers $MS_{Residual}$ and increases the F statistic for treatment — the treatment effect becomes easier to detect  
- The gain in precision arises because stratified randomization creates an orthogonal design in which treatment and grade effects can be estimated independently

# Backup slides

## Linear regression with effects coding

- Another common choice is effects (sum-to-zero) coding
- With this coding the regression coefficients map directly to the ANOVA parameters:

$$
Y_{ij} = \beta_0 + \beta_1 E_{1,ij} + \beta_2 E_{2,ij} + \varepsilon_{ij}
$$

where $E_1, E_2$ are the effect indicators for Control and DrugA (see table below).

| Treatment | Intercept | E1 | E2 |
|---|---:|:---:|:---:|
| Control | 1 | 1 | 0 |
| DrugA   | 1 | 0 | 1 |
| DrugB   | 1 | -1 | -1 |

- Interpretation:
  - Intercept ($\beta_0$): grand mean ($\mu$)
  - $\beta_1$ = $\tau_{\text{Control}}$ (deviation of Control from grand mean)
  - $\beta_2$ = $\tau_{\text{DrugA}}$ (deviation of DrugA from grand mean)
  - The remaining group's deviation follows from the sum-to-zero constraint: $\tau_{\text{DrugB}} = -\beta_1 - \beta_2$

## Estimated regression coefficients (effects coded model)

```{r}
#| echo: false
## R: effects (sum-to-zero) coding
contrasts(df_bp$Treatment) <- contr.sum(levels(df_bp$Treatment))
fit2 <- lm(SBP_change ~ Treatment, data = df_bp)
summary(fit2)
```
## Fixed vs random center effects – conceptual view

- In multi-center or blocked studies, center can be modeled as either fixed or random  
- **Fixed effect**: centers are specific and of intrinsic interest  
  $$
  Y_{ijk} = \mu + \tau_i + \beta_j + \varepsilon_{ijk}
  $$
  - One parameter per center (minus constraint)
  - Inference conditional on included centers
  - No assumption about distribution of $\beta_j$
- **Random effect**: centers are a random sample from a larger population  
  $$
  Y_{ijk} = \mu + \tau_i + b_j + \varepsilon_{ijk}, \quad b_j \sim N(0,\sigma_b^2)
  $$
  - One additional variance component ($\sigma_b^2$)
  - Inference averaged over the population of centers
- The choice determines the target of inference:  
  conditional (fixed) vs population-averaged (random)

## Fixed vs random center effects – statistical implications

- In balanced designs with orthogonality between treatment and center  
  → estimated treatment effects are identical under both models  
- In unbalanced designs  
  - Fixed effects give each center equal weight  
  - Random effects weight centers by precision (more efficient)
- Random effects provide partial pooling across centers  
  → smaller standard errors for treatment estimates on average  
- Fixed effects require estimating many parameters  
  → less efficient when many centers or small per-center sample sizes  
- Random effects introduce one additional assumption  
  → center effects follow a normal distribution with variance $\sigma_b^2$  
- Summary  

  | Aspect | Fixed | Random |
  |:--|:--|:--|
  | Inference scope | specific centers | population of centers |
  | Parameters | many ($\beta_j$) | one variance ($\sigma_b^2$) |
  | Weighting | equal across centers | precision-weighted |
  | Efficiency | lower if many small centers | higher via pooling |
  | Interpretation | conditional | marginal (population-averaged) |

