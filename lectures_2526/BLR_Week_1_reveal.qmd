---
title: "Beyond MLR - Week 1: Experimental Design I"
subtitle: "One-way FE/RE, ANOVA, coding, ICC"
author: "Dr. Douwe Postmus"
format:
  revealjs:
    theme: [default, custom-reveal.scss]
    slide-number: true
    toc: false
    slide-level: 2
    incremental: false
    code-overflow: wrap
    scrollable: true
    smaller: true
    width: 1280
    height: 720
    margin: 0.06
    max-scale: 2
    footer: "Beyond linear regression - week 1"
    logo: UMCG-logo.png
execute:
  warning: false
  message: false
  eval: true
  echo: false
---

```{r}
#| include: false
#| message: false
#| warning: false
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(knitr, rmarkdown, dplyr, ggplot2, emmeans)
```

## Introduction

- Welcome slide (to be completed later)

## Experimental research

- Experiment: study in which one or more factors are deliberately varied by assigning specific factor levels to experimental units in order to observe the effect on a response under controlled conditions

- Terminology:
  - Factor: variable the researcher controls or manipulates (e.g., drug, dose)
  - Levels (treatments): different values or categories of a factor (e.g., A, B, C; 10 mg, 20 mg)
  - Experimental unit: smallest unit that can be independently assigned a treatment
  - Response: outcome measured for each unit (e.g., blood pressure change)
  - Effect: difference in outcome caused by a change in the factor

## What do we mean by "effect"?

- An effect describes how the response changes when the level of a factor changes
- Effects can be expressed as differences (e.g., mean or risk difference) or ratios (e.g., risk or odds ratio)
- In an experiment, factors are deliberately varied to study their influence on the response
- The goal of experimental design is to ensure that:
  - the observed effects reflect the true influence of the factors rather than other sources of variation
  - these effects can be estimated precisely and efficiently, by minimizing unexplained variation through proper design choices

## Sources of unwanted variation

- Nuisance variables: influence the response but are not of primary interest (e.g., age, litter)
- They can:
  - increase random variation → more noise, less precision
  - cause systematic bias → distorted estimates of effects
- Types of bias if not controlled
  - Selection bias (confounding): systematic baseline differences between groups
  - Performance bias: different care or handling across treatments
  - Detection bias: outcome assessment influenced by knowledge of treatment

## Principles of experimental design

- Control: keep conditions as similar as possible except for the factors of interest
- Randomization: assign units to factor levels by chance → balances known and unknown nuisance variables
- Replication: include multiple experimental units per treatment — enables estimation of variability and statistical testing
- Blocking: group units by nuisance variables (e.g., litter, cage) and randomize within blocks — isolates treatment effects from nuisance effects

## Case Study — Antihypertensive Treatments

- Research question: Do two experimental drugs (Drug A, Drug B) reduce systolic blood pressure more than Control over 12 weeks?
- Design narrative: 120 patients with hypertension are randomly assigned to one of three groups (n = 40 each): Control, Drug A, or Drug B. The study is conducted under comparable conditions; outcome assessors are blinded to allocation.
- Outcome (response): change in systolic BP (mmHg) from baseline to week 12 (positive values indicate reduction)
- Factor (one-way): Treatment with three levels (Control, Drug A, Drug B)
- Experimental units: individual patients; one outcome per patient

```{r}
#| echo: false
# Prepare example data once for subsequent slides (hidden)
set.seed(123)
control <- rnorm(40, mean = 2,  sd = 10)
drugA   <- rnorm(40, mean = 20, sd = 10)
drugB   <- rnorm(40, mean = 5,  sd = 10)
df_bp <- data.frame(
  Treatment = factor(rep(c("Control","DrugA","DrugB"), each = 40),
                     levels = c("Control","DrugA","DrugB")),
  BP_Reduction = c(control, drugA, drugB)
)
```

## Exploratory Data Analysis

```{r}
#| echo: false
boxplot(BP_Reduction ~ Treatment, data = df_bp,
        col = c("gray85","skyblue","lightgreen"),
        ylab = "BP reduction (mmHg)", main = "BP reduction by treatment")
```

```{r}
#| echo: false
aggregate(BP_Reduction ~ Treatment, data = df_bp,
          FUN = function(x) c(Mean = round(mean(x),2), SD = round(sd(x),2)))
```

## Statistical model specification

To compare average blood pressure reduction across the three treatment groups (a single categorical factor), we use the one-way ANOVA model:

$$
\text{BP_Reduction}_{ij} = \mu + \tau_i + \varepsilon_{ij}
$$

- Model components:
  - $\text{BP_Reduction}_{ij}$: the blood-pressure reduction observed for the $j$-th subject in the $i$-th treatment group
  - $\mu$ (grand mean): the overall mean across groups (the average of the group means)
  - $\tau_i$ (treatment deviations): the systematic deviation of treatment $i$ from the grand mean; constrained so $\sum_i \tau_i = 0$
  - $\varepsilon_{ij}$ (residual error): the random deviation for subject $j$ in group $i$ that captures unexplained variation
- Statistical assumptions:
  - $\varepsilon_{ij}\sim\mathcal{N}(0,\sigma^2)$: errors are independent and identically normally distributed with mean zero and common variance $\sigma^2$ (homoscedasticity)


::: {.callout-tip title="Index nesting: groups (i) > members (j)"}
It is common practice to use earlier letters (e.g., $i$) for group- or factor-level indices and later letters (e.g., $j$) for observations within those groups. This reflects the nesting ($i$ outer, $j$ inner) and makes summation notation natural (e.g., summing over $j$ for a fixed $i$):

$$Y_{ij} = \mu + \tau_i + \varepsilon_{ij}$$

Here $i$ indexes the group (treatment) and $j$ the individual inside that group, so $Y_{ij}$ is the $j$-th subject in group $i$.
:::

## Estimation using linear regression

- A one-way ANOVA model can be expressed as a linear regression with a categorical predictor, allowing us to use the regression framework for estimation and hypothesis testing
- Using dummy coding with the control group as reference, the statistically equivalent regression model is:

$$
Y_{ij} = \beta_0 + \beta_1 D_{1,ij} + \beta_2 D_{2,ij} + \varepsilon_{ij}
$$

where $D_1, D_2$ are the dummy indicators for DrugA and DrugB (see table below).

| Treatment | Intercept | D1 (DrugA) | D2 (DrugB) |
|---|---:|:---:|:---:|
| Control | 1 | 0 | 0 |
| DrugA   | 1 | 1 | 0 |
| DrugB   | 1 | 0 | 1 |

- Interpretation:
  - Intercept ($\beta_0$): estimated mean for Control
  - $\beta_1$: estimated difference mean(DrugA) − mean(Control)
  - $\beta_2$: estimated difference mean(DrugB) − mean(Control)

## Estimated regression coefficients (dummy coded model)

```{r}
#| echo: false
# R (refresher): reference coding with Control as baseline
contrasts(df_bp$Treatment) <- contr.treatment(levels(df_bp$Treatment))
fit <- lm(BP_Reduction ~ Treatment, data = df_bp)
summary(fit)
```

## Mapping to the ANOVA model parameters

- Intercept and betas → group means:
  - mean(Control) = $\beta_0$
  - mean(DrugA)   = $\beta_0 + \beta_1$
  - mean(DrugB)   = $\beta_0 + \beta_2$

- Grand mean (ANOVA intercept):
  $\mu = \frac{\text{mean(Control)} + \text{mean(DrugA)} + \text{mean(DrugB)}}{3} = \beta_0 + \frac{\beta_1 + \beta_2}{3}$

- Treatment deviations (ANOVA $\tau_i$) written in terms of the regression coefficients:
  - $\tau_{\text{Control}} = \text{mean(Control)} - \mu = -\frac{\beta_1 + \beta_2}{3}$
  - $\tau_{\text{DrugA}}   = \text{mean(DrugA)} - \mu = \beta_1 - \frac{\beta_1 + \beta_2}{3}$
  - $\tau_{\text{DrugB}}   = \text{mean(DrugB)} - \mu = \beta_2 - \frac{\beta_1 + \beta_2}{3}$

## Estimated marginal means (EMMs)

- Regression coefficients describe differences relative to a reference group
- Estimated marginal means (EMMs) express the same model in terms of predicted group means
- EMMs provide a direct and interpretable summary of group outcomes implied by the model
- In a one-way ANOVA model, the EMMs equal the observed group means
  - This follows directly from least-squares estimation in that design
- In more complex models, EMMs give adjusted or conditional means that make comparisons fairer
  - With covariates (ANCOVA): EMMs adjust group means to a common covariate value, such as the overall mean
  - With interactions: EMMs provide conditional means for specific combinations of factors, allowing group comparisons at chosen settings

```{r}
#| echo: false
# Compute and display estimated marginal means
emms <- emmeans(fit, ~ Treatment)
summary(emms)
```

## Global hypothesis testing

- Hypotheses:
  - Null ($H_0$): all group means are equal ($\tau_1 = \tau_2 = \tau_3 = 0$)
  - Alternative ($H_1$): at least one group mean differs (at least one $\tau_i \ne 0$)

 - Tested using the F-test from the ANOVA table:

```{r}
#| echo: false
anova(fit)
```

- The p-value is $\leq 0.05$, so we reject $H_0$ and conclude that the treatment has a significant effect on blood pressure reduction

## Post-hoc comparisons

- Since we found a significant effect of treatment, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another
- To account for the increased Type I error risk due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled

```{r}
# Performing post-hoc analysis with emmeans
emms <- emmeans(fit, ~ Treatment)
contrast(emms, method="pairwise", adjust="Bonferroni")
```

## Model Diagnostics

- To assess the adequacy of the fitted model, we create two diagnostic plots:
  - **Normal Q-Q Plot**: Used to assess normality of the errors
  - **Residuals vs Fitted Plot**: Used to assess homoscedasticity (constant variance) for the errors

:::: {.columns}

::: {.column width="50%"}
```{r}
# Normal Q-Q
plot(fit, which = 2, main = "Normal Q-Q")
```
:::

::: {.column width="50%"}
```{r}
# Residuals vs Fitted
plot(fit, which = 1, main = "Residuals vs Fitted")
```
:::

::::

## Reporting

> A one-way ANOVA was conducted to compare the effect of three treatments on blood pressure reduction. There was a statistically significant effect of treatment on blood pressure reduction [F(2, 117) = 43.71, p < 0.001]. Estimated marginal means indicated that Drug A (M = 19.93 mm Hg, 95% CI = [17.11 mm Hg, 22.76 mm Hg]) resulted in significantly greater blood pressure reduction than both the Control group (M = 2.45 mm Hg, 95% CI = [-0.37 mm Hg, 5.28 mm Hg], p < 0.001) and Drug B (M = 5.08 mm Hg, 95% CI = [2.26 mm Hg, 7.90 mm Hg], p < 0.001). There was no significant difference between the Control group and Drug B (p = 0.586). P-values were adjusted for multiple testing using the Bonferroni correction.

## Linear regression with effects coding

- Another common choice is effects (sum-to-zero) coding
- With this coding the regression coefficients map directly to the ANOVA parameters:

$$
Y_{ij} = \beta_0 + \beta_1 E_{1,ij} + \beta_2 E_{2,ij} + \varepsilon_{ij}
$$

where $E_1, E_2$ are the effect indicators for Control and DrugA (see table below).

| Treatment | Intercept | E1 | E2 |
|---|---:|:---:|:---:|
| Control | 1 | 1 | 0 |
| DrugA   | 1 | 0 | 1 |
| DrugB   | 1 | -1 | -1 |

- Interpretation:
  - Intercept ($\beta_0$): grand mean ($\mu$)
  - $\beta_1$ = $\tau_{\text{Control}}$ (deviation of Control from grand mean)
  - $\beta_2$ = $\tau_{\text{DrugA}}$ (deviation of DrugA from grand mean)
  - The remaining group's deviation follows from the sum-to-zero constraint: $\tau_{\text{DrugB}} = -\beta_1 - \beta_2$

## Estimated regression coefficients (effects coded model)

```{r}
#| echo: false
## R: effects (sum-to-zero) coding
contrasts(df_bp$Treatment) <- contr.sum(levels(df_bp$Treatment))
fit2 <- lm(BP_Reduction ~ Treatment, data = df_bp)
summary(fit2)
```
