---
title: "Beyond MLR Lab 3: Replicated Randomized Block Designs"
format: 
  html:
    toc: true       # Enable the table of contents
    toc-depth: 3    # Set the depth of headers included in the ToC (e.g., H1, H2, H3)
    toc-location: right   # Optional: Can be left, right, or floating    
    embed-resources: true
  pdf:
    toc: false
execute:
  warning: false
  message: false
  eval: false    
---

::: {.callout-note icon=false title="Preliminary setup"}
In this lab, we will use the R packages `ggplot2`, `dplyr`, `emmeans`, `lmerTest`, and `broom.mixed`. You can use the script below to automatically install and load them using the `pacman` package.

```{r}
# Check whether pacman is available and install if needed
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")

# Use pacman to install (if needed) and load the required packages
pacman::p_load(dplyr, ggplot2, emmeans, lmerTest, broom.mixed)
```
:::

In the previous lab, we considered a traditional randomized block design without replication, where each treatment was applied once within each block (laboratory). This design allowed us to control for variability between laboratories and efficiently estimate the effect of treatment. However, a key limitation of this approach is that it does not allow us to assess the extent to which the effect of treatment varies across blocks, a concept known as **interaction**.

An interaction occurs when the effect of one factor (e.g., treatment) is not consistent across levels of another factor (e.g., laboratory). In other words, the effect of a treatment might vary depending on the laboratory conditions. Replicating the treatments within each block allows us to estimate these interaction effects and better understand the variability in treatment outcomes across different settings.

In this lab, we extend the randomized block design by adding replication within blocks, so we can estimate the variability within each block and assess the extent to which treatment effects vary across blocks.

# Example: Testing Wound Healing Treatments with Replication and Treatment-by-Block Interactions

To allow for replication and potential interaction between treatments and laboratories, we update the simulation code from the previous lab and run it to create an updated dataset: 

```{r}
# Set seed for reproducibility
set.seed(123)

# Define blocks (laboratories) and treatments
blocks <- factor(paste0("Laboratory ", rep(1:5, each = 6)))  # Labs 1 to 5, now with 6 observations per lab
treatments <- factor(rep(c("A", "B", "C"), each = 2, times = 5))  # Replication within blocks

# Simulate block effects and treatment effects
block_effect <- rnorm(5, mean = 0, sd = 2)  # Random effect for each block
treatment_effect <- c(A = 5, B = 7, C = 6)  # Fixed effects for treatments

# Simulate interaction terms (Treatment by Laboratory)
interaction_effect <- matrix(rnorm(15, mean = 0, sd = 1), nrow = 5, ncol = 3)

# Create data frame
data_rep_block <- data.frame(
  Laboratory = blocks,
  Treatment = treatments,
  WoundHealing = NA
)

# Assign responses with interaction terms
for (i in 1:nrow(data_rep_block)) {
  b <- as.numeric(data_rep_block$Laboratory[i])
  t <- data_rep_block$Treatment[i]
  t_index <- match(t, c("A", "B", "C"))
  data_rep_block$WoundHealing[i] <- 
    50 + block_effect[b] + treatment_effect[t] + interaction_effect[b, t_index] + rnorm(1, mean = 0, sd = 1)
}
```

The R code chunk above simulates wound healing observations (measured on a continuous scale, where higher values indicate better healing) for 30 cell culture plates, divided across five laboratory facilities. Each treatment (A, B, and C) is applied to two cell culture plates within each laboratory, introducing replication. The results are stored in the data frame `data_rep_block`, which consists of the following three variables:

- `Laboratory`: A factor variable indicating the laboratory facility.
- `Treatmment`: A factor variable indicating the applied treatment. 
- `WoundHealing`: A numeric variable representing the degree of wound healing on a continuous scale.

## Exploratory Data Analysis

To explore the data and investigate the presence of a potential interaction between treatments and laboratories, we create an  **interaction plot**. An interaction plot is a graphical tool that helps visualize whether the effect of one factor (in this case, treatment) depends on the levels of another factor (in this case, laboratory). Specifically, it shows how the mean response (wound healing) for each treatment varies across different laboratories. If the lines on the interaction plot are parallel, this suggests there is no interaction, meaning the treatment effect is consistent across laboratories. If the lines are not parallel, this indicates a potential interaction, meaning the effect of treatment differs depending on the laboratory.

```{r}
# Calculate mean Wound Healing for each Treatment-Laboratory combination
mean_data <- data_rep_block %>%
  group_by(Laboratory, Treatment) %>%
  summarise(Mean_WoundHealing = mean(WoundHealing))

# Display the produced summary table with the group means
mean_data

# Create an interaction plot
ggplot(mean_data, aes(x = Treatment, y = Mean_WoundHealing, group = Laboratory, color = Laboratory)) +
  geom_point(size = 3) +
  geom_line() +
  labs(title = "Interaction Plot",
       y = "Mean Wound Healing Measure",
       x = "Treatment") +
  theme_minimal()
```

::: {.callout-important icon=false title="Question"}
Does the interaction plot indicate a potential interaction between treatment and laboratory?
:::

::: {.callout-important icon=false title="Question"}
Does the plot suggest any differences in the overall effectiveness of the treatments (i.e., main effect of treatment) across all laboratories?
:::

::: {.callout-important icon=false title="Question"}
What does the plot suggest about variability between laboratories? Are some laboratories consistently higher or lower in wound healing across all treatments?
:::

## A Mixed Effects Model for the Randomized Block Design

As in the previous lab, laboratory is included as a random effect and treatment as a fixed effect in the model. The key new feature is the **treatment-by-laboratory interaction** term, which is also modeled as a random effect.

To understand why the interaction term must also be modeled as random, we need to consider the nature of random effects in this context. Since laboratory is treated as a random effect, we are assuming that the laboratories in the experiment represent a random sample from a larger population of possible laboratory conditions. This means that we are not just interested in the specific laboratories in the study, but in how the treatments would perform across any set of laboratories with varying conditions.

When we include an interaction term between treatment and laboratory, we are asking whether the effect of each treatment depends on the laboratory environment. If we had modeled laboratory as a fixed effect (i.e., we were only interested in those specific laboratories), the interaction could also be treated as fixed. However, because laboratory is random, the interaction must also be treated as random to reflect the idea that the variability in treatment effects across laboratories applies not just to the specific laboratories in the study, but to any laboratory from the broader population.

In other words, by modeling the interaction as random, we are assuming that the variation in treatment effects is not unique to the five laboratories in the study, but rather represents random fluctuations in treatment effectiveness that could occur in any laboratory setting. This approach allows us to generalize our findings beyond the laboratories in the experiment, making the model more realistic and applicable to a wider range of scenarios.

### Model Specification

The mixed-effects model for the replicated randomized block design is specified as:

$$
Y_{ijk} = \mu + \tau_i + b_j + (tb)_{ij} + \epsilon_{ijk}
$$

where:

- $Y_{ijk}$: Response (wound healing) for the $k$-tjh replicate of Treatment $i$ in Laboratory $j$.
- $\mu$: Overall mean response
- $\tau_{i}$: Fixed effect of Treatment $i$.
- $b_{j}$:Random effect of Laboratory $j$, assumed to follow a normal distribution with mean zero and variance $\sigma^2_{b}$.
- $(tb)_{ij}$: Random interaction effect between treatment $i$ and Laboratory $j$, assumed to follow a normal distribution with mean zero and variance $\sigma^2_{tb}$.
- $\epsilon_{ijk}$: Random error term, assumed to follow a normal distribution with mean zero and variance $\sigma^2$.

### Model Estimation

Similar as in the previous lab, we fit the mixed effects model using the `lmer()` function from the `lmeTest` package:

```{r}
options(contrasts = c("contr.sum", "contr.poly"))  # Effects coding

model_block <- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory), data = data_rep_block)
summary(model_block)
```

Let’s break down the model formula `WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory)`:

- `WoundHealing ~ Treatment`: This specifies that `WoundHealing` is the outcome variable and that `Treatment` is included as a fixed effect to estimate differences between the three treatments.
- `(1 | Laboratory)`: This specifies the random effect for `laboratory`, representing laboratory-specific deviations from the overall mean.
- `(1 | Treatment:Laboratory)`: This specifies the random interaction term between `Treatment` and `Laboratory`.

### Understanding the model output

When we run `summary(model_block)`, the output provides two main components: **fixed effects** and **variance components**. Together, these summarize the estimated treatment differences and the variability captured by the random effects.

#### Fixed effects

- The **intercept** represents the overall mean wound-healing measure across all treatments and laboratories (estimated as 56.47)  
- The coefficients for **Treatment A** (-1.04) and **Treatment B** (+1.03) indicate how each treatment’s mean differs from the overall mean  
- With effects coding, the coefficients must sum to zero, so the mean for **Treatment C** is slightly below the overall mean (≈ -0.01)  

These coefficients represent the **average treatment effects** across all laboratories, after adjusting for differences in baseline wound-healing levels between laboratories.

#### Variance components

The model includes two random terms that capture distinct sources of variability:

- The **laboratory-level random intercept** (variance = 1.446) represents systematic differences in average wound healing between laboratories  
- The **treatment-by-laboratory interaction** (variance = 0.475) captures how treatment effects vary across laboratories  
- The **residual variance** (0.909) represents unexplained variability within each treatment–laboratory combination  

These components can be summarized and interpreted using the **intra-class correlation coefficient (ICC)**, which expresses how much of the total unexplained variance arises from each random effect:

```{r}
# Extract variance components from the fitted model and
# square the standard deviations to obtain variances
vc <- tidy(model_block, effects = "ran_pars") |>
  mutate(variance = estimate^2)
vc

# Compute ICCs from the variance components
var_total <- sum(vc$variance)
icc_lab <- vc$variance[vc$group == "Laboratory"] / var_total
icc_int <- vc$variance[vc$group == "Treatment:Laboratory"] / var_total
icc_lab
icc_int
```

**Explanation:** The `tidy()` function from the `broom.mixed` package takes complex model output and organizes it into a standardized tidy data frame, where each row corresponds to one model parameter (e.g., fixed effect, random-effect variance, residual variance). Here, we use it to extract the random-effect variance components from the fitted model object (argument `effects = "ran_pars"`)

- The **laboratory ICC** quantifies how strongly wound-healing outcomes are correlated within the same laboratory (reflecting baseline lab differences)
- The **interaction ICC** quantifies how much of the total variability arises from differences in treatment effects across laboratories

Together, these ICCs describe how hierarchical structure influences precision: the larger the ICCs, the more variability stems from between-lab and treatment–lab differences rather than residual error.

::: {.callout-question icon=false title="Question"}
How large is the ICC for the laboratory effect? What does this tell us about differences in baseline wound-healing across labs?
:::

::: {.callout-question icon=false title="Question"}
How large is the ICC for the treatment-by-laboratory interaction? Does this suggest that treatment effects vary meaningfully across laboratories, or are they relatively consistent?
:::

### Assessing the fixed effect of Wound healing treatment

The fixed effect of wound healing treatment can be assessed by examining the ANOVA table from the mixed-effects model. This shows whether the average wound-healing differs significantly across treatments, after accounting for variability between laboratories and treatment–laboratory interactions.

```{r}
# Extract the ANOVA table
anova(model_block)
```

::: {.callout-question icon=false title="Question"}
Inspect the ANOVA table and report whether the overall treatment effect is statistically significant.
:::

::: {.callout-question icon=false title="Exercise"}
Use the `emmeans` package to perform pairwise comparisons between treatments and explore which pairs differ.
:::

### Model diagnostics

The process of performing model diagnostics for the replicated randomized block design is the same as for the traditional randomized block design. Therefore, we refer to the previous lab for detailed instructions on assessing model assumptions and performing diagnostic checks.

## Fitting a two-way additive ANOVA without the random interaction term

To explore how the inclusion of the random treatment-by-laboratory interaction impacts inference for the fixed effect of wound healing treatment, we now fit a simpler mixed-effects model that includes only a random intercept for laboratory. This corresponds to a two-way additive ANOVA with wound healing treatment as a fixed effect and laboratory as a random effect.

```{r}
# Fit the model without random interaction term
model_block_simple <- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_rep_block)
summary(model_block_simple)
anova(model_block_simple)

# Print the results of the model with random interction term
summary(model_block)
anova(model_block)
```

::: {.callout-question icon=false title="Question"}
Inspect the model summaries and ANOVA tables for both models. What do you obverve?
:::

#### Explanation

- The simpler model assumes that treatment effects are identical in every laboratory
  - All differences between labs are captured by a single random intercept
  - This ignores any lab-to-lab variation in how the treatments perform
  - As a result, treatment effects appear more precise (smaller SEs and lower p-values)
- The full model allows treatment effects to differ somewhat across laboratories by including a random `Treatment×Laboratory` term
  - This means that not all laboratories show exactly the same treatment differences
  - The model therefore recognizes treatment-by-lab heterogeneity and treats it as an additional source of uncertainty
  - As a result, the p-value for the overall treatment effect becomes slightly larger because part of the between-treatment variation is now explained by random treatment-by-lab differences rather than by the fixed treatment effect itself

In short, the mean treatment effect reflects the average across all laboratories, but when an interaction is included and only few labs are available, that average is more uncertain because we have limited information about between-lab differences. In this example, the difference in p-values from both models is very minor because the interaction ICC is low (0.167), indicating that only a small proportion of the total variance is due to treatment-by-lab heterogeneity. In situations where the interaction ICC is larger, the treatment effects will appear less certain, with larger standard errors and higher p-values, because a greater share of the total variation is attributed to differences in treatment performance across laboratories.
