---
title: "Beyond MLR Lab 5: multi-level analysis of cross-sectional observational data"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    code-overflow: wrap
    embed-resources: true
  pdf:
    toc: false
execute:
  warning: false
  message: false
  eval: false
  echo: true
---

::: {.callout-note icon=false title="Preliminary setup"}
In this lab, we will use the R packages `ggplot2`, `dplyr`, `emmeans`, and `lmerTest`. You can use the script below to automatically install and load them using the `pacman` package.

```{r}
# Check whether pacman is available and install if needed
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")

# Use pacman to install (if needed) and load the required packages
pacman::p_load(dplyr, ggplot2, emmeans, lmerTest)
```
:::

# Chicago AirBnB Data

The Chicago Airbnb dataset was compiled by Trinh and Ameri as part of a course project at St. Olaf College and is included with the book Beyond Multiple Linear Regression by Roback and Legler (2021). It contains information on 1,561 Airbnb listings in Chicago, including details such as nightly price, overall satisfaction rating, number of reviews, and various other listing characteristics. Additionally, the dataset includes neighborhood-level information, such as ratings for walkability, access to public transit, and bikeability, providing valuable context for the listings' locations.

The dataset is available on Brightspace under the name `airbnb.csv`. It contains the following variables:

* price: the nightly price of the listing (in USD)
* overall_satisfaction: the listing's average rating, on a scale from 1 to 5
* reviews: number of user reviews the listing has
* room_type: the type of listing (eg: Shared room)
* accommodates: number of guests the listing accommodates
* bedrooms: the number of bedrooms the listing has
* minstay: the minimum number of nights to stay in the listing
* neighborhood: the neighborhood in which the listing is located
* WalkScore: the neighborhood's rating for walkability (0 - 100)
* TransitScore: the neighborhood's rating for access to public transit (0 - 100)
* BikeScore: the neighborhood's rating for bikeability (0 - 100)

## Exploratory Data Analysis

Let's load the data and use the `str()` function to inspect the structure of the dataset.

```{r}
# Load the Chicago AirBnB data. Note that the call below assumes the csv file is placed in the 'data' folder directly above the root folder of the project. Update the string as needed if the file is located elsewhere.
chicago_airbnb <- read.csv("data/airbnb.csv")

# Convert all character variables into factors
chicago_airbnb <- chicago_airbnb |>
  mutate_if(is.character, as.factor)

# Inspect the structure of the dataset
str(chicago_airbnb)
```

This initial inspection makes clear that the Airbnb dataset has a hierarchical structure: 1,561 individual listings are nested within 43 neighborhoods. While the dataset also includes a `district` variable that groups neighborhoods into 9 broader districts, for educational purposes we will treat this as a two-level hierarchical structure with listings (level 1) nested within neighborhoods (level 2), ignoring the higher-level clustering of neighborhoods into districts.

### Grouping structure

To get a better feeling for the grouping structure, we create a summary table showing the number of listings within each neighborhood and visualize it with a bar chart:

```{r}
# Create a summary table showing listings per neighborhood
neighborhood_summary <- chicago_airbnb |>
  group_by(neighborhood) |>
  summarise(num_listings = n(), .groups = "drop") |>
  arrange(desc(num_listings))

# Create a bar chart showing listings per neighborhood (top 20)
neighborhood_summary |>
  top_n(20, num_listings) |>
  ggplot(aes(x = reorder(neighborhood, num_listings), y = num_listings)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  coord_flip() +
  labs(title = "Number of Listings per Neighborhood (Top 20)",
       x = "Neighborhood",
       y = "Number of Listings") +
  theme_minimal()
```

Explanation:

* `group_by(neighborhood)`: groups the data by neighborhood so that we can count listings within each neighborhood.
* `n()`: counts the total number of listings within each neighborhood.
* `arrange(desc(num_listings))`: sorts the table by the number of listings in descending order.
* `top_n(20, num_listings)`: selects the 20 neighborhoods with the most listings for visualization.
* `reorder(neighborhood, num_listings)`: reorders the neighborhood factor levels based on the values of `num_listings`, arranging neighborhoods from lowest to highest number of listings for easier interpretation.

::: {.callout-important icon=false title="Question"}
Which neighborhoods have the most Airbnb listings? Is there substantial variation in the number of listings across neighborhoods?
:::

### Outcome variable

Next, we create a histogram to visualize the distribution of the outcome variable `price`:

```{r}
# Create a histogram of price
ggplot(chicago_airbnb, aes(x = price)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Listing Prices",
       x = "Nightly Price (USD)",
       y = "Frequency") +
  theme_minimal()
```

While normality of the outcome is not strictly required for a mixed-effects model, transforming a right-skewed variable like price can help stabilize variance and linearize relationships. We therefore create a new variable, `log_price`, to store the log-transformed prices:

```{r}
# Log-transform the price variable
chicago_airbnb <- chicago_airbnb |>
  mutate(log_price = log(price))
```

### Variance components

We also want to get a sense of the variability in the listing prices within and between neighborhoods. For this, we are going to randomly select 10 neighborhoods and create a scatter plot with the log-transformed price on the y-axis and the neighborhood on the x-axis:

```{r}
# Set seed for reproducibility
set.seed(123)

# Randomly select 10 unique neighborhoods
random_neighborhoods <- sample(unique(chicago_airbnb$neighborhood), size = 10)

# Filter the data to include only the randomly selected neighborhoods
random_neighborhood_data <- chicago_airbnb |>
  filter(neighborhood %in% random_neighborhoods)

# Calculate the average log_price for each neighborhood
neighborhood_avg_price <- random_neighborhood_data |>
  group_by(neighborhood) |>
  summarise(avg_log_price = mean(log_price, na.rm = TRUE), .groups = "drop")

# Calculate the overall grand mean across all neighborhoods
grand_mean <- mean(chicago_airbnb$log_price, na.rm = TRUE)

# Create scatter plot with jittered observations
ggplot(random_neighborhood_data, aes(x = reorder(neighborhood, log_price, FUN = mean), y = log_price)) +
  geom_hline(yintercept = grand_mean, linetype = "solid", color = "black", linewidth = 1) +
  geom_jitter(alpha = 0.3, width = 0.2, size = 1, color = "gray60") +
  geom_point(data = neighborhood_avg_price, aes(x = neighborhood, y = avg_log_price),
             size = 4, shape = 18, color = "red") +
  labs(title = "Variation in listing prices: within and between neighborhoods",
       subtitle = "Points = individual listings; Diamonds = neighborhood means; Solid line = grand mean (all data)",
       x = "Neighborhood (ordered by mean log price)",
       y = "Log-transformed price") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

::: {.callout-important icon=false title="Question"}
What does this plot suggest about the variability in listing prices within and between neighborhoods?
:::

### Covariate effects

Before fitting models with covariates, it is useful to explore the relationships between potential predictors and the outcome variable. Let us examine how some subject-level characteristics relate to listing prices.

First, we will look at the relationship between the number of reviews and log-transformed price:

```{r}
# Scatterplot with smooth line for reviews vs log_price
ggplot(chicago_airbnb, aes(x = reviews, y = log_price)) +
  geom_jitter(alpha = 0.2, width = 0.1, color = "gray60") +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue", linewidth = 1.5) +
  labs(title = "Relationship between number of reviews and listing price",
       x = "Number of reviews",
       y = "Log-transformed price") +
  theme_minimal()
```

Next, let us examine how listing prices vary across different room types:

```{r}
# Boxplot for room_type vs log_price
ggplot(chicago_airbnb, aes(x = room_type, y = log_price, fill = room_type)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Listing prices by room type",
       x = "Room type",
       y = "Log-transformed price") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))
```

::: {.callout-important icon=false title="Coding exercise"}
Create similar visualizations to explore the relationships between:

1. Overall satisfaction rating and log-transformed price (scatterplot with smooth line)
2. Number of bedrooms and log-transformed price (boxplot)

What patterns do you observe? Do higher satisfaction ratings and more bedrooms tend to be associated with higher or lower prices?
:::

## Random intercept model

To model the variability in listing prices within and between neighborhoods, we start by fitting a random intercept model to account for the nesting of listings within neighborhoods. This model is specified as follows:

```{r}
# Fit the random intercept model
random_intercept_model <- lmer(log_price ~ 1 + (1 | neighborhood), data = chicago_airbnb)
summary(random_intercept_model)
```

::: {.callout-important icon=false title="Question"}
Based on the estimated variance components, what can you conclude about the relative contributions of within-neighborhood and between-neighborhood variability to the total variability in listing prices?
:::

## Extending the random intercept model with subject-level variables

As a second step, we extend the random intercept model with subject-level variables. To facilitate the interpretation of the model coefficients, we start by setting the coding scheme for categorical variables to effects coding. We also center the numerical variables by subtracting the mean value from each observation. This step is important to reduce multicollinearity, improve numerical stability, and make the intercept more interpretable.

```{r}
# Use effects coding for the categorical variables
options(contrasts = c("contr.sum", "contr.poly"))

# Center the continuous subject-level variables
chicago_airbnb <- chicago_airbnb |>
  mutate(overall_satisfaction_c = scale(overall_satisfaction, scale = FALSE),
         accommodates_c = scale(accommodates, scale = FALSE),
         bedrooms_c = scale(bedrooms, scale = FALSE),
         minstay_c = scale(minstay, scale = FALSE))
```

Next, we fit the random intercept model with the subject-level variables included:

```{r}
# Fit the random intercept model with subject-level variables
random_intercept_model_L1variables <- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + (1 | neighborhood), data = chicago_airbnb)
summary(random_intercept_model_L1variables)

# Display the coding scheme for the room_type variable
contrasts(chicago_airbnb$room_type)

# Obtain the ANOVA table for the subject-level variables
anova(random_intercept_model_L1variables)
```

::: {.callout-important icon=false title="Question"}
How does centering the continuous variables affect the interpretation of the intercept?
:::

::: {.callout-important icon=false title="Question"}
How does the inclusion of individual-level variables affect the estimated variance components? More specifically, does the inclusion of individual-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?
:::

::: {.callout-important icon=false title="Question"}
Which of the individual-level variables are significantly associated with listing prices? How do you interpret the coefficients for these variables?
:::

## Including context-level variables

As a third step, we extend the previously fitted model with context-level variables. We start by centering the context-level variables:

```{r}
# Center the context-level variables
chicago_airbnb <- chicago_airbnb |>
  mutate(WalkScore_c = scale(WalkScore, scale = FALSE),
         TransitScore_c = scale(TransitScore, scale = FALSE),
         BikeScore_c = scale(BikeScore, scale = FALSE))
```

Next, we fit the random intercept model with both subject-level and context-level variables included:

```{r}
# Fit the random intercept model with subject-level and context-level variables
random_intercept_model_L1L2variables <- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)
summary(random_intercept_model_L1L2variables)

# Obtain the ANOVA table
anova(random_intercept_model_L1L2variables)
```

::: {.callout-important icon=false title="Question"}
How does the inclusion of context-level variables affect the estimated variance components? More specifically, does the inclusion of context-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?
:::

### Model selection using stepwise elimination

Not all the context-level variables included in the model are significant predictors of listing prices. To obtain a more parsimonious model, we can use the `step()` function from the `lmerTest` package to perform a backward elimination of the fixed-effect terms.

The `step()` function uses **F-tests** to systematically test which terms can be removed without significantly worsening model fit. Here's how it works:

**Backward elimination process:**

1. Starting with the full model, the function computes F-tests for all marginal terms (i.e., terms that can be dropped while respecting the hierarchy of terms in the model)
2. It identifies the term with the highest (least significant) p-value from the F-tests
3. If that p-value exceeds the significance threshold (default α = 0.05), the term is removed
4. The process repeats with the new reduced model until no more terms can be removed

The F-tests used by `step()` are based on comparing models using Satterthwaite's approximation for the denominator degrees of freedom, which is appropriate for mixed models.

```{r}
# Perform stepwise selection to identify the most important predictors
step(random_intercept_model_L1L2variables)
```

::: {.callout-important icon=false title="Question"}
Which individual-level and context-level variables are retained in the final model after the stepwise selection procedure?
:::

## Exploring cross-level interactions

Finally, we explore the possibility of cross-level interactions between individual-level and context-level variables.

The relationship between the overall satisfaction rating of an individual listing and its price may depend on neighborhood characteristics such as their walkability and access to public transit. For instance, higher satisfaction ratings might have a stronger effect on prices in less walkable or transit-accessible neighborhoods, where positive reviews could help compensate for the disadvantages of limited walkability or transit options. In contrast, in neighborhoods with high walkability or access to public transit ratings, these location-based amenities might already drive prices, reducing the added impact of satisfaction ratings.

To formally test whether cross-level interactions improve model fit, we use **likelihood ratio tests (LRT)** to compare nested models with and without the interaction term.

**Likelihood ratio test basics:**

The likelihood ratio test compares two nested models:

* **Null model (restricted)**: the model without the interaction term
* **Alternative model (full)**: the model with the interaction term

The test statistic is calculated as:
$$\text{LR} = -2 \times (\text{log-likelihood of restricted model} - \text{log-likelihood of full model})$$

Under the null hypothesis (that the interaction term is not needed), this test statistic follows a chi-square distribution with degrees of freedom equal to the difference in the number of parameters between the two models. A significant result (p < 0.05) indicates that the model with the interaction provides a significantly better fit to the data.

**Important note about ML vs. REML:**

When comparing models with different fixed effects using likelihood ratio tests, we must use **ML (Maximum Likelihood)** rather than **REML (Restricted Maximum Likelihood)**. This is because REML likelihoods are not directly comparable across models with different fixed effect structures. We specify `REML = FALSE` when fitting the models for LRT comparisons.

Let's test whether the `overall_satisfaction × WalkScore` interaction significantly improves model fit:

```{r}
# Fit the base model without any interactions (using ML)
model_no_interaction <- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb, REML = FALSE)

# Fit model with WalkScore interaction (using ML)
model_interaction_walk <- lmer(log_price ~ overall_satisfaction_c * WalkScore_c + room_type + accommodates_c + bedrooms_c + minstay_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb, REML = FALSE)

# Likelihood ratio test for WalkScore interaction
anova(model_no_interaction, model_interaction_walk)
```

::: {.callout-important icon=false title="Question"}
Based on the likelihood ratio test, does the `overall_satisfaction × WalkScore` interaction significantly improve model fit? What does this tell you about how the relationship between satisfaction ratings and listing prices varies across neighborhoods with different walkability levels?
:::

::: {.callout-important icon=false title="Coding exercise"}
Following the example above, test whether the `overall_satisfaction × TransitScore` interaction significantly improves model fit.

1. Fit a model that includes the `overall_satisfaction × TransitScore` interaction (remember to use `REML = FALSE`)
2. Perform a likelihood ratio test comparing this model to the base model without interactions
3. Interpret the results: Does the interaction significantly improve model fit? What does this suggest about how satisfaction ratings relate to prices in neighborhoods with different levels of transit accessibility?
:::

::: {.callout-note icon=false title="F-tests vs. Likelihood Ratio Tests for fixed effects"}
In this lab, we've used two different approaches for testing fixed effects:

**F-tests (via `step()` function):**

* Based on Satterthwaite's approximation for degrees of freedom
* Work with REML estimation (the default for `lmer()`)
* Provide approximate p-values that account for the uncertainty in variance component estimates
* Particularly useful for automated model selection procedures
* Generally more conservative (higher p-values) due to the approximation

**Likelihood Ratio Tests (via `anova()` comparing models):**

* Based on comparing the likelihoods of nested models
* Require ML estimation (`REML = FALSE`) for comparing models with different fixed effects
* Provide exact test statistics following a chi-square distribution
* More appropriate for formal hypothesis testing of specific effects
* Often used for testing interactions or other theory-driven model comparisons

**Which should you use?**

Both approaches are valid and will generally lead to similar conclusions. The choice often depends on context:

* Use **F-tests** (with REML) when you want to retain the better variance component estimates and are performing exploratory model selection
* Use **LRTs** (with ML) when you want to formally test specific hypotheses about fixed effects or when comparing models is the primary goal

In practice, if both methods give similar results, you can be more confident in your conclusions. If they differ, it is worth investigating further and considering the specific research question at hand.

**Important note about missing data:**

Likelihood ratio tests require that both models being compared are fitted on **exactly the same observations**. If different predictors have different patterns of missing values, models may use different subsets of data, making the LRT invalid. The F-tests via `step()` are generally more robust to this issue as they work within a single REML-fitted model. If you encounter errors about "number of rows in use has changed" when using LRTs, ensure all models use the same complete-case dataset by explicitly removing missing values before model fitting.
:::

### Model diagnostics

The process of performing model diagnostics for the random intercept models fitted in this lab is similar to the one described in the previous labs. Therefore, we refer to those labs for more detailed instructions on assessing model assumptions.
