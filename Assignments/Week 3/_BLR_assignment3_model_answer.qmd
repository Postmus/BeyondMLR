---
title: "Assignment 3: Multilevel Analysis of School Effectiveness"
subtitle: "Model answer"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    code-overflow: wrap
execute:
  warning: false
  message: false
  eval: true
  echo: true
---

::: {.callout-note icon=false title="Preliminary setup"}
In this assignment, we will use the R packages `ggplot2`, `dplyr`, `emmeans`, `lmerTest`. You can use the script below to automatically install and load them using the `pacman` package.

```{r}
# Check whether pacman is available and install if needed
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")

# Use pacman to install (if needed) and load the required packages
pacman::p_load(dplyr, ggplot2, emmeans, lmerTest)
```
:::

# ILEA School Effectiveness Data

The Inner London Education Authority (ILEA) dataset contains examination records of 15,362 students from 140 secondary schools over the years 1985, 1986, and 1987. This dataset was sourced from the data library of the Centre for Multilevel Modelling at the University of Bristol and is used to examine school effectiveness and the factors that influence student exam scores.

The dataset contains the following variables:

* School: A numeric variable representing the school identifier
* ExamScore: A numeric variable representing the exam score of each student
* PercentFSM: The percentage of students in the school eligible for free school meals (an indicator of socioeconomic status)
* Gender: A categorical variable representing the gender of the student
* VRBand: The verbal reasoning band of the student (VR1, VR2, or VR3)
* SchoolDenomination: The denomination of the school (Maintained, Church of England, Roman Catholic)

## Exploratory Data Analysis

Let's load the data and use the `str()` function to inspect the structure of the dataset.

```{r}
# Load the ILEA data
ilea_data <- read.csv("/home/simalgo/projects/BeyondMLR/Assignments/Week 3/downloads/ilea_data.csv")

# Convert all character variables into factors
ilea_data <- ilea_data %>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(School = as.factor(School))

# Inspect the structure of the dataset
str(ilea_data)
```

This initial inspection makes clear that the ILEA dataset has a hierarchical structure: 15,362 individual students are nested within 140 schools. This is a two-level hierarchical structure with students (level 1) nested within schools (level 2).

### Grouping structure

To get a better feeling for the grouping structure, we create a summary table showing the number of students within each school and visualize it with a bar chart:

```{r}
# Create a summary table showing students per school
school_summary <- ilea_data %>%
  group_by(School) %>%
  summarise(num_students = n(), .groups = "drop") %>%
  arrange(desc(num_students))

# Display summary statistics for the number of students per school
summary(school_summary$num_students)

# Create a histogram showing the distribution of school sizes
ggplot(school_summary, aes(x = num_students)) +
  geom_histogram(bins = 20, fill = "skyblue", color = "black") +
  labs(title = "Distribution of School Sizes",
       x = "Number of Students",
       y = "Frequency") +
  theme_minimal()
```

The distribution shows substantial variation in school sizes, with most schools having between 50 and 150 students.

### Outcome variable

Next, we create a histogram to visualize the distribution of the outcome variable `ExamScore`:

```{r}
# Create a histogram of ExamScore
ggplot(ilea_data, aes(x = ExamScore)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Exam Scores",
       x = "Exam Score",
       y = "Frequency") +
  theme_minimal()
```

The distribution of exam scores is right-skewed with a notable floor effect: a substantial number of students scored zero or near-zero on the exam. This floor effect occurs because exam scores are bounded at zero - students cannot score below this minimum. Such distributional characteristics may lead to heteroscedasticity in the residuals, which we will examine in the model diagnostics section.

### Variance components

We also want to get a sense of the variability in exam scores within and between schools. For this, we are going to randomly select 10 schools and create a scatter plot with the exam score on the y-axis and the school on the x-axis:

```{r}
# Set seed for reproducibility
set.seed(123)

# Randomly select 10 unique schools
random_schools <- sample(unique(ilea_data$School), size = 10)

# Filter the data to include only the randomly selected schools
random_school_data <- ilea_data %>%
  filter(School %in% random_schools)

# Calculate the average ExamScore for each school
school_avg_score <- random_school_data %>%
  group_by(School) %>%
  summarise(avg_exam_score = mean(ExamScore, na.rm = TRUE), .groups = "drop")

# Calculate the overall grand mean across all schools
grand_mean <- mean(ilea_data$ExamScore, na.rm = TRUE)

# Create scatter plot with jittered observations
ggplot(random_school_data, aes(x = reorder(School, ExamScore, FUN = mean), y = ExamScore)) +
  geom_hline(yintercept = grand_mean, linetype = "solid", color = "black", linewidth = 1) +
  geom_jitter(alpha = 0.3, width = 0.2, size = 1, color = "gray60") +
  geom_point(data = school_avg_score, aes(x = School, y = avg_exam_score),
             size = 4, shape = 18, color = "red") +
  labs(title = "Variation in exam scores: within and between schools",
       subtitle = "Points = individual students; Diamonds = school means; Solid line = grand mean (all data)",
       x = "School (ordered by mean exam score)",
       y = "Exam Score") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

This plot reveals both within-school variability (the spread of individual student scores around their school mean) and between-school variability (the differences in school means from the grand mean). The red diamonds show that schools differ in their average exam scores, suggesting that school-level factors may influence student performance.

### Covariate effects

Before fitting models with covariates, it is useful to explore the relationships between potential predictors and the outcome variable.

First, let's examine how exam scores vary across different verbal reasoning bands:

```{r}
# Boxplot for VRBand vs ExamScore
ggplot(ilea_data, aes(x = VRBand, y = ExamScore, fill = VRBand)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Exam scores by Verbal Reasoning Band",
       x = "Verbal Reasoning Band",
       y = "Exam Score") +
  theme_minimal() +
  theme(legend.position = "none")
```

Note that the plot above includes an `NA` category for students with missing VRBand values. This is default `ggplot2` behavior. To exclude missing values from the plot, we can filter them out before plotting:

```{r}
# Boxplot for VRBand vs ExamScore (excluding missing values)
ilea_data %>%
  filter(!is.na(VRBand)) %>%
  ggplot(aes(x = VRBand, y = ExamScore, fill = VRBand)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Exam scores by Verbal Reasoning Band",
       x = "Verbal Reasoning Band",
       y = "Exam Score") +
  theme_minimal() +
  theme(legend.position = "none")
```

Next, let's examine how exam scores differ by gender:

```{r}
# Boxplot for Gender vs ExamScore
ggplot(ilea_data, aes(x = Gender, y = ExamScore, fill = Gender)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Exam scores by Gender",
       x = "Gender",
       y = "Exam Score") +
  theme_minimal() +
  theme(legend.position = "none")
```

Now let's explore the relationship between PercentFSM (school-level socioeconomic indicator) and exam scores:

```{r}
# Create a school-level summary with average exam scores and PercentFSM
school_level_data <- ilea_data %>%
  group_by(School) %>%
  summarise(
    avg_exam_score = mean(ExamScore, na.rm = TRUE),
    PercentFSM = first(PercentFSM),
    SchoolDenomination = first(SchoolDenomination),
    .groups = "drop"
  )

# Scatterplot of school average exam score vs PercentFSM
ggplot(school_level_data, aes(x = PercentFSM, y = avg_exam_score)) +
  geom_point(color = "gray60", size = 2) +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue", linewidth = 1.5) +
  labs(title = "Relationship between School SES (PercentFSM) and Average Exam Score",
       x = "Percentage of Students Eligible for Free School Meals",
       y = "Average Exam Score") +
  theme_minimal()
```

Finally, let's examine exam scores by school denomination:

```{r}
# Boxplot for SchoolDenomination vs ExamScore (using school-level averages)
ggplot(school_level_data, aes(x = SchoolDenomination, y = avg_exam_score, fill = SchoolDenomination)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Average Exam Scores by School Denomination",
       x = "School Denomination",
       y = "Average Exam Score") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))
```

## Random intercept model (null model)

To partition the variance in exam scores between students and schools, we start by fitting a null model (random intercept model without any predictors):

```{r}
# Fit the null model (random intercept only)
null_model <- lmer(ExamScore ~ 1 + (1 | School), data = ilea_data)
summary(null_model)
```

From the variance components, we can calculate the Intraclass Correlation Coefficient (ICC):

```{r}
# Extract variance components
var_between <- as.data.frame(VarCorr(null_model))$vcov[1]
var_within <- as.data.frame(VarCorr(null_model))$vcov[2]

# Calculate ICC
ICC <- var_between / (var_between + var_within)
cat("Between-school variance:", round(var_between, 2), "\n")
cat("Within-school variance:", round(var_within, 2), "\n")
cat("Intraclass Correlation Coefficient (ICC):", round(ICC, 3), "\n")
```

The ICC indicates that approximately `r round(ICC * 100, 1)`% of the total variability in exam scores can be attributed to differences between schools, while the remaining `r round((1-ICC) * 100, 1)`% is due to differences between students within schools. This suggests that while most of the variability in exam scores is at the student level, there is still meaningful variation between schools that warrants a multilevel approach.

## Extending the random intercept model with individual-level variables

As a second step, we extend the random intercept model with individual-level variables (`Gender` and `VRBand`). To facilitate the interpretation of the model coefficients, we use effects coding for categorical variables:

```{r}
# Use effects coding for the categorical variables
options(contrasts = c("contr.sum", "contr.poly"))

# Fit the random intercept model with individual-level variables
model_L1 <- lmer(ExamScore ~ Gender + VRBand + (1 | School), data = ilea_data)
summary(model_L1)

# Display the coding scheme for the categorical variables
cat("\nContrasts for Gender:\n")
contrasts(ilea_data$Gender)
cat("\nContrasts for VRBand:\n")
contrasts(ilea_data$VRBand)

# Obtain the ANOVA table for the individual-level variables
anova(model_L1)
```

The results show that both `Gender` and `VRBand` are significant predictors of exam scores. With effects coding:

- The intercept represents the grand mean exam score across all groups
- The coefficient for Gender1 (Female = 1) indicates how much the mean for females differs from the grand mean; males differ by the same amount in the opposite direction
- The coefficients for VRBand indicate how much each verbal reasoning band differs from the grand mean

Let's examine how the variance components have changed:

```{r}
# Extract variance components from the model with L1 variables
var_between_L1 <- as.data.frame(VarCorr(model_L1))$vcov[1]
var_within_L1 <- as.data.frame(VarCorr(model_L1))$vcov[2]

cat("After adding individual-level variables:\n")
cat("Between-school variance:", round(var_between_L1, 2), "(was", round(var_between, 2), ")\n")
cat("Within-school variance:", round(var_within_L1, 2), "(was", round(var_within, 2), ")\n")
```

The inclusion of individual-level variables primarily reduces the within-school variance because these variables (Gender and VRBand) explain differences between students within the same school.

## Including context-level variables

As a third step, we extend the model with context-level variables (`PercentFSM` and `SchoolDenomination`). We start by centering the continuous context-level variable:

```{r}
# Center the context-level variable
ilea_data <- ilea_data %>%
  mutate(PercentFSM_c = scale(PercentFSM, scale = FALSE))

# Fit the random intercept model with individual-level and context-level variables
model_L1L2 <- lmer(ExamScore ~ Gender + VRBand + PercentFSM_c + SchoolDenomination + (1 | School), data = ilea_data)
summary(model_L1L2)

# Obtain the ANOVA table
anova(model_L1L2)
```

Let's examine how the variance components have changed:

```{r}
# Extract variance components from the model with L1 and L2 variables
var_between_L1L2 <- as.data.frame(VarCorr(model_L1L2))$vcov[1]
var_within_L1L2 <- as.data.frame(VarCorr(model_L1L2))$vcov[2]

cat("After adding context-level variables:\n")
cat("Between-school variance:", round(var_between_L1L2, 2), "(was", round(var_between_L1, 2), ")\n")
cat("Within-school variance:", round(var_within_L1L2, 2), "(was", round(var_within_L1, 2), ")\n")

# Calculate proportion of between-school variance explained
prop_explained <- (var_between_L1 - var_between_L1L2) / var_between_L1
cat("\nProportion of between-school variance explained by context-level variables:", round(prop_explained * 100, 1), "%\n")
```

The inclusion of context-level variables primarily reduces the between-school variance, as these variables explain differences between schools.

### Model selection using stepwise elimination

To obtain a more parsimonious model, we can use the `step()` function from the `lmerTest` package to perform backward elimination of fixed-effect terms:

```{r}
# Perform stepwise selection to identify the most important predictors
# Set reduce.random = FALSE to only eliminate fixed effects (not random effects)
step(model_L1L2, reduce.random = FALSE)
```

## Exploring cross-level interactions

Finally, we explore potential cross-level interactions. The relationship between individual-level variables (such as VRBand) and exam scores may depend on school-level characteristics (such as PercentFSM or SchoolDenomination).

For example, we might hypothesize that the gap between high-ability (VR1) and low-ability (VR3) students differs depending on the socioeconomic composition of the school.

```{r}
# Fit model with VRBand × PercentFSM interaction
model_interaction <- lmer(ExamScore ~ Gender + VRBand * PercentFSM_c + SchoolDenomination + (1 | School), data = ilea_data)
summary(model_interaction)

# Test the interaction terms
drop1(model_interaction)
```

Let's also test whether the effect of Gender differs by school denomination:

```{r}
# Fit model with Gender × SchoolDenomination interaction
model_interaction2 <- lmer(ExamScore ~ Gender * SchoolDenomination + VRBand + PercentFSM_c + (1 | School), data = ilea_data)

# Test the interaction term
drop1(model_interaction2)
```

### Interpreting the VRBand × PercentFSM interaction

If the interaction is significant, we can use the `emmeans` package to visualize how the effect of VRBand on exam scores varies across schools with different levels of PercentFSM:

```{r}
# Calculate representative values for PercentFSM
fsm_low <- quantile(ilea_data$PercentFSM_c, 0.25, na.rm = TRUE)
fsm_high <- quantile(ilea_data$PercentFSM_c, 0.75, na.rm = TRUE)

# Compute estimated marginal means
predictions_grid <- emmeans(model_interaction,
                            specs = ~ VRBand * PercentFSM_c,
                            at = list(PercentFSM_c = c(fsm_low, 0, fsm_high)),
                            lmer.df = "satterthwaite")

# Convert predictions to data frame for plotting
pred_df <- as.data.frame(summary(predictions_grid))

# Add descriptive labels
pred_df$fsm_label <- factor(pred_df$PercentFSM_c,
                            levels = c(fsm_low, 0, fsm_high),
                            labels = c("Low FSM (Q1)", "Average FSM", "High FSM (Q3)"))

# Create interaction plot
ggplot(pred_df, aes(x = VRBand, y = emmean, color = fsm_label, group = fsm_label)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  labs(title = "Interaction between VRBand and School SES",
       subtitle = "Estimated exam scores at different combinations of VRBand and PercentFSM",
       x = "Verbal Reasoning Band",
       y = "Estimated Exam Score",
       color = "School SES Level") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

The interaction plot shows that the lines are nearly parallel, indicating that the practical effect of the interaction is modest despite being statistically significant. Looking at the estimated marginal means:

- For **VR1 students** (high ability): scores decrease slightly as PercentFSM increases (30.8 → 30.0)
- For **VR3 students** (low ability): scores increase slightly as PercentFSM increases (11.4 → 12.3)
- For **VR2 students**: scores remain essentially flat

This means the gap between high and low ability students is **smaller in high-FSM schools** (30.0 - 12.3 = 17.7 points) compared to **low-FSM schools** (30.8 - 11.4 = 19.4 points). The interaction is statistically significant (p < 0.001) due to the large sample size (n = 15,347), but the practical effect is modest (about 1.7 points difference in the VR1-VR3 gap). This illustrates an important point: **statistical significance does not imply practical significance**.

## Model diagnostics

To assess the assumptions of the multilevel model, we examine the conditional residuals (the difference between observed values and fitted values). Key assumptions include:

1. Residuals are normally distributed
2. Residuals have constant variance (homoscedasticity)
3. Residuals are independent

### Histogram of conditional residuals

```{r}
# Extract conditional residuals from the final model
residuals_cond <- residuals(model_interaction)

# Create histogram of conditional residuals
ggplot(data.frame(residuals = residuals_cond), aes(x = residuals)) +
  geom_histogram(bins = 50, fill = "skyblue", color = "black", aes(y = after_stat(density))) +
  stat_function(fun = dnorm,
                args = list(mean = mean(residuals_cond), sd = sd(residuals_cond)),
                color = "red", linewidth = 1) +
  labs(title = "Distribution of Conditional Residuals",
       subtitle = "Red line shows normal distribution with same mean and SD",
       x = "Residuals",
       y = "Density") +
  theme_minimal()
```

The histogram shows that the conditional residuals are approximately normally distributed, with a shape that closely follows the theoretical normal distribution (red line).

### Residuals vs. fitted values

```{r}
# Extract fitted values
fitted_values <- fitted(model_interaction)

# Create residuals vs fitted values plot
ggplot(data.frame(fitted = fitted_values, residuals = residuals_cond),
       aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.2, color = "gray50") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_smooth(method = "loess", se = FALSE, color = "red", linewidth = 1) +
  labs(title = "Residuals vs. Fitted Values",
       subtitle = "Red line shows loess trend; dashed line at zero",
       x = "Fitted Values",
       y = "Conditional Residuals") +
  theme_minimal()
```

The residuals vs. fitted values plot reveals some violation of the homoscedasticity assumption. The loess trend line curves upward at both the low and high ends of the fitted values, and the spread of residuals appears more constrained at lower fitted values. This pattern is likely caused by a **floor effect** in the exam scores: as seen in the histogram of the outcome variable, a substantial number of students scored zero or near-zero on the exam. Since students cannot score below zero, residuals for students with low predicted scores are truncated on the negative side, leading to:

1. A "fan-shaped" pattern where residual variance increases with fitted values
2. A curved loess line that deviates from the horizontal zero line

This floor effect, combined with the right-skewed distribution of exam scores, suggests that the assumption of homogeneous residual variance is not fully met. In practice, mixed models are reasonably robust to moderate violations of this assumption, especially with large sample sizes. However, for a more rigorous analysis, one could consider:

- Transforming the outcome variable (though this complicates interpretation)
- Using a generalized linear mixed model with a distribution that better accommodates bounded or skewed outcomes
- Applying robust standard errors

For the purposes of this analysis, we proceed with the linear mixed model while acknowledging this limitation.

## Summary of findings

Based on our multilevel analysis:

1. **Variance partitioning**: The ICC from the null model indicates that approximately `r round(ICC * 100, 1)`% of the variance in exam scores is between schools, while the majority is between students within schools.

2. **Individual-level effects**: Both Gender and VRBand are significant predictors of exam scores. Students in higher verbal reasoning bands (VR1) score higher than those in lower bands (VR3), and there are gender differences in exam performance.

3. **Context-level effects**: PercentFSM is a significant predictor, with schools having higher proportions of students eligible for free school meals tending to have lower average exam scores. The school denomination also influences exam scores.

4. **Cross-level interactions**: The analysis of cross-level interactions reveals whether the effects of individual-level predictors vary across different types of schools.

The multilevel approach is appropriate for this dataset because it accounts for the clustering of students within schools, provides accurate standard errors for the fixed effects, and allows us to partition the variance into student-level and school-level components.

## Sensitivity analysis: Log-transformed outcome

Given the floor effect and right-skewed distribution of exam scores, we explore whether a log transformation improves the model diagnostics. Since some students scored zero, we use log(ExamScore + 1) to handle these cases.

### Distribution of log-transformed outcome

```{r}
# Create log-transformed outcome variable
ilea_data <- ilea_data %>%
  mutate(log_ExamScore = log(ExamScore + 1))

# Histogram of log-transformed exam scores
ggplot(ilea_data, aes(x = log_ExamScore)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Log-Transformed Exam Scores",
       subtitle = "log(ExamScore + 1)",
       x = "Log(Exam Score + 1)",
       y = "Frequency") +
  theme_minimal()
```

The log transformation reduces the right skewness, but the floor effect remains visible as a spike at log(0 + 1) = 0 for students who scored zero.

### Fitting the model with log-transformed outcome

```{r}
# Fit the interaction model with log-transformed outcome
model_interaction_log <- lmer(log_ExamScore ~ Gender + VRBand * PercentFSM_c + SchoolDenomination + (1 | School), data = ilea_data)
summary(model_interaction_log)
```

### Residuals vs. fitted values for log-transformed model

```{r}
# Extract residuals and fitted values
residuals_log <- residuals(model_interaction_log)
fitted_log <- fitted(model_interaction_log)

# Create residuals vs fitted values plot
ggplot(data.frame(fitted = fitted_log, residuals = residuals_log),
       aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.2, color = "gray50") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_smooth(method = "loess", se = FALSE, color = "red", linewidth = 1) +
  labs(title = "Residuals vs. Fitted Values (Log-Transformed Outcome)",
       subtitle = "Red line shows loess trend; dashed line at zero",
       x = "Fitted Values",
       y = "Conditional Residuals") +
  theme_minimal()
```

### Square root transformation

An alternative to the log transformation is the square root transformation, which has some advantages for this type of data:

- **Handles zeros naturally**: √0 = 0, so no need to add a constant
- **Milder transformation**: Less aggressive than log, reducing skewness without over-compressing the upper tail
- **Common for count-like data**: Square root transformations are often used for count data or bounded scores

```{r}
# Create square root transformed outcome variable
ilea_data <- ilea_data %>%
  mutate(sqrt_ExamScore = sqrt(ExamScore))

# Histogram of square root transformed exam scores
ggplot(ilea_data, aes(x = sqrt_ExamScore)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Square Root Transformed Exam Scores",
       x = "√(Exam Score)",
       y = "Frequency") +
  theme_minimal()
```

```{r}
# Fit the interaction model with square root transformed outcome
model_interaction_sqrt <- lmer(sqrt_ExamScore ~ Gender + VRBand * PercentFSM_c + SchoolDenomination + (1 | School), data = ilea_data)
summary(model_interaction_sqrt)
```

```{r}
# Extract residuals and fitted values
residuals_sqrt <- residuals(model_interaction_sqrt)
fitted_sqrt <- fitted(model_interaction_sqrt)

# Create residuals vs fitted values plot
ggplot(data.frame(fitted = fitted_sqrt, residuals = residuals_sqrt),
       aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.2, color = "gray50") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_smooth(method = "loess", se = FALSE, color = "red", linewidth = 1) +
  labs(title = "Residuals vs. Fitted Values (Square Root Transformed Outcome)",
       subtitle = "Red line shows loess trend; dashed line at zero",
       x = "Fitted Values",
       y = "Conditional Residuals") +
  theme_minimal()
```

### Comparison of approaches

Neither the log nor the square root transformation fully resolves the heteroscedasticity issue:

1. **The floor effect persists**: Students who scored zero still create a boundary at the lower end. Both transformations map zero to zero, maintaining the cluster of observations at the lower bound.

2. **Interpretation trade-offs**:
   - Untransformed: coefficients represent changes in exam score points (most intuitive)
   - Square root: coefficients represent changes in √(points) (moderate interpretability)
   - Log: coefficients represent changes in log-units (least intuitive)

3. **The fundamental issue remains**: The heteroscedasticity is caused by the bounded nature of the outcome (scores cannot go below zero), which no monotonic transformation can fully address.

The square root transformation may provide a modest improvement over both the untransformed and log-transformed models, as it handles zeros naturally and applies a milder correction. However, for this dataset, the untransformed model with acknowledged limitations may still be the most practical choice for interpretation, while recognizing that more sophisticated approaches (such as Tobit models for censored data) could be considered for a more rigorous analysis.

