---
title: "Beyond MLR Lab 6: Longitudinal data analysis"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    code-overflow: wrap
  pdf:
    toc: false
execute:
  warning: false
  message: false
  eval: true
  echo: true
---

::: {.callout-note icon=false title="Preliminary setup"}
In this lab, we will use the R packages `haven`, `ggplot2`, `dplyr`, `emmeans`, `lmerTest`. You can use the script below to automatically install and load them using the `pacman` package.

```{r}
# Check whether pacman is available and install if needed
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")

# Use pacman to install (if needed) and load the required packages
pacman::p_load(haven, dplyr, ggplot2, emmeans, lmerTest)
```
:::

# Adolescent alcohol use data

In this lab, we will explore the analysis of longitudinal data using linear mixed-effects models. Longitudinal data involve repeated measurements taken on the same subjects over time, allowing us to study changes in outcomes within individuals.

The dataset we will use comes from a study of adolescent alcohol use, featured in Singer and Willettâ€™s *Applied Longitudinal Data Analysis: Modeling Change and Event Occurrence* (2003). This study tracked 82 adolescents over three years (ages 14, 15, and 16) to examine how their alcohol use changed over time.

## Dataset description

The dataset contains the following variables:

- **Outcome variable**:
  - `alcuse`: Continuous measure of alcohol use based on various survey items.
- **Grouping variable**:
  - `id`: Unique identifier for each adolescent in the study.
- **Covariates**:
  - `coa`: Dichotomous variable indicating parental alcoholism (1 = yes, 0 = no).
  - `sex`: Dichotomous variable indicating sex.
  - `peer`: Continuous measure of peer alcohol use, assessed at age 14.
  - `age`: Numerical variable representing the age of the adolescent at each time point (14, 15, 16).

## Research question

In this lab, we are going to address the following research question:

> What factors predict adolescent alcohol use and its change over time? Specifically, do parental alcoholism, sex, and peer alcohol use influence baseline levels and trajectories of alcohol use from ages 14 to 16?

## Data import, cleaning, and inspection

```{r}
# Load the adolescent alcohol use data
# Note: the call below assumes the dataset is placed in the 'data' folder
# directly above the root folder of the project. Update the path as needed.
alcohol_data <- read_sav("data/alcoholpp.sav")

# Convert labelled variables (dbl+lbl) to factors using their value labels
alcohol_data <- alcohol_data |> mutate(across(where(is.labelled), as_factor))

# Use effects coding for the categorical variables
options(contrasts = c("contr.sum", "contr.poly"))

# Inspect the structure of the dataset
str(alcohol_data)
```

## Exploratory data analysis

### Overall pattern and individual variation

We begin by examining both the overall mean trajectory and individual trajectories simultaneously. This "spaghetti plot" shows all individual trajectories (thin gray lines) overlaid with the overall mean trajectory (thick blue line), providing an immediate sense of both the average pattern and the variability around it.

```{r}
# Compute the overall mean alcohol use by age
mean_trajectory <- alcohol_data |>
  group_by(age) |>
  summarise(mean_alcuse = mean(alcuse, na.rm = TRUE), .groups = "drop")

# Create spaghetti plot: individual trajectories + mean trajectory
ggplot(alcohol_data, aes(x = age, y = alcuse)) +
  geom_line(aes(group = id), alpha = 0.3, color = "gray60") +  # Individual trajectories
  geom_line(data = mean_trajectory, aes(x = age, y = mean_alcuse), 
            color = "steelblue", linewidth = 1.5) +             # Mean trajectory
  geom_point(data = mean_trajectory, aes(x = age, y = mean_alcuse), 
             color = "steelblue", size = 3) +                   # Mean points
  labs(
    title = "Individual and Mean Alcohol Use Trajectories",
    subtitle = "Gray lines = individual trajectories; Blue line = overall mean",
    x = "Age",
    y = "Alcohol Use"
  ) +
  theme_minimal()
```

::: {.callout-important icon=false title="Question"}
Based on the spaghetti plot:

1. Does the change in alcohol use over time appear to be linear, or would a quadratic trend be more appropriate?
2. How much variability is there in individual trajectories around the mean? Does this variability suggest the need for random effects in our models?
:::

### Examining individual trajectories in detail

While the spaghetti plot gives us a good overview of the overall variability, it can be difficult to distinguish specific individual patterns when all trajectories are overlaid. To get a better sense of the different types of individual trajectories, we'll examine a random sample of 16 individuals using a facet plot.

```{r}
set.seed(123)  # Set seed for reproducibility

# Sample 16 unique individuals
sampled_ids <- sample(1:82, 16)

# Filter dataset for the sampled IDs and plot
alcohol_data |>
  filter(id %in% sampled_ids) |>
  ggplot(aes(x = age, y = alcuse)) +
  geom_line() +                               # Add trajectories (lines)
  geom_point(size = 2, alpha = 0.7) +         # Add individual data points (dots)
  facet_wrap(~ id) +                          # Create a subplot for each individual
  labs(
    title = "Sample of Individual Alcohol Use Trajectories",
    x = "Age",
    y = "Alcohol Use"
  ) +
  theme_minimal()
```

#### Observations:
- Many adolescents report no alcohol use (`alcuse = 0`) across all time points.
- For adolescents who do report alcohol use, the trajectories show diverse patterns: some increasing, some decreasing, and some remaining relatively stable over time.
- The heterogeneity in both baseline levels and rates of change motivates the use of random intercepts and random slopes in our models.

::: {.callout-warning icon=true title="Disclaimer"}
The dataset used in this lab is zero-inflated, with a large number of zero alcohol use values. While linear mixed-effects models are not necessarily the best approach for analyzing such data, we will use them in this lab to focus on the methodology. The results derived in this lab are intended for educational purposes only.
:::

### Mean trajectories by parental alcoholism

Next, we will examine the mean trajectories of alcohol use by parental alcoholism (`coa`). This will provide an overview of how this variable relates to alcohol use over time.

```{r}
# Compute the mean alcohol use by age, and COA status
mean_alcuse <- alcohol_data |>
  group_by(age, coa) |>
  summarise(mean_alcuse = mean(alcuse, na.rm = TRUE), .groups = "drop")

# Plot the mean trajectories by COA
ggplot(mean_alcuse, aes(x = age, y = mean_alcuse, color = coa)) +
  geom_line() +
  labs(
    title = "Mean Alcohol Use Trajectories by Parental Alcoholism",
    x = "Age",
    y = "Mean Alcohol Use"
  ) +
  ylim(0, 3) +
  theme_minimal()
```

::: {.callout-important icon=false title="Question"}
Based on the plot, do you expect there to be a effect of parental alcoholism on alcohol use? Do you expect there to be an interaction effect between parental alcoholism and age? Explain your reasoning based on the trends shown in the plot.
:::

::: {.callout-important icon=false title="Coding exercise"}
Create similar plots to explore mean trajectories by `sex` and by `peer` alcohol use.

**Hint for peer alcohol use:** Since `peer` is a continuous variable, you can categorize it into tertiles (low, medium, high) for visualization purposes using the following code:

```r
alcohol_data <- alcohol_data |>
  mutate(peer_cat = cut(peer,
                        breaks = quantile(peer, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
                        labels = c("Low", "Medium", "High"),
                        include.lowest = TRUE))
```

Then compute mean trajectories by `age` and `peer_cat`, and create a plot similar to the one above.
:::

## Assessing the intraclass correlation coefficient (ICC)

Before building more complex models, we first assess the intraclass correlation coefficient (ICC) to understand how much of the variance in alcohol use is attributable to differences between individuals. In longitudinal data analysis, the ICC is typically calculated from a model that includes time as a fixed effect.

### Modeling time flexibly for ICC calculation

Since we have only 3 time points (ages 14, 15, and 16), we can model time with maximum flexibility by including both linear and quadratic terms. This saturated representation uses 2 degrees of freedom to perfectly fit the 3 observed means, which is equivalent to treating time as a categorical variable. However, we prefer the continuous representation because it:

1. Maintains interpretable coefficients (linear and quadratic change)
2. Allows us to extend the model to include random slopes later (which is not identifiable with categorical time and one observation per person-time combination)
3. Provides a natural framework for growth modeling

```{r}
# Center age at 15 
alcohol_data$age_centered <- alcohol_data$age - 15

# Create quadratic term
alcohol_data$age_centered_sq <- alcohol_data$age_centered^2

# Fit a random intercept model with linear and quadratic time
icc_model <- lmer(alcuse ~ age_centered + age_centered_sq + (1 | id), data = alcohol_data)
summary(icc_model)
```

::: {.callout-important icon=false title="Question"}
Calculate the ICC based on the estimated variance components from the `icc_model`. What proportion of variance in alcohol use (after accounting for age trends) is due to differences between individuals?
:::

## Model building

### Step 1: Fit the saturated model

Following the model building strategy outlined in the lecture, we start with a saturated fixed-effects structure that includes all predictors and their interactions with time, combined with a complex random-effects structure (random intercept and random slope).

```{r}
# Center peer at its mean for interpretability
alcohol_data$peer_centered <- alcohol_data$peer - mean(alcohol_data$peer, na.rm = TRUE)

# Fit the saturated model with all predictors and their interactions with time
# Note: Random effects include only intercept and linear slope, not quadratic slope
saturated_model <- lmer(
  alcuse ~ (age_centered + age_centered_sq) * (coa + sex + peer_centered) + (1 + age_centered | id),
  data = alcohol_data
)
summary(saturated_model)
```

::: {.callout-note icon=false title="Why not random quadratic slopes?"}
With only 3 observations per person, we do not have sufficient information to reliably estimate individual-specific quadratic trajectories. While we are only estimating variance components (not separate parameters for each person), the issue is one of **identifiability at the individual level**: with 3 time points, we cannot distinguish between "person i has a different quadratic trajectory" and "person i has random measurement error."

**General guideline for random effects:**

- 3 time points: Random intercept + random linear slope is feasible
- 4+ time points: Could consider random quadratic slopes (though rarely used in practice)
- The quadratic term remains as a **fixed effect** to model the average curvature across all individuals

This limitation is why continuous time modeling (which imposes structure) is preferred over categorical time modeling (which would make even random linear slopes unidentifiable with one observation per person-time combination).
:::

### Step 2: Determine the random-effects structure

Before simplifying the fixed effects, we first determine whether the random slope for time is necessary. We compare the saturated model (with random slope) against a model with only a random intercept using a likelihood ratio test. Since we are comparing random effects, we retain REML estimation.

```{r}
# Fit a model with only random intercept (same fixed effects as saturated model)
random_intercept_only <- lmer(
  alcuse ~ (age_centered + age_centered_sq) * (coa + sex + peer_centered) + (1 | id),
  data = alcohol_data
)

# Compare models using likelihood ratio test
anova(random_intercept_only, saturated_model, refit = FALSE)
```

::: {.callout-important icon=false title="Question"}
Based on the likelihood ratio test, is the random slope for time necessary? What does this tell us about individual trajectories?
:::

#### Using step() for sequential testing of random effects

When working with more complex random-effects structures (e.g., multiple random slopes), it becomes impractical to manually test each term. The `step()` function from the `lmerTest` package provides a systematic approach by performing sequential backward elimination of random effects using likelihood ratio tests:

```{r}
# Use step() to test random effects structure
# reduce.random = TRUE: test and potentially remove random effects
# reduce.fixed = FALSE: keep all fixed effects unchanged
step_random <- step(saturated_model, reduce.random = TRUE, reduce.fixed = FALSE)
print(step_random)

# Extract the model with the final random effects structure
model_with_final_random <- get_model(step_random)
```

In this example, we have only one random effect that can be tested (the random slope for `age_centered`), so `step()` performs the same likelihood ratio test we conducted manually above. However, the real advantage of `step()` becomes apparent when you have multiple random effects terms: the function tests them sequentially, removing the least significant term at each step until all remaining random effects are statistically significant or until further simplification would violate model hierarchy.

### Step 3: Simplify the fixed-effects structure

Now that we have determined the appropriate random-effects structure, we use the model from Step 2 as the starting point to simplify the fixed effects. By setting `reduce.fixed = TRUE` and `reduce.random = FALSE`, the function will only eliminate non-significant fixed effects while keeping the random effects structure unchanged.

```{r}
# Use step() to simplify fixed effects only
# Start with the model that has the final random effects structure from Step 2
# reduce.fixed = TRUE: test and potentially remove fixed effects
# reduce.random = FALSE: keep the random effects structure unchanged
step_result <- step(model_with_final_random, reduce.fixed = TRUE, reduce.random = FALSE)
print(step_result)

# Extract the final model
final_model <- get_model(step_result)
```

The `step()` function performs backward elimination of fixed effects, adhering to important model building principles such as the marginality principle (lower-order terms are retained if higher-order terms involving them remain in the model) and uses F-tests with Satterthwaite approximation for hypothesis testing.

::: {.callout-important icon=false title="Question"}
Based on the output from `step()`, which random effects and fixed effects terms were removed from the model? Does the final model include any interaction effects, or only main effects?
:::

### Step 4: Final model and interpretation

Based on the model building process, we arrive at our final model. We can now interpret the results in detail:

```{r}
# Display the final model summary
summary(final_model)
```

::: {.callout-important icon=false title="Question"}
Based on the final model, what can you conclude about the factors that predict adolescent alcohol use and its change over time? Consider:

- Which predictors have significant effects on alcohol use?
- How does alcohol use change with age on average?
- Are there differences between groups (e.g., children of alcoholic parents vs. not, sex differences)?
- Do any predictors interact with time (age), suggesting different trajectories for different groups?
:::

### Model diagnostics

After fitting the final model, it is important to check the modeling assumptions. We focus on checking the assumptions regarding the conditional residuals, which represent the deviation of the observed data from the model's predictions after accounting for both fixed and random effects. These residuals can be considered estimates of the errors $\epsilon_{ij}$, which are assumed to be normally distributed with a mean of zero and constant variance.

To check these assumptions, we generate diagnostic plots:

- **Residuals vs. Fitted Plot**: Checks for homoscedasticity (constant variance) and linearity
- **Normal Q-Q Plot**: Assesses whether the residuals follow a normal distribution

```{r}
# Extract conditional residuals from the final model
residuals_cond <- resid(final_model)

# Residuals vs Fitted
plot(fitted(final_model), residuals_cond,
     main = "Residuals vs Fitted",
     xlab = "Fitted values",
     ylab = "Conditional Residuals")
abline(h = 0, col = "red")

# Normal Q-Q Plot
qqnorm(residuals_cond, main = "Normal Q-Q Plot of Conditional Residuals")
qqline(residuals_cond, col = "red")
```

::: {.callout-important icon=false title="Question"}
Based on the diagnostic plots, do you observe any violations of the model assumptions? Consider:

- Does the Residuals vs. Fitted plot show any patterns suggesting non-constant variance or non-linearity?
- Does the Q-Q plot suggest that the residuals are approximately normally distributed?
:::


