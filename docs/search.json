[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R labs for the Beyond MLR course",
    "section": "",
    "text": "This website hosts the R labs for the beyond MLR course. You can navigate between the different labs using the menu above."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html",
    "href": "BLR_lab_replicated_randomized_block.html",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "",
    "text": "In the previous lab, we considered a traditional randomized block design without replication, where each treatment was applied once within each block (laboratory). This design allowed us to control for variability between laboratories and efficiently estimate the main effects of the treatments. However, a key limitation of this approach is that it does not allow us to assess whether the treatment effects vary across blocks, a concept known as interaction.\nThe lack of replication in the traditional design means we can only test for main effects of the treatments and laboratories, but not whether the effectiveness of a treatment depends on the specific laboratory conditions. For example, a treatment might work well in one laboratory but not in another due to environmental differences (e.g., humidity or temperature), indicating a treatment-by-laboratory interaction.\nAn interaction occurs when the effect of one factor (e.g., treatment) is not consistent across levels of another factor (e.g., laboratory). In other words, the effect of a treatment might vary depending on the laboratory conditions. Replicating the treatments within each block allows us to estimate these interaction effects and better understand the variability in treatment outcomes across different settings.\nIn this lab, we introduce replication within blocks, allowing us to estimate the variability within treatment-block combinations and assess whether treatment effects are consistent across blocks."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo explore the data and investigate the presence of a potential interaction between treatments and laboratories, we create an interaction plot. An interaction plot is a graphical tool that helps visualize whether the effect of one factor (in this case, treatment) depends on the levels of another factor (in this case, laboratory). Specifically, it shows how the mean response (wound healing) for each treatment varies across different laboratories. If the lines on the interaction plot are parallel, this suggests there is no interaction, meaning the treatment effect is consistent across laboratories. If the lines are not parallel, this indicates a potential interaction, meaning the effect of treatment differs depending on the laboratory.\n\n# Calculate mean Wound Healing for each Treatment-Laboratory combination\nlibrary(dplyr)\nmean_data &lt;- data_rep_block %&gt;%\n  group_by(Laboratory, Treatment) %&gt;%\n  summarise(Mean_WoundHealing = mean(WoundHealing))\n\n# Display the produced summary table with the group means\nmean_data\n\n# Create an interaction plot\nlibrary(ggplot2)\nggplot(mean_data, aes(x = Treatment, y = Mean_WoundHealing, group = Laboratory, color = Laboratory)) +\n  geom_point(size = 3) +\n  geom_line() +\n  labs(title = \"Interaction Plot\",\n       y = \"Mean Wound Healing Measure\",\n       x = \"Treatment\") +\n  theme_minimal()\n\n\n\n\n\n\n\nQuestion\n\n\n\nDoes the interaction plot indicate a potential interaction between treatment and laboratory?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDoes the plot suggest any differences in the overall effectiveness of the treatments (i.e., main effect of treatment) across all laboratories?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the plot suggest about variability between laboratories? Are some laboratories consistently higher or lower in wound healing across all treatments?"
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "href": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "A Mixed Effects Model for the Randomized Block Design",
    "text": "A Mixed Effects Model for the Randomized Block Design\nSimilar to the previous lab, laboratory is included as a random effect and treatment as a fixed effect in the model. The key new feature is the treatment-by-laboratory interaction term, which is also modeled as a random effect.\nTo understand why the interaction term must also be modeled as random, we need to consider the nature of random effects in this context. Since laboratory is treated as a random effect, we are assuming that the laboratories in the experiment represent a random sample from a larger population of possible laboratory conditions. This means that we are not just interested in the specific laboratories in the study, but in how the treatments would perform across any set of laboratories with varying conditions.\nWhen we include an interaction term between treatment and laboratory, we are asking whether the effect of each treatment depends on the laboratory environment. If we had modeled laboratory as a fixed effect (i.e., we were only interested in those specific laboratories), the interaction could also be treated as fixed. However, because laboratory is random, the interaction must also be treated as random to reflect the idea that the variability in treatment effects across laboratories applies not just to the specific laboratories in the study, but to any laboratory from the broader population.\nIn other words, by modeling the interaction as random, we are assuming that the variation in treatment effects is not unique to the five laboratories in the study, but rather represents random fluctuations in treatment effectiveness that could occur in any laboratory setting. This approach allows us to generalize our findings beyond the laboratories in the experiment, making the model more realistic and applicable to a wider range of scenarios.\n\nModel Specification\nThe mixed-effects model for the replicated randomized block design is specified as:\n\\[\nY_{ijk} = \\mu + \\tau_i + b_j + (tb)_{ij} + \\epsilon_{ijk}\n\\]\nwhere:\n\n\\(Y_{ijk}\\): Response (wound healing) for the \\(k\\)-tjh replicate of Treatment \\(i\\) in Laboratory \\(j\\).\n\\(\\mu\\): Overall mean response\n\\(\\tau_{i}\\): Fixed effect of Treatment \\(i\\).\n\\(b_{j}\\):Random effect of Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{b}\\).\n\\((tb)_{ij}\\): Random interaction effect between treatment \\(i\\) and Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{tb}\\).\n\\(\\epsilon_{ijk}\\): Random error term, assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2\\).\n\n\n\nModel Estimation\nSimilar as in the previous lab, we fit the mixed effects model using the lmer() function from the lmeTest package:\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory), data = data_rep_block)\nsummary(model_block)\n\n\nSyntax overview\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory):\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments.\n(1 | Laboratory): This specifies the random effect for laboratory, representing laboratory-specific deviations from the overall mean.\n(1 | Treatment:Laboratory): This specifies the random interaction term between Treatment and Laboratory.\n\n\n\nSummary overview\nWhen we run summary(model_random), the following output is displayed:\n\nFixed Effects\n\nThe intercept represents the overall mean wound healing measure across all treatments and laboratories, which is estimated as 56.47.\nThe coefficient for Treatment1 (-1.04) indicates that the mean wound healing for Treatment A is 1.04 units lower than the overall mean.\nThe coefficient for Treatment2 (1.03) shows that the mean wound healing for Treatment B is 1.03 units higher than the overall mean.\nTreatment C is not directly shown in the output because, with effects coding, the sum of the treatment coefficients must equal zero. Treatment C can be inferred as having a mean very close to the overall mean (around 0.01 units below it).\n\n\n\n\nVariance components\n\nThe random effect for Laboratory has a variance of 1.4462, indicating considerable variability in baseline wound healing levels across different laboratories.\nThe random effect for the Treatment-by-Laboratory Interaction has a variance of 0.4747, showing that the treatment effects vary across laboratories. This means the effectiveness of treatments is not entirely consistent across laboratories, though the variability in this interaction is smaller compared to the variability between laboratory baselines and may not be statistically significant (more about that later).\nThe residual variance is 0.9089, which represents the unexplained variability within each treatment-laboratory combination.\n\n\n\n\n\nAssessing the variance components\nIn our model, the treatment-by-laboratory interaction is modeled as a random effect. To determine whether this variance component is necessary, we perform a likelihood ratio test to compare the full model (i.e., the previously fitted model with both the random laboratory effect and the random treatment-by-laboratory interaction effect) to a reduced model that includes only the random laboratory effect:\n\n# Fit the full model with the random interaction term\nfull_model &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory), \n                   data = data_rep_block)\n\n# Fit the reduced model without the random interaction term\nreduced_model &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), \n                      data = data_rep_block)\n\n# Perform the likelihood ratio test\nanova(full_model, reduced_model, refit=FALSE)\n\nWhen given two or more arguments representing fitted models, the anova() function from the lmerTest package produces likelihood ratio tests to compare these models. By default, these models are refitted using maximum likelihood (ML) estimation, which is suitable for testing fixed effects but not ideal for testing random effects. Random effects are better assessed using restricted maximum likelihood (REML).\nTo keep the REML estimation intact for testing random effects, we use the refit=FALSE argument in the anova() function. This ensures that the models are compared without being refitted using ML.\nThe output provides the likelihood ratio test statistic and p-value, indicating whether the random interaction term significantly improves the model fit.\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the likelihood ratio test, is it necessary to include the random interaction term in the model, or is the simpler model (without the interaction term) sufficient?\n\n\n\n\n\n\n\n\nMaximum Likelihood (ML) versus Restricted Maximum Likelihood (REML) estimation\n\n\n\n\n\n\nMaximum Likelihood (ML): This method estimates all model parameters simultaneously, including both fixed and random effects. It provides unbiased estimates for fixed effects but can lead to biased estimates of the variance components.\nRestricted Maximum Likelihood (REML): REML focuses on estimating variance components while accounting for the loss of degrees of freedom associated with fixed effects. This method provides more accurate estimates of random effects.\n\nEstimates of the fixed effects parameters are generally comparable between ML and REML. However, variance component estimates will typically be larger with REML given that the method was developed to overcome the downward bias of the maximum likelihood estimates of variance components. For this reason, REML is the default estimation approach when fitting mixed effects models with the lmer() function. However, there are also situations where REML cannot be used, particularly during the model-building phase when comparing models with different fixed effects structures. In these cases, the models need to be refitted using ML.\n\n\n\n\n\nAssessing the fixed effects\nThe fixed effects can be assessed using an approach similar to that used in the previous lab. This includes testing for the overall significance of the treatment effect and, if significant, exploring the differences between specific treatment groups through estimated marginal means and pairwise comparisons.\nHowever, before performing these tests, we need to determine which model to use: the full model with the random interaction term or the reduced model without it. This choice is based on the results of the likelihood ratio test performed earlier. If the likelihood ratio test indicates that the random interaction term is necessary, we will use the full model for testing the fixed effects. Conversely, if the likelihood ratio test suggests that the random interaction term is unnecessary, we will use the simpler model without it. This aligns with the general scientific principle of preferring more parsimonious models that adequately explain the data while minimizing complexity.\n\n\nModel diagnostics\nThe process of performing model diagnostics for the replicated randomized block design is the same as for the traditional randomized block design. Therefore, we refer to the previous lab for detailed instructions on assessing model assumptions and performing diagnostic checks."
  },
  {
    "objectID": "BLR_lab_Poisson.html",
    "href": "BLR_lab_Poisson.html",
    "title": "Beyond MLR Lab 7: Poisson regression models",
    "section": "",
    "text": "Asthma exacerbations represent sudden worsening of asthma symptoms, often requiring urgent medical attention. Understanding the factors that increase the frequency of exacerbations can aid in risk assessment and prevention strategies. This case study focuses on analyzing individual-level data to explore how demographic and lifestyle factors contribute to asthma exacerbation rates.\n\n\n\nThe dataset asthma_data.csv contains information for 500 individuals.\nThe columns in the dataset are:\n\nID: Unique identifier for each individual.\nAge: Age of the individual in years.\nSmoking_Status: Smoking status (1 = smoker, 0 = non-smoker).\nExacerbations: Number of asthma exacerbations experienced in one year.\n\nThe dataset is available for download from Brightspace.\n\n\n\n\n\n# Load required packages\nlibrary(ggplot2)\nlibrary(dplyr)\n\nWe begin by loading the dataset and examining its structure:\n\n# Load the dataset\nasthma_data &lt;- read.csv(\"asthma_data.csv\")\n\n# Convert Smoking_Status to a factor\nasthma_data$Smoking_Status &lt;- factor(asthma_data$Smoking_Status, labels = c(\"Non-Smoker\", \"Smoker\"))\n\n# Inspect the structure of the dataset\nstr(asthma_data)\n\nNext, we calculate summary statistics and create a bar chart to visualize the distribution of asthma exacerbations in the population:\n\n# Summary statistics\nasthma_data %&gt;%\n  summarize(\n    Mean_Exacerbations = mean(Exacerbations),\n    Variance_Exacerbations = var(Exacerbations)\n  )\n\n# Bar chart of exacerbation counts\nggplot(asthma_data, aes(x = Exacerbations)) +\n  geom_bar(fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Distribution of Asthma Exacerbations\",\n    x = \"Number of Exacerbations\",\n    y = \"Count of Individuals\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the bar chart and the summary statistics, describe the distribution of asthma exacerbations in the population.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate facetted bar charts showing the distribution of asthma exacerbations, stratified by:\n\nSmoking Status (facet by smoking group: Non-Smoker vs. Smoker).\nAge Groups.\n\nHint: Use the cut() function to create age categories. For example:\n\nasthma_data &lt;- asthma_data %&gt;%\n  mutate(Age_Group = cut(Age, breaks = c(-Inf, 40, 60, Inf), labels = c(\"&lt;40\", \"40-60\", \"&gt;60\")))\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate the mean and variance of the number of exacerbations stratified by smoking status and age groups.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat do the facetted bar charts reveal about differences in the distribution of exacerbations across smoking and age groups?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAre the mean and variance of exacerbations consistent across subgroups? What might this imply about the data or the Poisson model’s assumptions?\n\n\n\n\n\nThe syntax in the code chunk below fits a Poisson regression model to investigate the relationship between asthma exacerbations and age and smoking status:\n\n# Fit the Poisson regression model\npoisson_model &lt;- glm(\n  Exacerbations ~ Age + Smoking_Status,\n  family = poisson(link = \"log\"),\n  data = asthma_data\n)\n\n# View the model summary\nsummary(poisson_model)\n\nExplanation of the code:\n\nglm() function: Fits a generalized linear model (GLM) to the data.\nExacerbations ~ Age + Smoking_Status: Specifies the outcome (Exacerbations) and predictors (Age and Smoking_Status).\nfamily = poisson(link = \"log\"): Indicates that the model uses the Poisson distribution with a log link function.\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the intercept of the model represent in this context?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nInterpret the coefficient for Smoking_Status. How does smoking affect the expected number of asthma exacerbations?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nInterpret the coefficient for Age. How does an increase in age affect the expected number of asthma exacerbations?\n\n\n\n\n\nTo evaluate the model fit, we calculate the Pearson residuals. These residuals measure the standardized difference between observed and predicted counts:\n\nFormula: \\(r_i = \\frac{Y_i - \\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}\\), where:\n\n\\(Y_i\\): Observed counts\n\\(\\hat{\\lambda}_i\\): Predicted counts\n\n\n\n# Calculate Pearson residuals\nasthma_data$Pearson_Residuals &lt;- residuals(poisson_model, type = \"pearson\")\n\nNext, we assess the goodness-of-fit using the chi-square test:\n\nTest statistic: \\(\\chi^2 = \\sum r_i^2 = \\sum \\frac{(Y_i - \\hat{\\lambda}_i)^2}{\\hat{\\lambda}_i}\\)\nDegrees of freedom: \\(\\text{df} = n - p\\), where:\n\n\\(n\\): Number of observations.\n\\(p\\): Number of model parameters (including intercept).\n\n\n\n# Calculate chi-square test statistic\nchisq_test &lt;- sum(asthma_data$Pearson_Residuals^2)\n\n# Degrees of freedom\ndf &lt;- nrow(asthma_data) - length(coef(poisson_model))\n\n# p-value\np_value &lt;- 1 - pchisq(chisq_test, df)\n\n# Display results\nlist(Chi_Square_Statistic = chisq_test, Degrees_of_Freedom = df, P_Value = p_value)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the chi-square test tell us about the goodness-of-fit of the Poisson regression model?"
  },
  {
    "objectID": "BLR_lab_Poisson.html#exploratory-data-analysis",
    "href": "BLR_lab_Poisson.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 7: Poisson regression models",
    "section": "",
    "text": "# Load required packages\nlibrary(ggplot2)\nlibrary(dplyr)\n\nWe begin by loading the dataset and examining its structure:\n\n# Load the dataset\nasthma_data &lt;- read.csv(\"asthma_data.csv\")\n\n# Convert Smoking_Status to a factor\nasthma_data$Smoking_Status &lt;- factor(asthma_data$Smoking_Status, labels = c(\"Non-Smoker\", \"Smoker\"))\n\n# Inspect the structure of the dataset\nstr(asthma_data)\n\nNext, we calculate summary statistics and create a bar chart to visualize the distribution of asthma exacerbations in the population:\n\n# Summary statistics\nasthma_data %&gt;%\n  summarize(\n    Mean_Exacerbations = mean(Exacerbations),\n    Variance_Exacerbations = var(Exacerbations)\n  )\n\n# Bar chart of exacerbation counts\nggplot(asthma_data, aes(x = Exacerbations)) +\n  geom_bar(fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Distribution of Asthma Exacerbations\",\n    x = \"Number of Exacerbations\",\n    y = \"Count of Individuals\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the bar chart and the summary statistics, describe the distribution of asthma exacerbations in the population.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate facetted bar charts showing the distribution of asthma exacerbations, stratified by:\n\nSmoking Status (facet by smoking group: Non-Smoker vs. Smoker).\nAge Groups.\n\nHint: Use the cut() function to create age categories. For example:\n\nasthma_data &lt;- asthma_data %&gt;%\n  mutate(Age_Group = cut(Age, breaks = c(-Inf, 40, 60, Inf), labels = c(\"&lt;40\", \"40-60\", \"&gt;60\")))\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate the mean and variance of the number of exacerbations stratified by smoking status and age groups.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat do the facetted bar charts reveal about differences in the distribution of exacerbations across smoking and age groups?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nAre the mean and variance of exacerbations consistent across subgroups? What might this imply about the data or the Poisson model’s assumptions?"
  },
  {
    "objectID": "BLR_lab_Poisson.html#fitting-a-poisson-regression-model",
    "href": "BLR_lab_Poisson.html#fitting-a-poisson-regression-model",
    "title": "Beyond MLR Lab 7: Poisson regression models",
    "section": "",
    "text": "The syntax in the code chunk below fits a Poisson regression model to investigate the relationship between asthma exacerbations and age and smoking status:\n\n# Fit the Poisson regression model\npoisson_model &lt;- glm(\n  Exacerbations ~ Age + Smoking_Status,\n  family = poisson(link = \"log\"),\n  data = asthma_data\n)\n\n# View the model summary\nsummary(poisson_model)\n\nExplanation of the code:\n\nglm() function: Fits a generalized linear model (GLM) to the data.\nExacerbations ~ Age + Smoking_Status: Specifies the outcome (Exacerbations) and predictors (Age and Smoking_Status).\nfamily = poisson(link = \"log\"): Indicates that the model uses the Poisson distribution with a log link function.\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the intercept of the model represent in this context?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nInterpret the coefficient for Smoking_Status. How does smoking affect the expected number of asthma exacerbations?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nInterpret the coefficient for Age. How does an increase in age affect the expected number of asthma exacerbations?"
  },
  {
    "objectID": "BLR_lab_Poisson.html#evaluating-model-fit-pearson-residuals-and-goodness-of-fit",
    "href": "BLR_lab_Poisson.html#evaluating-model-fit-pearson-residuals-and-goodness-of-fit",
    "title": "Beyond MLR Lab 7: Poisson regression models",
    "section": "",
    "text": "To evaluate the model fit, we calculate the Pearson residuals. These residuals measure the standardized difference between observed and predicted counts:\n\nFormula: \\(r_i = \\frac{Y_i - \\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}\\), where:\n\n\\(Y_i\\): Observed counts\n\\(\\hat{\\lambda}_i\\): Predicted counts\n\n\n\n# Calculate Pearson residuals\nasthma_data$Pearson_Residuals &lt;- residuals(poisson_model, type = \"pearson\")\n\nNext, we assess the goodness-of-fit using the chi-square test:\n\nTest statistic: \\(\\chi^2 = \\sum r_i^2 = \\sum \\frac{(Y_i - \\hat{\\lambda}_i)^2}{\\hat{\\lambda}_i}\\)\nDegrees of freedom: \\(\\text{df} = n - p\\), where:\n\n\\(n\\): Number of observations.\n\\(p\\): Number of model parameters (including intercept).\n\n\n\n# Calculate chi-square test statistic\nchisq_test &lt;- sum(asthma_data$Pearson_Residuals^2)\n\n# Degrees of freedom\ndf &lt;- nrow(asthma_data) - length(coef(poisson_model))\n\n# p-value\np_value &lt;- 1 - pchisq(chisq_test, df)\n\n# Display results\nlist(Chi_Square_Statistic = chisq_test, Degrees_of_Freedom = df, P_Value = p_value)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the chi-square test tell us about the goodness-of-fit of the Poisson regression model?"
  },
  {
    "objectID": "BLR_lab_longitudinal.html",
    "href": "BLR_lab_longitudinal.html",
    "title": "Beyond MLR Lab 6: Longitudinal data analysis",
    "section": "",
    "text": "In this lab, we will explore the analysis of longitudinal data using linear mixed-effects models. Longitudinal data involve repeated measurements taken on the same subjects over time, allowing us to study changes in outcomes within individuals."
  },
  {
    "objectID": "BLR_lab_longitudinal.html#dataset-description",
    "href": "BLR_lab_longitudinal.html#dataset-description",
    "title": "Beyond MLR Lab 6: Longitudinal data analysis",
    "section": "Dataset description",
    "text": "Dataset description\nThe dataset contains the following variables:\n\nOutcome variable:\n\nalcuse: Continuous measure of alcohol use based on various survey items.\n\nGrouping variable:\n\nid: Unique identifier for each adolescent in the study.\n\n\nCovariates:\n\ncoa: Dichotomous variable indicating parental alcoholism (1 = yes, 0 = no).\nmale: Dichotomous variable indicating male gender (1 = yes, 0 = no).\npeer: Continuous measure of peer alcohol use, assessed at age 14.\nage: Numerical variable representing the age of the adolescent at each time point (14, 15, 16)."
  },
  {
    "objectID": "BLR_lab_longitudinal.html#research-question",
    "href": "BLR_lab_longitudinal.html#research-question",
    "title": "Beyond MLR Lab 6: Longitudinal data analysis",
    "section": "Research question",
    "text": "Research question\nIn this lab, we are going to address the following research question:\n\nDoes being a child of an alcoholic parent influence the level and change in alcohol use from ages 14 to 16?"
  },
  {
    "objectID": "BLR_lab_longitudinal.html#data-import-cleaning-and-inspection",
    "href": "BLR_lab_longitudinal.html#data-import-cleaning-and-inspection",
    "title": "Beyond MLR Lab 6: Longitudinal data analysis",
    "section": "Data import, cleaning, and inspection",
    "text": "Data import, cleaning, and inspection\n\n# Load the required libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lmerTest)\nlibrary(haven)\n\n# Load the adolescent alcohol use data. Note that the call below assumes the dataset is placed in the 'data' folder directly above the root folder of the project. Update the string as needed if the file is located elsewhere. Because the dataset is in SPSS format, we use the `haven` package to import it:\nalcohol_data &lt;- read_sav(\"data/alcoholpp.sav\")\n\n# Convert the dummy coded dichotomous variables into factors\nalcohol_data &lt;- alcohol_data %&gt;%\n  mutate(\n    coa = as.factor(coa),\n    male = as.factor(male),\n  )\n\n# Inspect the structure of the dataset\nstr(alcohol_data)"
  },
  {
    "objectID": "BLR_lab_longitudinal.html#exploratory-data-analysis",
    "href": "BLR_lab_longitudinal.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 6: Longitudinal data analysis",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nIndividual trajectories of alcohol use\nWe will start by examining the individual trajectories of alcohol use over time. One way to achieve this is a facet plot, which displays each individual’s trajectory in a separate subplot. In this case, however, the dataset consists of 82 individuals, making it impractical to display all trajectories. We therefore take a random sample of 16 individuals for visualization.\n\nset.seed(123)  # Set seed for reproducibility\n\n# Sample 16 unique individuals\nsampled_ids &lt;- sample(1:82, 16)\n\n# Filter dataset for the sampled IDs and plot\nalcohol_data %&gt;%\n  filter(id %in% sampled_ids) %&gt;%\n  ggplot(aes(x = age, y = alcuse)) +\n  geom_line() +                               # Add trajectories (lines)\n  geom_point(size = 2, alpha = 0.7) +         # Add individual data points (dots)\n  facet_wrap(~ id) +                          # Create a subplot for each individual\n  labs(\n    title = \"Individual Alcohol Use Trajectories with Data Points\",\n    x = \"Age\",\n    y = \"Alcohol Use\"\n  ) +\n  theme_minimal()\n\n\nObservations:\n\nMany adolescents report no alcohol use (alcuse = 0) across all time points.\nFor adolescents who do report alcohol use, the trajectories vary, with some increasing, decreasing, or remaining relatively stable over time.\nThis variability underscores the need for statistical models, such as linear mixed-effects models, to account for differences both within and between individuals.\n\n\n\n\n\n\n\nDisclaimer\n\n\n\nThe dataset used in this lab is zero-inflated, with a large number of zero alcohol use values. While linear mixed-effects models are not necessarily the best approach for analyzing such data, we will use them in this lab to focus on the methodology. The results derived in this lab are intended for educational purposes only.\n\n\n\n\n\nMean trajectories by parental alcoholism\nNext, we will examine the mean trajectories of alcohol use by parental alcoholism (COA). This will provide an overview of how this variable relates to alcohol use over time.\n\n# Compute the mean alcohol use by age, and COA status\nmean_alcuse &lt;- alcohol_data %&gt;%\n  group_by(age, coa) %&gt;%\n  summarise(mean_alcuse = mean(alcuse, na.rm = TRUE))\n\n# Plot the mean trajectories by COA \nggplot(mean_alcuse, aes(x = age, y = mean_alcuse, color = coa)) +\n  geom_line() +\n  labs(\n    title = \"Mean Alcohol Use Trajectories by Parental Alcoholism\",\n    x = \"Age\",\n    y = \"Mean Alcohol Use\"\n  ) +\n  scale_color_manual(values = c(\"0\" = \"blue\", \"1\" = \"red\")) +\n  ylim(0, 3) +\n  theme_minimal()\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the plot, do you expect there to be a main effect of parental alcoholism (COA) or age on alcohol use?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo you expect there to be an interaction effect between COA and age? Explain your reasoning based on the trends shown in the plot.\n\n\n\n\nRandom intercept model\nWe will start by fitting a random intercept model to the data. This model assumes that each individual has a unique baseline level of alcohol use at age 14, which varies randomly around the population mean. The model can be specified as follows:\n\n# Center age at 14 for interpretability\nalcohol_data$age_centered &lt;- alcohol_data$age - 14\n\n# Fit a random intercept model with age centered at 14 and coa\nrandom_intercept_model &lt;- lmer(alcuse ~ age_centered*coa + (1 | id), data = alcohol_data)\nsummary(random_intercept_model)\n\n\n\n\n\n\n\nQuestion\n\n\n\nCalculate the ICC based on the estimated variance components. What proportion of variance in alcohol use is due to differences between individuals?\n\n\n\n\nRandom slope model\nTo extend the previous model to include a random slope, we specify (1 + age_centered | id) in the model formula:\n\n# Fit the random slope model\nrandom_slope_model &lt;- lmer(alcuse ~ age_centered*coa + (1 + age_centered | id), data = alcohol_data)\n\n# Display the summary of the model\nsummary(random_slope_model)\n\nWe begin by assessing the variance components of the model. In addition to including a random intercept for the grouping variable id, the model now incorporates a random slope for the age_centered variable. This allows the rate of change in alcohol use with age to vary across individuals. Furthermore, the model includes a term for the correlation between the random intercept and the random slope, which captures the relationship between an individual’s baseline level of alcohol use and their rate of change over time. This correlation provides insight into whether individuals with higher initial levels of alcohol use are more likely to increase or decrease their usage as they age.\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the estimated correlation between the random intercept and random slope tell us about the relationship between baseline alcohol use and the rate of change over time?\n\n\nThe inclusion of the correlation between the random intercept and the random slope arises from how we specified the formula object in the model. By default, the random effects are modeled as a multivariate normal distribution, allowing for the estimation of a correlation between the intercept and slope. However, an alternative specification is also possible, where the random intercept and random slope are assumed to be independent. This can be achieved by using a formula that separates the random intercept and slope terms, such as (1 | id) + (0 + age_centered | id). Such a model may be appropriate if there is no theoretical or empirical justification for expecting a relationship between baseline levels and rates of change, or if simplifying the model does not significantly worsen model fit, which can be tested for using a Likelihood ratio test.\nHere, we focus on comparing the random slope model against the previously fitted random intercept model. This approach allows us to evaluate whether modeling individual trajectories with these additional random effects provides a significantly better fit to the data compared to a simpler model that accounts only for variability in baseline alcohol use.\n\n# Perform the likelihood ratio test\nanova(random_intercept_model, random_slope_model, refit = FALSE)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the likelihood ratio test tell us about the comparison between the random intercept and random slope models?\n\n\n\n\nAssessing the fixed effects structure\nNow that we have determined an appropriate structure for the random effects, we turn our attention to evaluating the fixed effects. The fixed effects represent the average relationships between the predictors and the outcome variable across all individuals in the study. Specifically, this includes the main effects of age_centered and coa as well as their interaction. By assessing the fixed effects, we aim to determine whether these predictors significantly contribute to explaining variation in alcohol use and whether their inclusion aligns with our theoretical expectations.\nTo determine whether the relationship between age and alcohol use differs depending on coa status, we start by testing the interaction effect between age_centered and coa:\n\n# Obtain the ANOVA table for the random slope model\nanova(random_slope_model)\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the ANOVA table, what can you conclude about the interaction effect between age_centered and coa on alcohol use?\n\n\nBecause the interaction effect is insignificant, we can simplify the model by removing this term. We then refit the model and assess the main effects of age_centered and coa:\n\n# Fit the simplified model without the interaction term\nsimplified_model &lt;- lmer(alcuse ~ age_centered + coa + (1 + age_centered | id), data = alcohol_data)\nsummary(simplified_model)\n\n# Obtain the ANOVA table for the simplified model\nanova(simplified_model, refit=TRUE)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat can you conclude about the main effects of age and parental alcoholism on adolescent alcohol use based on the simplified model?"
  },
  {
    "objectID": "BLR_lab_longitudinal.html#model-building-principles-for-longitudinal-data-analysis",
    "href": "BLR_lab_longitudinal.html#model-building-principles-for-longitudinal-data-analysis",
    "title": "Beyond MLR Lab 6: Longitudinal data analysis",
    "section": "Model building principles for longitudinal data analysis",
    "text": "Model building principles for longitudinal data analysis\nModel building for longitudinal data analysis follows a systematic approach to ensure that the final model is both parsimonious and adequately represents the data. The process typically involves the following steps:\n\nStart with a saturated fixed-effects structure and a complex random-effects structure\n\nA saturated fixed-effects structure includes all plausible predictors and their interactions based on theoretical considerations and prior knowledge. This ensures that no potentially important effect is excluded at the outset.\nA complex random-effects structure allows for a flexible representation of variability in the data. For example, random intercepts and random slopes are included to account for between-subject variability and other grouping factors.\n\nThis initial specification provides a robust starting point for model refinement, ensuring the inclusion of all meaningful variability in the model.\nDetermine the appropriate random-effects structure\n\nSimplify the random-effects structure by comparing models with different random-effects terms using likelihood ratio tests (LRTs).\nImportantly, these comparisons are made without refitting the models using maximum likelihood (ML). Restricted maximum likelihood (REML) is retained during this step to ensure accurate estimation of variance components.\nRemove unnecessary random-effects terms to avoid overfitting while retaining terms that account for substantial variability in the data.\n\nSimplify the fixed-effects structure\n\nStarting from the saturated fixed-effects structure combined with the final reduced random-effects structure, iteratively remove non-significant fixed effects.\nFor fixed-effects structure refinement, models must be refitted using ML rather than REML. This ensures correct inference for hypothesis testing and comparison of nested models.\nOnce the final fixed-effects structure is determined, the model can be refitted using REML for final parameter estimation.\n\n\n\nAdditional considerations for model comparison\nThe model building principles described above apply specifically to the comparison of nested models, where one model is a special case of another (e.g., a simpler model can be obtained by constraining parameters in the more complex model). In such cases, likelihood ratio tests (LRTs) provide a robust framework for selecting between models.\nHowever, when comparing non-nested models, where one model cannot be derived from the other by parameter constraints, LRTs are not appropriate. Instead, model selection criteria such as Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC) should be used. These criteria provide a balance between model fit and complexity, aiding in the selection of the most parsimonious model that adequately represents the data."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html",
    "href": "Assignments/Week 5/Assignment_week_5.html",
    "title": "Assignment Week 5",
    "section": "",
    "text": "In this assignment, you will analyze multilevel data to describe the development of students’ English and Mathematics test scores over time. The data come from the Junior School Project (Mortimore et al.), which examines factors influencing academic progress in junior schools. There are over 1000 students measured over three school years with 3236 records included in this dataset.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#introduction",
    "href": "Assignments/Week 5/Assignment_week_5.html#introduction",
    "title": "Assignment Week 5",
    "section": "",
    "text": "In this assignment, you will analyze multilevel data to describe the development of students’ English and Mathematics test scores over time. The data come from the Junior School Project (Mortimore et al.), which examines factors influencing academic progress in junior schools. There are over 1000 students measured over three school years with 3236 records included in this dataset.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#dataset-description",
    "href": "Assignments/Week 5/Assignment_week_5.html#dataset-description",
    "title": "Assignment Week 5",
    "section": "Dataset description",
    "text": "Dataset description\nThe dataset consists of the following variables:\n\nSchool: School ID.\nStudent.ID: Student ID.\nGender: A categorical variable representing the gender of the student\nJunior.school.year: Year of the study (0, 1, or 2).\nEnglish.test: English test score in year 1.\nMathematics.test: Mathematics test score in year 1.\n\nThe dataset can be downloaded from the link provided in the Downloads section below. When reading the dataset into R, ensure that the Gender variable is correctly encoded as a factor."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#objectives",
    "href": "Assignments/Week 5/Assignment_week_5.html#objectives",
    "title": "Assignment Week 5",
    "section": "Objectives",
    "text": "Objectives\nYour objectives are to:\n\nDevelop an appropriate model to describe the development of students’ English test scores over time\n\nInclude random intercepts to account for the nesting of longitudinal measurements within students and the subsequent nesting of students within schools\nExplore systematic differences in the mean “growth curves” of English test scores over time between boys and girls\nConsider interaction terms such as Gender * Junior.school.year to explore gender-specific trends\n\nDevelop an appropriate model to describe the development of students’ Mathematics test scores over time\n\nInclude random intercepts to account for the nesting of longitudinal measurements within students and the subsequent nesting of students within schools\nExplore systematic differences in the mean “growth curves” of Mathematics test scores over time between boys and girls\nConsider interaction terms such as Gender * Junior.school.year to explore gender-specific trends"
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#requirements-for-the-report",
    "href": "Assignments/Week 5/Assignment_week_5.html#requirements-for-the-report",
    "title": "Assignment Week 5",
    "section": "Requirements for the report",
    "text": "Requirements for the report\nYour report should clearly explain:\n\nThe reasoning behind your choice of model structure, supported by the results of the exploratory data analysis\nThe interpretation of key model parameters in the context of the research questions\nAny limitations or assumptions affecting your analysis\n\nSubmit both the Quarto source file (.qmd) and the rendered HTML file.\n\n\n\n\n\n\nTip\n\n\n\nThe time variable Junior.school.year is represented as a continuous variable in the dataset. However, you may transform it into a categorical variable in your analysis if you find it more appropriate. For example, you could treat it as a factor with three levels (0, 1, and 2) to represent the three years of the study. This transformation may help you interpret the results more easily.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhile conceptually it is possible to also include a random slope for the time variable in your models, you are not required to do so for this assignment (depending on the coding of the time variable, there are either not sufficient degrees of freedom to fit this model or you may run into convergence/boundary fit issues. You may therefore focus on random intercepts to keep the analysis manageable."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#downloads",
    "href": "Assignments/Week 5/Assignment_week_5.html#downloads",
    "title": "Assignment Week 5",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html",
    "href": "Assignments/Week 3/Assignment_week_3.html",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "",
    "text": "In this assignment, you will analyze a dataset collected by the Inner London Education Authority (ILEA) to examine the effectiveness of schools. The dataset consists of examination records of 15,362 students from 140 secondary schools over the years 1985, 1986, and 1987. This dataset was sourced from the data library of the Centre for Multilevel Modelling at the University of Bristol."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#introduction",
    "href": "Assignments/Week 3/Assignment_week_3.html#introduction",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "",
    "text": "In this assignment, you will analyze a dataset collected by the Inner London Education Authority (ILEA) to examine the effectiveness of schools. The dataset consists of examination records of 15,362 students from 140 secondary schools over the years 1985, 1986, and 1987. This dataset was sourced from the data library of the Centre for Multilevel Modelling at the University of Bristol."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#dataset-description",
    "href": "Assignments/Week 3/Assignment_week_3.html#dataset-description",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Dataset Description",
    "text": "Dataset Description\nThe dataset consists of the following variables:\n\nSchool: A numeric variable representing the school identifier (codes 1 to 139)\nExamScore: A numeric variable representing the exam score of each student\nPercentFSM: The percentage of students in the school eligible for free school meals (an indicator of socioeconomic status)\nGender: A categorical variable representing the gender of the student\nVRBand: The verbal reasoning band of the student (VR1, VR2, or VR3). VR band is an indicator of the student’s assessed ability level, with VR1 typically representing the highest ability group, VR2 representing intermediate ability, and VR3 representing lower ability.\nSchoolDenomination: The denomination of the school (Maintained, Church of England, Roman Catholic)"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#objective",
    "href": "Assignments/Week 3/Assignment_week_3.html#objective",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Objective",
    "text": "Objective\nYour goals are to determine:\n\nHow much of the variability in exam scores can be attributed to:\n\nDifferences between students\nDifferences between schools\n\nWhether individual-level factors (e.g., Gender, VRBand) significantly influence student exam scores\nWhether school-level factors (e.g., PercentFSM) significantly influence student exam scores"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 3/Assignment_week_3.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Steps to Complete the Analysis",
    "text": "Steps to Complete the Analysis\n\nLoad the Dataset\nDownload the dataset (see link in the Downloads section below) and read it into R. Make sure all character variables are correctly encoded as factors.\n\n\nExploratory Data Analysis (EDA):\n\nVisualize the nesting structure of the data (i.e., number of students per school)\nExplore the distribution of the outcome variable (ExamScore)\n\n\n\nMulti-Level Modeling\n\nStart by fitting a null model (i.e., a random intercept model without any predictors) to partition the variance in exam scores between students and schools. Assess how much of the variability in exam scores is due to differences between students and schools.\nNext, add individual-level variables (Gender, VRBand) to the model to explore how these factors influence exam scores.\nAfter that, add context-level variables (e.g., PercentFSM) to your model to understand how factors at the school level contribute to differences in exam scores.\nFinally, explore potential cross-level interactions between individual-level and context-level variables.\n\n\n\nInterpret the Results\nInterpret the findings from your analysis, focusing on the variance components and the effects of individual-level and context-level variables."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#requirements-for-the-report",
    "href": "Assignments/Week 3/Assignment_week_3.html#requirements-for-the-report",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The HTML file should be rendered with code visibility enabled (echo = TRUE)."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#downloads",
    "href": "Assignments/Week 3/Assignment_week_3.html#downloads",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html",
    "href": "Assignments/Week 1/Assignment_week_1.html",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that examines the effect of different rehabilitation programs on the mobility of stroke patients. The dataset includes mobility improvement measurements taken using the 6-Minute Walk Test (6MWT), a standard assessment to evaluate physical mobility and endurance.\nPatients in the study were randomly assigned to one of three rehabilitation programs:\n\nControl: Standard physical therapy.\nRobotic-Assisted Therapy: Rehabilitation involving robotic devices designed to support movement.\nAquatic Therapy: Water-based exercises aimed at improving mobility with reduced joint stress."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#introduction",
    "href": "Assignments/Week 1/Assignment_week_1.html#introduction",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that examines the effect of different rehabilitation programs on the mobility of stroke patients. The dataset includes mobility improvement measurements taken using the 6-Minute Walk Test (6MWT), a standard assessment to evaluate physical mobility and endurance.\nPatients in the study were randomly assigned to one of three rehabilitation programs:\n\nControl: Standard physical therapy.\nRobotic-Assisted Therapy: Rehabilitation involving robotic devices designed to support movement.\nAquatic Therapy: Water-based exercises aimed at improving mobility with reduced joint stress."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#objective",
    "href": "Assignments/Week 1/Assignment_week_1.html#objective",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Objective",
    "text": "Objective\nYour objective is to determine whether there is a statistically significant difference in mobility improvement among the three rehabilitation groups. To complete this analysis, follow these steps:\n\nExplore the Data: Perform an exploratory data analysis (EDA) to understand the distribution of mobility improvements across treatment groups.\nFit a One-Way ANOVA Model: Fit a one-way ANOVA model to test for overall group differences.\nPost-Hoc Comparisons: If you identify significant group differences, calculate estimated marginal means and conduct post-hoc comparisons to determine which groups differ.\nModel Diagnostics: Conduct diagnostic tests and visualizations to evaluate model assumptions, including homoscedasticity and normality of residuals."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#requirements-for-the-report",
    "href": "Assignments/Week 1/Assignment_week_1.html#requirements-for-the-report",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The quarto source file should include all R code and annotations, and the html file should be rendered with code visibility enabled (echo = TRUE, which is the default option). The Quarto file in the downloads section below provides a starter template that you can use for this assignment."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#downloads",
    "href": "Assignments/Week 1/Assignment_week_1.html#downloads",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Downloads",
    "text": "Downloads\n\nDownload dataset\nDownload Quarto Template"
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html",
    "href": "Assignments/Week 2/Assignment_week_2.html",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that evaluates the effectiveness of different exercise routines on improving functional mobility in patients recovering from knee replacement surgery. The study uses a replicated randomized block design to account for individual variability among patients.\nEach patient participated in all three exercise routines, and each routine was performed three times. Functional mobility was assessed after each session, with scores ranging from 40 to 80 (higher scores indicate better mobility). The dataset contains 54 observations (6 patients x 3 routines x 3 replications) and is provided in the downloads section below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#introduction",
    "href": "Assignments/Week 2/Assignment_week_2.html#introduction",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that evaluates the effectiveness of different exercise routines on improving functional mobility in patients recovering from knee replacement surgery. The study uses a replicated randomized block design to account for individual variability among patients.\nEach patient participated in all three exercise routines, and each routine was performed three times. Functional mobility was assessed after each session, with scores ranging from 40 to 80 (higher scores indicate better mobility). The dataset contains 54 observations (6 patients x 3 routines x 3 replications) and is provided in the downloads section below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#dataset-description",
    "href": "Assignments/Week 2/Assignment_week_2.html#dataset-description",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Dataset Description",
    "text": "Dataset Description\nThe dataset consists of the following variables:\n\nPatient: A numeric variable representing individual patients (blocks).\nExerciseRoutine: A factor variable representing the type of exercise routine:\n\nA: Low-impact walking exercises.\nB: Resistance training exercises.\nC: Balance and flexibility exercises.\n\nFunctionalMobility: A numeric variable (40-80) representing the mobility score measured after each session."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#objective",
    "href": "Assignments/Week 2/Assignment_week_2.html#objective",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Objective",
    "text": "Objective\nYour goal is to determine:\n\nWhether there are significant differences in functional mobility scores between the three exercise routines.\nHow much of the variability in mobility scores can be attributed to:\n\nDifferences between patients.\nDifferences between exercise routines.\nResidual variability (within patient-treatment combinations).\n\n\nTo complete this analysis, follow the detailed steps outlined below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 2/Assignment_week_2.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Steps to Complete the Analysis",
    "text": "Steps to Complete the Analysis\n\n1. Load the dataset\nWhen loading the dataset in R, ensure that the ExerciseRoutine variable is treated as a factor. One way to achieve this is by specifying the column type explicitly using the colClasses argument in the read.csv() function. For example:\n\n# Load the dataset and specify ExerciseRoutine as a factor\ndataset &lt;- read.csv(\"functional_mobility.csv\", colClasses = c(\"ExerciseRoutine\" = \"factor\"))\n\n\n\n2. Perform an Exploratory Data Analysis (EDA)\n\nVisualize the data using an interaction plot.\nCalculate descriptive statistics for each exercise routine and patient.\n\n\n\n3. Fit a Mixed-Effects Model\n\nFit a mixed-effects model with:\n\nFixed Effects: ExerciseRoutine (to estimate differences between exercise routines).\nRandom Effects:\n\nPatient (to account for variability between individuals).\nPatient × ExerciseRoutine (to account for potential variability in how patients respond to different routines).\n\n\nTest whether the Patient × ExerciseRoutine random interaction term is necessary by comparing the full model (with the interaction term) to a reduced model (without the interaction term).\nBased on the results of this test:\n\nIf the interaction term is significant, proceed with the full model for further analysis.\nIf the interaction term is not significant, proceed with the reduced model.\n\nSummarize the chosen model:\n\nReport the fixed effects and variance components.\n\n\n\n\n4. Test for Overall Differences\n\nUse the selected model to test for overall differences in functional mobility scores across exercise routines.\n\n\n\n5. Perform Pairwise Comparisons\n\nIf significant overall differences are found, calculate estimated marginal means and perform pairwise comparisons to identify which routines differ.\n\n\n\n6. Evaluate Model Assumptions\n\nAssess the model’s assumptions (e.g., normality of residuals, homoscedasticity) using diagnostic plots."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#requirements-for-the-report",
    "href": "Assignments/Week 2/Assignment_week_2.html#requirements-for-the-report",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The quarto source file should include all R code and annotations, and the html file should be rendered with code visibility enabled (echo = TRUE)."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#downloads",
    "href": "Assignments/Week 2/Assignment_week_2.html#downloads",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html",
    "href": "Assignments/Week 4/Assignment_week_4.html",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "",
    "text": "You will work with longitudinal data from a growth curve study. The dataset captures weight measurements of 568 Asian children, recorded during clinic visits on up to five occasions. Ages range from approximately 6 weeks to 27 months. Your task is to model the children’s growth trajectories over time.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#introduction",
    "href": "Assignments/Week 4/Assignment_week_4.html#introduction",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "",
    "text": "You will work with longitudinal data from a growth curve study. The dataset captures weight measurements of 568 Asian children, recorded during clinic visits on up to five occasions. Ages range from approximately 6 weeks to 27 months. Your task is to model the children’s growth trajectories over time.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#dataset-description",
    "href": "Assignments/Week 4/Assignment_week_4.html#dataset-description",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Dataset description",
    "text": "Dataset description\nThe dataset consists of the following variables:\n\nChildID: Unique identifier for each child\nAge: Child’s age at the time of measurement (months)\nWeight: Child’s weight at the time of measurement (grams)\nGender: Child’s gender (Boy or Girl)"
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#objectives",
    "href": "Assignments/Week 4/Assignment_week_4.html#objectives",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Objectives",
    "text": "Objectives\nYour objectives are to:\n\nDevelop an appropriate model to describe the growth curve of children’s weight over time, considering fixed and random effects.\nUse the model to answer the following research questions:\n\nHow does the weight of children change over time (e.g., constant, linear, quadratic)?\nHow does gender influence the mean growth curve of children’s weight?"
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 4/Assignment_week_4.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Steps to complete the analysis",
    "text": "Steps to complete the analysis\n\nLoad the dataset\nDownload the dataset (see link in the Downloads section below) and read it into R. Ensure that the Gender variable is correctly encoded as a factor.\n\n\nExploratory data analysis\n\nExplore the individual and mean trajectories of weight gain over time.\n\n\n\nModel building\n\nBegin with a comprehensive (saturated) model and iteratively simplify it to determine the best fixed and random effects structure.\nUse likelihood ratio tests to refine random effects (models not refitted with ML).\nUse likelihood ratio tests with models refitted using ML to refine fixed effects.\n\n\n\nInterpret the results\nInterpret the findings from your analysis, focusing on answering the research questions outlined in the Objectives section."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#requirements-for-the-report",
    "href": "Assignments/Week 4/Assignment_week_4.html#requirements-for-the-report",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Requirements for the report",
    "text": "Requirements for the report\nYour report should clearly explain:\n\nThe reasoning behind your choice of model structure.\nThe interpretation of key model parameters in the context of the research questions.\nAny limitations or assumptions affecting your analysis.\n\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. Ensure that the HTML file includes visible code (echo = TRUE) for reproducibility."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#downloads",
    "href": "Assignments/Week 4/Assignment_week_4.html#downloads",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html",
    "href": "BLR_lab_FE_oneway.html",
    "title": "Beyond MLR Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "Welcome to lab 1 of the Beyond MLR course. In this lab, we make use of the following R packages: gglot2, dplyr, and emmeans. You can use the script below to check if these packages are installed. Any missing packages can be installed using install.packages(\"package_name\").\npackages &lt;- c(\"dplyr\", \"ggplot2\", \"emmeans\")\n\ninstalled &lt;- sapply(packages, requireNamespace, quietly = TRUE)\nif (all(installed)) {\n  message(\"All packages are installed.\")\n} else {\n  missing &lt;- names(installed)[!installed]\n  message(\"The following packages are not installed: \", paste(missing, collapse = \", \"))\n}"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "href": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo understand the distribution of blood pressure reduction across treatment groups, we start by creating a boxplot:\n\n# Visualizing the results\nlibrary(ggplot2)\nggplot(data_oneway, aes(x = Treatment, y = BP_Reduction, fill = Treatment)) +\n  geom_boxplot() +\n  labs(title = \"Blood Pressure Reduction by Treatment\",\n       x = \"Treatment\", y = \"Blood Pressure Reduction (mm Hg)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\nWe also calculate some summary statistics:\n\n# Summarizing data\nlibrary(dplyr)\nsummary_stats &lt;- data_oneway %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_BP_Reduction = mean(BP_Reduction),\n    SD_BP_Reduction = sd(BP_Reduction)\n  )\n\nsummary_stats\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the mean blood pressure reductions compare among the treatment groups?"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "href": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "title": "Beyond MLR Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "Performing a One-Way ANOVA",
    "text": "Performing a One-Way ANOVA\n\nModel Specification\nUsing effects coding, the one-way Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The blood pressure reduction for the \\(j\\)-th patient in the \\(i\\)-th treatment group.\n\\(\\mu\\): The overall mean blood pressure reduction.\n\\(\\tau_i\\): The effect of the \\(i\\)-th treatment (deviation from the overall mean).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and constant variance.\n\n\n\n\n\n\n\nNote 1: Coding schemes for categorical variables\n\n\n\nIn regression models, categorical variables are represented using coding schemes that allow their inclusion as explanatory variables. In R, dummy coding is the default coding scheme for nominal variables, where each level is compared to a reference category. For ordinal variables (i.e., ordered factors), R uses orthogonal polynomials as the default coding scheme, which can capture linear or nonlinear trends across ordered levels.\nWhile dummy coding is widely used in multiple linear regression models, effects coding is more common in ANOVA models, as it enables interpretation of group differences relative to the grand mean rather than a single reference category. This interpretative difference makes effects coding particularly useful for examining group-level effects in experimental designs.\nTo change the coding scheme globally to effects coding:\n\n# Set contrasts to effects coding globally\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nTo reset the coding scheme to the default dummy coding:\n\n# Reset contrasts to default dummy coding\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))  # Dummy coding\n\n\n\n\n\nModel Estimation\nWe can fit the one-way ANOVA model using the lm() function:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\n# Fitting the model with effects coding\nmodel_oneway &lt;- lm(BP_Reduction ~ Treatment, data = data_oneway)\nsummary(model_oneway)\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated coefficients relate to the group means?\n\n\n\n\nANOVA Table\nTo test whether the effect of treatment is statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_oneway)\nanova_results\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\nEstimated Marginal Means\nEstimated marginal means, also known as least-squares means, are model-based means that represent the predicted (or expected) response at each level of a factor, averaged over the levels of other variables in the model.\nIn the context of a one-way ANOVA, where there is only one factor (e.g., treatment group), the estimated marginal means are equal to the observed group means. In more complex models with multiple factors, estimated marginal means provide predicted group means that are averaged over the levels of these additional factors. For example, in a model with both treatment and age as factors, the estimated marginal means for the treatment groups show the treatment means averaged over age, illustrating what these group means are expected to be at specific values of age (or averaged over a grid of age values).\nWe can calculate the estimated marginal means using the emmeans() function from the emmeans package:\n\n# Obtain estimated marginal means\nlibrary(emmeans)\nemms &lt;- emmeans(model_oneway, ~ Treatment)\nemms\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated marginal means compare to the observed group means calculated during the exploratory data analysis?\n\n\n\n\nPairwise comparisons\nSince we found a significant treatment effect, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another. We perform these pairwise comparisons using the contrast() function from the emmeans package. To account for the increased risk of Type I error due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled.\n\n# Performing post-hoc analysis with emmeans\ncontrast(emms, method=\"pairwise\", adjust=\"Bonferroni\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\nModel Diagnostics\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance) for the errors. A random scatter of residuals around zero indicates equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Residuals following the reference line suggest normally distributed errors.\n\n\n# Residuals vs Fitted\nplot(model_oneway, which = 1, main = \"Residuals vs Fitted\")\n\n# Normal Q-Q\nplot(model_oneway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?"
  },
  {
    "objectID": "BLR_lab_MLA.html",
    "href": "BLR_lab_MLA.html",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "",
    "text": "In this lab, we will explore the analysis of multilevel data, focusing on situations where subjects are nested within larger contexts, such as schools, neighborhoods, or clinics. The data include subject-level characteristics (e.g., age, gender), which reflect differences between individuals and help explain variation in their outcomes within a specific context. They also include context-level characteristics (e.g., school funding, neighborhood income), which account for differences between contexts and help explain variation in subject-level outcomes across these contexts."
  },
  {
    "objectID": "BLR_lab_MLA.html#exploratory-data-analysis",
    "href": "BLR_lab_MLA.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nLet’s load the data and use the str() function to inspect the structure of the dataset.\n\n# Load the required libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lmerTest)\n\n# Load the Chicago AirBnB data. Note that the call below assumes the csv file is placed in the 'data' folder directly above the root folder of the project. Update the string as needed if the file is located elsewhere.\nchicago_airbnb &lt;- read.csv(\"data/airbnb.csv\")\n\n# Convert all character variables into factors\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate_if(is.character, as.factor)\n\n# Inspect the structure of the dataset\nstr(chicago_airbnb)\n\nThis initial inspection makes clear that the Airbnb dataset has a multilevel structure: 1,561 individual listings are nested within 43 neighborhoods, which are further nested within 9 districts. To get a better feeling for this grouping structure, we begin by summarizing the number of listings in each neighborhood:\n\n# Summarize number of listings within each neighborhood\nlisting_summary &lt;- chicago_airbnb %&gt;%\n  group_by(neighborhood) %&gt;%\n  summarise(num_listings = n())\n\n# Visualize the distribution of listings across neighborhoods\nggplot(listing_summary, aes(x = reorder(neighborhood, num_listings), y = num_listings)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  coord_flip() +\n  labs(title = \"Number of Listings per Neighborhood\",\n       x = \"Neighborhood\",\n       y = \"Number of Listings\")\n\nExplanation:\n\ngroup_by(neighborhood): groups the data by the neighborhood column so that operations like counting can be applied to each group separately.\nAfter grouping, summarise() calculates the number of rows (listings) in each group (neighborhood) using the n() function. The result is stored in a new data fame with two columns:\n\nneighborhood: the name of the neighborhood;\nnum_listings: the number of listings in that neighborhood.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the plot tell us about the distribution of Airbnb listings across neighborhoods?\n\n\n\n\n\n\n\n\nCoding excerise\n\n\n\nCreate a similar plot to visualize the distribution of neighborhoods across districts. Hint: group the dataset by the district column and count the number of unique neighborhoods in each district. See ?summarise for a list of useful functions to use within summarise().\n\n\nNext, we create a histogram to visualize the distribution of the outcome variable price:\n\n# Create a histogram of price\nggplot(chicago_airbnb, aes(x = price)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Histogram of Listing Prices\",\n       x = \"Price\",\n       y = \"Frequency\")\n\nWhile normality of the outcome is not strictly required for a mixed-effects model, transforming a right-skewed variable like price can help stabilize variance and linearize relationships. We therefore create a new variable, log_price, to store the log-transformed prices:\n\n# Log-transform the price variable\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate(log_price = log(price))\n\nWe also want to get a sense of the variability in the listing prices within and between neighborhoods. For this, we are going to select the 10 neighborhoods with the most listings and create a scatter plot with the log-transformed price on the y-axis and the neighborhood on the x-axis:\n\n# Select the top 10 neighborhoods with the most listings\ntop_neighborhoods &lt;- listing_summary %&gt;%\n  slice_max(num_listings, n = 10) %&gt;%\n  pull(neighborhood)\n\n# Filter the data to include only the top neighborhoods\ntop_neighborhood_data &lt;- chicago_airbnb %&gt;%\n  filter(neighborhood %in% top_neighborhoods)\n\nExplanation:\n\nslice_max(num_listings, n = 10): selects the top 10 neighborhoods with the most listings based on the num_listings column.\npull(neighborhood): extracts the neighborhood names from the resulting tibble as a vector.\nfilter(neighborhood %in% top_neighborhoods): filters the chicago_airbnb dataset to include only rows where the neighborhood column matches one of the neighborhoods in the top_neighborhoods vector.\n\n\n# Calculate the average log_price for each neighborhood\nneighborhood_avg_price &lt;- top_neighborhood_data %&gt;%\n  group_by(neighborhood) %&gt;%\n  summarise(avg_log_price = mean(log_price, na.rm = TRUE))\n\n# create a scatter plot of log_price by neighborhood\nggplot(top_neighborhood_data, aes(x = neighborhood, y = log_price)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Price by Neighborhood\",\n       x = \"Neighborhood\",\n       y = \"Log-transformed price\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_point(data = neighborhood_avg_price, aes(x = neighborhood, y = avg_log_price), color = \"red\", size = 3) +  # neighborhood-level averages \n  geom_hline(yintercept = mean(neighborhood_avg_price$avg_log_price, na.rm = TRUE), linetype = \"dashed\", color = \"blue\") # overall average\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does this plot suggest about the variability in listing prices within and between neighborhoods?"
  },
  {
    "objectID": "BLR_lab_MLA.html#random-intercept-model",
    "href": "BLR_lab_MLA.html#random-intercept-model",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Random intercept model",
    "text": "Random intercept model\nTo model the variability in listing prices within and between neighborhoods, we start by fitting a random intercept model to account for the nesting of listings within neighborhoods, ignoring the higher-level nesting of neighborhoods into districts. The model is specified as follows:\n\n# Fit the random intercept model\nrandom_intercept_model &lt;- lmer(log_price ~ 1 + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model)\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of within-neighborhood and between-neighborhood variability to the total variability in listing prices?"
  },
  {
    "objectID": "BLR_lab_MLA.html#extending-the-random-intercept-model-with-subject-level-variables",
    "href": "BLR_lab_MLA.html#extending-the-random-intercept-model-with-subject-level-variables",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Extending the random intercept model with subject-level variables",
    "text": "Extending the random intercept model with subject-level variables\nAs a second step, we extend the random intercept model with subject-level variables. To facilitate the interpretation of the model coefficients, we start by setting the coding scheme for categorical variables to effects coding. We also center the numerical variables by subtracting the mean value from each observation. This step is important to reduce multicollinearity, improve numerical stability, and make the coefficients more interpretable.\n\n# Use effects coding for the categorical variables\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\n# Center the continuous subject-levl variables\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate(overall_satisfaction_c = scale(overall_satisfaction, scale = FALSE),\n         accommodates_c = scale(accommodates, scale = FALSE),\n         bedrooms_c = scale(bedrooms, scale = FALSE),\n         minstay_c = scale(minstay, scale = FALSE))\n\nNext, we fit the random intercept model with the subject-level variables included:\n\n# Fit the random intercept model with subject-level variables    \nrandom_intercept_model_L1variables &lt;- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_L1variables)\n\n# Display the coding scheme for the room_type variable\ncontrasts(chicago_airbnb$room_type)\n\n# Obtain the ANOVA table for the subject-level variables\nanova(random_intercept_model_L1variables)\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow does centering the continuous variables affect the interpretation of the intercept?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow does the inclusion of individual-level variables affect the estimated variance components? More specifically, does the inclusion of individual-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the individual-level variables are significantly associated with listing prices? How do you interpret the coefficients for these variables?"
  },
  {
    "objectID": "BLR_lab_MLA.html#including-context-level-variables",
    "href": "BLR_lab_MLA.html#including-context-level-variables",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Including context-level variables",
    "text": "Including context-level variables\nAs a third step, we extend the previously fitted model with context-level variables. We start by centering the context-level variables:\n\n# Center the context-level variables\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate(WalkScore_c = scale(WalkScore, scale = FALSE),\n         TransitScore_c = scale(TransitScore, scale = FALSE),\n         BikeScore_c = scale(BikeScore, scale = FALSE))\n\nNext, we fit the random intercept model with both subject-level and context-level variables included:\n\n# Fit the random intercept model with subject-level and context-level variables\nrandom_intercept_model_L1L2variables &lt;- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_L1L2variables)\n\n# Obtain the ANOVA table\nanova(random_intercept_model_L1L2variables)  \n\n\n\n\n\n\n\nQuestion\n\n\n\nHow does the inclusion of context-level variables affect the estimated variance components? More specifically, does the inclusion of context-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?\n\n\nNot all the context-level variables included in the model are significant predictors of listing prices. To obtain a more parsimonious model, we use the step() function from the lmerTest package to perform a backward elimination of the fixed-effect terms:\n\n# Perform stepwise selection to identify the most important predictors\nstep(random_intercept_model_L1L2variables, reduce.random = FALSE)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich individual-level and context-level variables are retained in the final model after the stepwise selection procedure?"
  },
  {
    "objectID": "BLR_lab_MLA.html#exploring-cross-level-interactions",
    "href": "BLR_lab_MLA.html#exploring-cross-level-interactions",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Exploring cross-level interactions",
    "text": "Exploring cross-level interactions\nFinally, we explore the possibility of cross-level interactions between individual-level and context-level variables.\nThe relationship between the overall satisfaction rating of an individual listing and its price may depend on neighborhood characteristics such as their walkability and access to public transit. For instance, higher satisfaction ratings might have a stronger effect on prices in less walkable or transit-accessible neighborhoods, where positive reviews could help compensate for the disadvantages of limited walkability or transit options. In contrast, in neighborhoods with high walkability or access to public transit ratings, these location-based amenities might already drive prices, reducing the added impact of satisfaction ratings.\nTo test whether the effect of the individual-level variable overall_satisfaction on listing prices varies across different values of the context-level variable WalkScore, we refit the model with an interaction term between these two variables:\n\n# Fit the model with the interaction between overall_satisfaction and WalkScore\nrandom_intercept_model_interaction &lt;- lmer(log_price ~ overall_satisfaction_c * WalkScore_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_interaction)\n\n\n\n\n\n\n\nQuestion\n\n\n\nIs there evidence of a significant interaction between overall satisfaction ratings and neighborhood walkability in predicting listing prices? If so, how do you interpret the interaction term coefficient?\n\n\nSimilarly, to test whether the effect of the individual-level variable overall_satisfaction varies across different values of the context-level variable TransitScore, we refit the model with an interaction term between these two variables:\n\n# Fit the model with the interaction between overall_satisfaction and WalkScore\nrandom_intercept_model_interaction &lt;- lmer(log_price ~ overall_satisfaction_c * WalkScore_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_interaction)\n\n\n\n\n\n\n\nQuestion\n\n\n\nIs there evidence of a significant interaction between overall satisfaction ratings and neighborhood walkability in predicting listing prices? If so, how do you interpret the interaction term coefficient?\n\n\n\nModel diagnostics\nThe process of performing model diagnostics for the random intercept models fitted in this lab is similar to the one described in the previous labs. Therefore, we refer to those labs for more detailed instructions on assessing model assumptions."
  },
  {
    "objectID": "BLR_lab_randomized_block.html",
    "href": "BLR_lab_randomized_block.html",
    "title": "Beyond MLR Lab 3: Randomized Block Designs",
    "section": "",
    "text": "Suppose we are conducting an experiment to compare the effectiveness of three different wound healing treatments (Treatment A, Treatment B, and Treatment C) on cell cultures. The experimental units are the cell culture plates. To account for potential variability in laboratory conditions (such as humidity and temperature), we use a randomized block design, with laboratory facility as the blocking factor. Within each laboratory (block), the three treatments are randomly assigned to one cell culture plate each, ensuring that every treatment is represented once within each block. This design helps control for variability between laboratory facilities, allowing us to more effectively isolate the treatment effects.\n\n# Set seed for reproducibility\nset.seed(456)\n\n# Define blocks and treatments\nblocks &lt;- factor(paste0(\"Laboratory \", rep(1:5, each = 3)))  # Labs 1 to 5\ntreatments &lt;- factor(rep(c(\"A\", \"B\", \"C\"), times = 5))\n\n# Simulate data\nblock_effect &lt;- rnorm(5, mean = 0, sd = 2)  # Random effect for each block\ntreatment_effect &lt;- c(A = 5, B = 7, C = 6)  # Fixed effects for treatments\n\n# Create data frame\ndata_block &lt;- data.frame(\n  Laboratory = blocks,\n  Treatment = treatments,\n  WoundHealing = NA\n)\n\n# Assign responses\nfor (i in 1:nrow(data_block)) {\n  b &lt;- as.numeric(data_block$Laboratory[i])\n  t &lt;- data_block$Treatment[i]\n  data_block$WoundHealing[i] &lt;-\n    50 + block_effect[b] + treatment_effect[t] + rnorm(1, mean = 0, sd = 1)\n}\n\nThe R code chunk above simulates wound healing observations (measured on a continuous scale, where higher values indicate better healing) for 15 cell culture plates, divided across five laboratory facilities. The results are stored in the data frame data_block, which consists of the following three variables:\n\nLaboratory: A factor variable indicating the laboratory facility.\nTreatmment: A factor variable indicating the applied treatment.\nWoundHealing: A numeric variable representing the degree of wound healing on a continuous scale.\n\n\n\nTo explore the data and investigate the possible presence of a laboratory effect, we start by creating a scatter plot with the wound healing variable on the x-axis and the laboratory facility variable on the y-axis:\n\nlibrary(ggplot2)\nggplot(data_block, aes(x = WoundHealing, y = Laboratory, color = Treatment)) +\n  geom_point(size = 4) +\n  labs(title = \"Wound Healing by Treatment and Laboratory\",\n       x = \"Wound Healing Measure\",\n       y = \"Laboratory\") +\n  theme_minimal()\n\nIn addition to the scatter plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\nlibrary(dplyr)\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_block %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_block %&gt;%\n  group_by(Laboratory) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\nsummary_stats_laboratory\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment and laboratory based on the plot and summary statistics?\n\n\n\n\n\nIn a mixed-effects model, both fixed effects and random effects are used to account for different sources of variation.\nIn the wound healing example, it is essential to account for the laboratory facility because differences between laboratories (such as variations in environmental conditions) could influence the outcome. By including laboratory as a blocking variable, we can more efficiently estimate the treatment effects by controlling for this source of variability. This can be statistically achieved by modeling laboratory as either a fixed effect or a random effect.\nWhile we could model laboratory as a fixed effect, treating it as a random effect is preferred in this case for two reasons: first, it better reflects reality, as the laboratories are considered a random sample of possible laboratory conditions; second, it reduces the number of parameters we need to estimate, making the model more parsimonious. Modeling the lab as random allows us to account for variability between laboratories without estimating a separate effect for each one, which ultimately helps to isolate the treatment effects more effectively.\nOn the other hand, treatment is modeled as a fixed effect because we are specifically interested in estimating and comparing the effectiveness of the three particular wound healing treatments (Treatment A, Treatment B, and Treatment C). These treatments are not considered random samples from a larger population of treatments; rather, they are the specific interventions under study. By modeling treatment as a fixed effect, we aim to draw conclusions about the differences between these particular treatments, and their impact on wound healing.\n\n\nThe mixed-effects model for our randomized block design can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + b_j + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The observed wound healing response for treatment \\(i\\) in laboratory \\(j\\).\n\\(\\mu\\): The overall mean response across all treatments and laboratories.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\), representing the deviation of treatment \\(i\\) from the overall mean \\(\\mu\\).\n\\(b_j\\): The random effect of laboratory \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\)).\n\\(\\epsilon_{ij}\\): The error term, assumed to be normally distributed with mean zero and variance \\(\\sigma^2\\).\n\n\n\n\nWe previously mentioned that the lme4 package does not provide p-values for the fixed effect estimates. One way around this is to fit the mixed effects model using the lmer() function from the lmeTest package, which extends to original lmer() function from the lme4 to include p-values for the fixed effect estimates. The lmerTest package achieves this by applying Satterthwaite’s approximation to calculate degrees of freedom, which are then used to derive the p-values.\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_block)\nsummary(model_block)\n\n\n\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory)\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments. Note that the intercept is included by default in the model, so WoundHealing ~ Treatment is essentially a shortcut for WoundHealing ~ 1 + Treatment. Also remember that with effects coding, the intercept represents the overall mean across all levels of the treatment variable, and the treatment coefficients represent deviations from this mean.\n(1 | Laboratory): This specifies the random effect for Laboratory, representing laboratory-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_block), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean wound healing score averaged across all treatments and laboratories.\nTreatment: The differences in wound healing associated with each treatment relative to the overall mean.\n\nRandom Effects: Estimates of the variance components\n\nLaboratory - Intercept: Between-laboratory variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nCaution: Interpreting p-values in Mixed Effects Models\n\n\n\nWhile the lmerTest package provides p-values for fixed effects, it is important to use them with caution, primarily because methods for calculating degrees of freedom, such as Satterthwaite, are approximations that may not always be reliable, particularly in complex models fitted to imbalanced data. Generally, this sensitivity is not a concern for the randomized block design considered in this lab.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of laboratory variability and residual error to the total variability in wound healing?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsidering these results, do you think that blocking by laboratory was necessary for this experiment?\n\n\n\n\n\nIn addition to providing p-values for the fixed effects estimates, the lmerTest package also implements the anova() function to test the overall significance of fixed effects in the model. Additionally, the ls_means() function can be used to calculate the estimated marginal means for the factors (i.e., variables that are defined as factors in the data frame or the model formula) included in the fixed effects structure of the model. Alternatively, these estimated marginal means can be calculated using the emmeans() function from the emmeans package, which provides more options and greater flexibility for advanced users.\n\n# Obtain ANOVA table for the fixed effects\nanova(model_block)\n\n# Calculate estimated marginal means for the Treatment variable\nls_means(model_block)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow to the estimated marginal means compare to the observed group means from the exploratory data analysis?\n\n\n\n\nSince we found a significant treatment effect, we proceed with computing pairwise differences of the estimated marginal means. This can be achieved by adding the argument pairwise=TRUE to the call to the ls_means() function. Unlike the emmmeans package, there is no multiplicity correction for pairwise comparisons in the lmerTest package. We therefore use the p.adjust() function from the base R stats package to compute the Bonferroni corrected p-values (i.e., the original p-values multiplied by the number of comparisons).\n\n# Compute pairwise differences of the estimated marginal means \nemms &lt;- ls_means(model_block, pairwise=TRUE)\nemms\n\n# Retrieve the p-values from the emms object and adjust them \n# for multiple testing using the Bonferroni correction\np.adjust(emms$`Pr(&gt;|t|)`, method=\"bonferroni\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\n\nSimilar as in the previous lab, we will inspect the conditional residuals to check the model assumptions regarding the error term:\n\n# Extract conditional residuals\nresiduals_cond &lt;- resid(model_block)\n\n# Residuals vs Fitted\nplot(fitted(model_block), residuals_cond,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond)\nqqline(residuals_cond, col = \"red\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 3: Randomized Block Designs",
    "section": "",
    "text": "To explore the data and investigate the possible presence of a laboratory effect, we start by creating a scatter plot with the wound healing variable on the x-axis and the laboratory facility variable on the y-axis:\n\nlibrary(ggplot2)\nggplot(data_block, aes(x = WoundHealing, y = Laboratory, color = Treatment)) +\n  geom_point(size = 4) +\n  labs(title = \"Wound Healing by Treatment and Laboratory\",\n       x = \"Wound Healing Measure\",\n       y = \"Laboratory\") +\n  theme_minimal()\n\nIn addition to the scatter plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\nlibrary(dplyr)\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_block %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_block %&gt;%\n  group_by(Laboratory) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\nsummary_stats_laboratory\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment and laboratory based on the plot and summary statistics?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "href": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "title": "Beyond MLR Lab 3: Randomized Block Designs",
    "section": "",
    "text": "In a mixed-effects model, both fixed effects and random effects are used to account for different sources of variation.\nIn the wound healing example, it is essential to account for the laboratory facility because differences between laboratories (such as variations in environmental conditions) could influence the outcome. By including laboratory as a blocking variable, we can more efficiently estimate the treatment effects by controlling for this source of variability. This can be statistically achieved by modeling laboratory as either a fixed effect or a random effect.\nWhile we could model laboratory as a fixed effect, treating it as a random effect is preferred in this case for two reasons: first, it better reflects reality, as the laboratories are considered a random sample of possible laboratory conditions; second, it reduces the number of parameters we need to estimate, making the model more parsimonious. Modeling the lab as random allows us to account for variability between laboratories without estimating a separate effect for each one, which ultimately helps to isolate the treatment effects more effectively.\nOn the other hand, treatment is modeled as a fixed effect because we are specifically interested in estimating and comparing the effectiveness of the three particular wound healing treatments (Treatment A, Treatment B, and Treatment C). These treatments are not considered random samples from a larger population of treatments; rather, they are the specific interventions under study. By modeling treatment as a fixed effect, we aim to draw conclusions about the differences between these particular treatments, and their impact on wound healing.\n\n\nThe mixed-effects model for our randomized block design can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + b_j + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The observed wound healing response for treatment \\(i\\) in laboratory \\(j\\).\n\\(\\mu\\): The overall mean response across all treatments and laboratories.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\), representing the deviation of treatment \\(i\\) from the overall mean \\(\\mu\\).\n\\(b_j\\): The random effect of laboratory \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\)).\n\\(\\epsilon_{ij}\\): The error term, assumed to be normally distributed with mean zero and variance \\(\\sigma^2\\).\n\n\n\n\nWe previously mentioned that the lme4 package does not provide p-values for the fixed effect estimates. One way around this is to fit the mixed effects model using the lmer() function from the lmeTest package, which extends to original lmer() function from the lme4 to include p-values for the fixed effect estimates. The lmerTest package achieves this by applying Satterthwaite’s approximation to calculate degrees of freedom, which are then used to derive the p-values.\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_block)\nsummary(model_block)\n\n\n\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory)\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments. Note that the intercept is included by default in the model, so WoundHealing ~ Treatment is essentially a shortcut for WoundHealing ~ 1 + Treatment. Also remember that with effects coding, the intercept represents the overall mean across all levels of the treatment variable, and the treatment coefficients represent deviations from this mean.\n(1 | Laboratory): This specifies the random effect for Laboratory, representing laboratory-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_block), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean wound healing score averaged across all treatments and laboratories.\nTreatment: The differences in wound healing associated with each treatment relative to the overall mean.\n\nRandom Effects: Estimates of the variance components\n\nLaboratory - Intercept: Between-laboratory variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nCaution: Interpreting p-values in Mixed Effects Models\n\n\n\nWhile the lmerTest package provides p-values for fixed effects, it is important to use them with caution, primarily because methods for calculating degrees of freedom, such as Satterthwaite, are approximations that may not always be reliable, particularly in complex models fitted to imbalanced data. Generally, this sensitivity is not a concern for the randomized block design considered in this lab.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of laboratory variability and residual error to the total variability in wound healing?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsidering these results, do you think that blocking by laboratory was necessary for this experiment?\n\n\n\n\n\nIn addition to providing p-values for the fixed effects estimates, the lmerTest package also implements the anova() function to test the overall significance of fixed effects in the model. Additionally, the ls_means() function can be used to calculate the estimated marginal means for the factors (i.e., variables that are defined as factors in the data frame or the model formula) included in the fixed effects structure of the model. Alternatively, these estimated marginal means can be calculated using the emmeans() function from the emmeans package, which provides more options and greater flexibility for advanced users.\n\n# Obtain ANOVA table for the fixed effects\nanova(model_block)\n\n# Calculate estimated marginal means for the Treatment variable\nls_means(model_block)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow to the estimated marginal means compare to the observed group means from the exploratory data analysis?\n\n\n\n\nSince we found a significant treatment effect, we proceed with computing pairwise differences of the estimated marginal means. This can be achieved by adding the argument pairwise=TRUE to the call to the ls_means() function. Unlike the emmmeans package, there is no multiplicity correction for pairwise comparisons in the lmerTest package. We therefore use the p.adjust() function from the base R stats package to compute the Bonferroni corrected p-values (i.e., the original p-values multiplied by the number of comparisons).\n\n# Compute pairwise differences of the estimated marginal means \nemms &lt;- ls_means(model_block, pairwise=TRUE)\nemms\n\n# Retrieve the p-values from the emms object and adjust them \n# for multiple testing using the Bonferroni correction\np.adjust(emms$`Pr(&gt;|t|)`, method=\"bonferroni\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\n\nSimilar as in the previous lab, we will inspect the conditional residuals to check the model assumptions regarding the error term:\n\n# Extract conditional residuals\nresiduals_cond &lt;- resid(model_block)\n\n# Residuals vs Fitted\nplot(fitted(model_block), residuals_cond,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond)\nqqline(residuals_cond, col = \"red\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "BLR_lab_RE_oneway.html",
    "href": "BLR_lab_RE_oneway.html",
    "title": "Beyond MLR Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "Welcome to lab 2 of the Beyond MLR course. In this lab, we make use of the following R packages: gglot2, dplyr, emmeans, and lme4. You can use the script below to check if these packages are installed. Any missing packages can be installed using install.packages(\"package_name\").\npackages &lt;- c(\"dplyr\", \"ggplot2\", \"emmeans\", \"lme4\")\n\ninstalled &lt;- sapply(packages, requireNamespace, quietly = TRUE)\nif (all(installed)) {\n  message(\"All packages are installed.\")\n} else {\n  missing &lt;- names(installed)[!installed]\n  message(\"The following packages are not installed: \", paste(missing, collapse = \", \"))\n}"
  },
  {
    "objectID": "BLR_lab_RE_oneway.html#exploratory-data-analysis",
    "href": "BLR_lab_RE_oneway.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 2: Random Effects Model for the One-Way Layout",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nBefore modeling, it’s important to visualize and summarize the data to identify any trends, patterns, or anomalies that may impact the analysis. In this case, we aim to explore the variability in waist circumference measurements across nurses and assess the consistency of these measurements.\nWe’ll use two main approaches:\n\nVisualizing the data: A boxplot will be created to compare waist circumference measurements across nurses, highlighting differences in measurement tendencies or variability.\nSummarizing the data: Summary statistics (mean and standard deviation) will be computed for each nurse, providing a numerical overview of central tendency and spread for the measurements.\n\n\n# Create a boxplot\nlibrary(ggplot2)\nggplot(data_waist_circumference, aes(x = Nurse, y = Waist_Circumference, fill = Nurse)) +\n  geom_boxplot() +\n  labs(title = \"Waist Circumference Measurements by Nurse\",\n       x = \"Nurse\", y = \"Waist Circumference (cm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n# Calculate summary statistics\nlibrary(dplyr)\nsummary_stats_random &lt;- data_waist_circumference %&gt;%\n  group_by(Nurse) %&gt;%\n  summarise(\n    Mean_Waist = mean(Waist_Circumference),\n    SD_Waist = sd(Waist_Circumference)\n  )\n\nsummary_stats_random\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the boxplot and summary statistics, do you observe any systematic differences in waist circumference measurements across the nurses? If so, describe the differences and what they might suggest about the measurements."
  },
  {
    "objectID": "BLR_lab_RE_oneway.html#random-effects-model-for-the-one-way-layout",
    "href": "BLR_lab_RE_oneway.html#random-effects-model-for-the-one-way-layout",
    "title": "Beyond MLR Lab 2: Random Effects Model for the One-Way Layout",
    "section": "Random Effects Model for the One-Way Layout",
    "text": "Random Effects Model for the One-Way Layout\nA random effects model represents variations assumed to arise from a larger population. Unlike fixed effects, which estimate specific differences between levels of a factor, random effects account for variability among factor levels by treating them as random samples from a broader population.\nIn the waist circumference example, the four nurses can be considered a random sample from a larger population of nurses. By modeling “Nurse” as a random effect, we aim to generalize the findings about measurement variability to the broader population of nurses, rather than focusing solely on the four in the study.\n\nModel Specification\nThe random effects model can be specified as:\n\\[\nY_{ij} = \\mu + b_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The waist circumference measurement for the \\(j\\)-th observation by the \\(i\\)-th nurse.\n\\(\\mu\\): The overall mean waist circumference.\n\\(b_i\\): The random effect of the \\(i\\)-th nurse, assumed to be normally distributed with mean zero and variance \\(\\sigma^2_{b}\\).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and variance \\(\\sigma^2\\).\n\nThe use of random effects allows us to decompose the total variance in the outcome variable into distinct components, each associated with a different source of variation. In this example, the total variance in waist circumference measurements is split into two variance components:\n\nBetween-nurse variability (\\(\\sigma^2_{b}\\)): This component, represented by the variance of the random effect \\(b_{i}\\), captures the variability in waist circumference measurements attributable to differences among nurses. It reflects how much of the overall variability is due to systematic differences in measurement techniques or practices between nurses.\nResidual variance (\\(\\sigma^2\\)): This component, represented by the variance of the error term \\(\\epsilon_{ij}\\), captures the variability in waist circumference measurements that remains unexplained by nurse-related differences. It includes measurement error, patient-specific factors, and other unmeasured sources of variation.\n\n\n\n\n\n\n\nNotation convention\n\n\n\nIn mixed-effects models, fixed effects are typically represented by Greek letters, while random effects are represented by Roman letters. This helps differentiate between the two types of effects in model specification.\n\n\n\nIntraclass Correlation Coefficient\nThe Intraclass Correlation Coefficient (ICC) is a statistical measure that quantifies the proportion of the total variance in the outcome variable that can be attributed to differences between groups. In this context, the ICC measures the extent to which waist circumference measurements are more similar when taken by the same nurse (within-group), compared to the overall variability across all nurses (between-group). In other words, it tells us how strongly measurements are correlated within the same group.\nMathematically, the ICC is calculated as:\n\\[\nICC = \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2}\n\\]\nInterpretation of ICC:\n\nICC \\(\\approx\\) 0: Indicates that nearly all the variability in waist circumference measurements is due to residual factors (such as patient differences or measurement error). This suggests that nurse-level differences contribute minimally to the total variability, implying a high degree of consistency across nurses in their measurement practices.\nICC \\(\\approx\\) 1: Indicates that nearly all the variability is attributable to differences between nurses. This suggests substantial between-nurse variability, meaning different nurses consistently record different waist circumference measurements.\n\n\n\n\nModel Estimation\nWe will fit the random effects model using the lmer() function from the lme4 package.\n\n# Fitting the random effects model\nlibrary(lme4)\nmodel_random &lt;- lmer(Waist_Circumference ~ 1 + (1 | Nurse), data = data_waist_circumference)\nsummary(model_random)\n\n\nSyntax overview\nLet’s break down the model formula Waist_Circumference ~ 1 + (1 | Nurse)\n\nWaist_Circumference ~ 1: This specifies that Waist_Circumference is the outcome variable and that the fixed effects structure consists of a single intercept, modeled by the term 1, that represents the overall mean waist circumference across all nurses.\n(1 | Nurse): This specifies the random effect for Nurse, representing nurse-specific deviations from the overall mean.\n\n\n\nSummary overview\nWhen you run summary(model_random), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean waist circumference across all nurses.\n\nRandom Effects: Estimates of the two variance components\n\nNurse - Intercept: Between-nurse variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nNo p-values\n\n\n\nThe lme4 package does not provide p-values for fixed effect estimates. This is a deliberate choice by the package authors, based on concerns about the appropriateness of traditional hypothesis testing methods in the context of mixed effects models. In subsequent labs, we will use of the lmerTest package to calculate these p-values and add them to the summary output.\n\n\n\n\n\nAssessing the variance components\n\n\n\n\n\n\nQuestion\n\n\n\nWhat proportion of the total variance is attributable to nurse differences (i.e., what is the value of the ICC)?\n\n\n\n\nModel Diagnostics\nIn mixed-effects models, model diagnostics involve analyzing different types of residuals to evaluate how well the model fits the data and to assess whether key assumptions are satisfied.\nThe default type of residuals used in these models are the conditional residuals, which are calculated based on predicted values that incorporate both fixed effects and estimated random effects. Conditional residuals represent the deviation of the observed data from the model’s predictions, accounting for variability from both sources: fixed effects and random effects. They can be considered estimates of the errors \\(\\epsilon_{ij}\\), which are assumed to be normally distributed with a mean of zero and constant variance.\nTo check these assumptions, we can generate diagnostic plots similar to those used in linear regression models:\n\nResiduals vs. Fitted Plot: This plot helps check for homoscedasticity (constant variance).\nNormal Q-Q Plot: This plot assesses whether the residuals follow a normal distribution.\n\n\n# Extract conditional residuals and predicted values\nresiduals_model_random &lt;- resid(model_random)\nfitted_model_random &lt;- fitted(model_random)\n\n# Residuals vs Fitted\nggplot(data.frame(Fitted = fitted_model_random, Residuals = residuals_model_random), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n# Normal Q-Q\nqqnorm(residuals_model_random, main = \"Normal Q-Q\")\nqqline(residuals_model_random)\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "Assignments/Week 5/test.html",
    "href": "Assignments/Week 5/test.html",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "",
    "text": "This dataset models students’s English and Mathematics test scores over time, by examining the records of over 1000 English students over 3 school years. The objective of the analysis is to develop a model to describe the development of students’ English and Mathematics test scores over time, considering fixed and random effects. This model explains how the test scores change over time and how gender influences the test scores."
  },
  {
    "objectID": "Assignments/Week 5/test.html#data-visualization-of-the-structure-of-the-data",
    "href": "Assignments/Week 5/test.html#data-visualization-of-the-structure-of-the-data",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "Data visualization of the structure of the data",
    "text": "Data visualization of the structure of the data\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lmerTest)\nlibrary(haven)\npackages &lt;- c(\"dplyr\", \"ggplot2\", \"emmeans\", \"lmerTest\")\n\n# Load the dataset and specify Gender as a factor\ndataset &lt;- read.csv(\"downloads/jsp_data.csv\")\n\n# Convert all character variables into factors\ndataset &lt;- dataset%&gt;%\n  mutate_if(is.character, as.factor)\n\n# Inspect the structure of the dataset\nstr(dataset)\n\n'data.frame':   3236 obs. of  6 variables:\n $ School            : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Student.ID        : int  1 1 1 2 2 3 3 3 4 4 ...\n $ Gender            : Factor w/ 2 levels \"Boy\",\"Girl\": 2 2 2 1 1 1 1 1 1 1 ...\n $ Junior.school.year: int  0 1 2 0 1 0 1 2 0 1 ...\n $ English.test      : int  72 80 39 7 17 88 89 83 12 25 ...\n $ Mathematics.test  : int  23 24 23 14 11 36 32 39 24 26 ...\n\n# Summarize number of students within each school\nstudent_summary &lt;- dataset %&gt;%\ngroup_by(School) %&gt;%\nsummarise(num_students = n())\n\n# Visualize the distribution of students across schools\nggplot(student_summary, aes(x = reorder(School, num_students), y = num_students)) +\ngeom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\ncoord_flip() +\nlabs(title = \"Number of Students per School\",\n     x = \"School\",\ny = \"Number of Students\")"
  },
  {
    "objectID": "Assignments/Week 5/test.html#data-visualisation-of-english-test-scores",
    "href": "Assignments/Week 5/test.html#data-visualisation-of-english-test-scores",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "Data visualisation of English test scores",
    "text": "Data visualisation of English test scores\n\n# Summary statistics of English\ndataset %&gt;%\n  summarize(\n    mean_English.test = mean(English.test),\n    variance_English.test = var(English.test)\n  )\n\n  mean_English.test variance_English.test\n1          52.49289              610.6976\n\n# Save mean statistic of English grouped by school year\nmean_English_year &lt;- dataset %&gt;%\n  group_by(Junior.school.year) %&gt;%\n  summarise(mean_English_year = mean(English.test, na.rm = TRUE))\nmean_English_year\n\n# A tibble: 3 × 2\n  Junior.school.year mean_English_year\n               &lt;int&gt;             &lt;dbl&gt;\n1                  0              48.1\n2                  1              65.3\n3                  2              42.6\n\n# Plot the mean trajectory of English test over the Junior School Years\nggplot(mean_English_year, aes(x = Junior.school.year, y = mean_English_year)) +\n  geom_line() +\n  labs(\n    title = \"Mean English Test Score Trajectory\",\n    x = \"Junior School Year\",\n    y = \"Mean English Test Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Select the top 10 schools with the most students\ntop_Schools &lt;- student_summary %&gt;%\nslice_max(num_students, n = 10) %&gt;%\npull(School)\n\n# Filter the data to include only the top schools\ntop_Schools_data &lt;- dataset %&gt;%\nfilter(School %in% top_Schools)\n\n# Calculate the average English test score for each School\nSchool_avg_English.test &lt;- top_Schools_data %&gt;%\n  group_by(School) %&gt;%\n  summarise(mean_English.test = mean(English.test, na.rm = TRUE))\n\n# create a scatter plot of English test score by School\nggplot(top_Schools_data, aes(x = School, y = English.test)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"English test score by School\",\n       x = \"School\",\n       y = \"English test score\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_point(data = School_avg_English.test, aes(x = School, y = mean_English.test), color = \"red\", size = 3) +  # School-level averages \n  geom_hline(yintercept = mean(School_avg_English.test$mean_English.test, na.rm = TRUE), linetype = \"dashed\", color = \"blue\") # overall average\n\n\n\n\n\n\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Sample 16 unique individuals only from the Student IDs that exist in the dataset\nsampled_ids &lt;- sample(1:82, 16)\n\n# Filter dataset for the sampled IDs and plot individual English scores\ndataset %&gt;%\n  filter(Student.ID %in% sampled_ids) %&gt;%\n   ggplot(aes(x = Junior.school.year, y = English.test)) +\n  geom_line() +                               \n  geom_point(size = 2, alpha = 0.7) +         \n  facet_wrap(~ Student.ID) +                          \n  labs(\n    title = \"Individual English Score Trajectories with Data Points\",\n    x = \"Junior school year\",\n    y = \"English test score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Compute the mean English test score by school year and gender\nmean_English_gender &lt;- dataset %&gt;%\n  group_by(Junior.school.year, Gender) %&gt;%\n  summarise(mean_English_gender = mean(English.test, na.rm = TRUE))\nmean_English_gender\n\n# A tibble: 6 × 3\n# Groups:   Junior.school.year [3]\n  Junior.school.year Gender mean_English_gender\n               &lt;int&gt; &lt;fct&gt;                &lt;dbl&gt;\n1                  0 Boy                   42.6\n2                  0 Girl                  53.1\n3                  1 Boy                   60.6\n4                  1 Girl                  69.7\n5                  2 Boy                   39.6\n6                  2 Girl                  45.4\n\n# Plot the mean trajectories\nggplot(mean_English_gender, aes(x = Junior.school.year, y = mean_English_gender, color = Gender)) +\n  geom_line() +\n  labs(\n    title = \"Mean English Test Score Trajectories by gender\",\n    x = \"Junior School Year\",\n    y = \"Mean English Test Score\"\n  ) +\n  scale_color_manual(values = c(\"Boy\" = \"blue\", \"Girl\" = \"red\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis data visualisation shows the different trajectories of English test scores within a random sample of students. The mean trajectory seem to show a quadratic relationship between Junior School Year and English Test scores. There are different mean scores between schools, indicating that school could be a relevant explanatory variable. In addition, Girls seem to have higher mean English test scores than boys, indicating a possible relationship between gender and test score."
  },
  {
    "objectID": "Assignments/Week 5/test.html#multi-level-modeling-of-english-test-scores",
    "href": "Assignments/Week 5/test.html#multi-level-modeling-of-english-test-scores",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "Multi-level modeling of English Test Scores",
    "text": "Multi-level modeling of English Test Scores\n\nRandom intercept model\nFit a full model with a random intercept. Examine the variance components\n\n#Random intercept model \nrandom_intercept_model_English &lt;- lmer(English.test ~ Junior.school.year + I(Junior.school.year^2) + School + Gender + Gender*Junior.school.year + (1 | Student.ID), data = dataset)\nsummary(random_intercept_model_English)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: English.test ~ Junior.school.year + I(Junior.school.year^2) +  \n    School + Gender + Gender * Junior.school.year + (1 | Student.ID)\n   Data: dataset\n\nREML criterion at convergence: 27239.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2348 -0.5352  0.0453  0.5639  3.5697 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n Student.ID (Intercept) 393.5    19.84   \n Residual               112.3    10.60   \nNumber of obs: 3236, groups:  Student.ID, 1192\n\nFixed effects:\n                                Estimate Std. Error         df t value Pr(&gt;|t|)\n(Intercept)                    4.218e+01  1.430e+00  1.323e+03  29.495  &lt; 2e-16\nJunior.school.year             3.887e+01  8.513e-01  2.055e+03  45.655  &lt; 2e-16\nI(Junior.school.year^2)       -2.075e+01  3.983e-01  2.058e+03 -52.093  &lt; 2e-16\nSchool                         3.777e-03  4.065e-02  1.185e+03   0.093  0.92598\nGenderGirl                     1.071e+01  1.288e+00  1.491e+03   8.313  &lt; 2e-16\nJunior.school.year:GenderGirl -1.485e+00  4.765e-01  2.071e+03  -3.116  0.00186\n                                 \n(Intercept)                   ***\nJunior.school.year            ***\nI(Junior.school.year^2)       ***\nSchool                           \nGenderGirl                    ***\nJunior.school.year:GenderGirl ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Jnr.s. I(J..^ School GndrGr\nJnr.schl.yr -0.166                            \nI(Jnr.s.^2)  0.084 -0.915                     \nSchool      -0.755 -0.002  0.002              \nGenderGirl  -0.445  0.096  0.002 -0.032       \nJnr.sch.:GG  0.158 -0.290 -0.001  0.000 -0.337\n\n#Extract variance components\nvar_comp_English &lt;- (VarCorr(random_intercept_model_English))\nvar_comp_English\n\n Groups     Name        Std.Dev.\n Student.ID (Intercept) 19.836  \n Residual               10.599  \n\n#Between ID variance\nvar_BW_English &lt;- var_comp_English$Student.ID[1]\nvar_BW_English\n\n[1] 393.4694\n\n#Within ID variance\nvar_WW_English &lt;- summary(random_intercept_model_English)$sigma^2\nvar_WW_English\n\n[1] 112.344\n\n#Calculate total variance, standard deviation and ICC\nvar_total_English &lt;- var_BW_English + var_WW_English\nvar_total_English\n\n[1] 505.8134\n\nsd_total_English &lt;- sqrt(var_total_English)\nsd_total_English\n\n[1] 22.4903\n\n#ICC of variance components\nICC_English &lt;- var_BW_English / var_total_English\nICC_English\n\n[1] 0.7778943\n\n\nThe ICC of 0.77 shows that 77% of the variance in the model is explained by the difference between children and the other 23% of the variance is due to the differences within an individual child\n\n\nRefine the fixed effects\nRefine the fixed effects using the ANOVA table of the random slope model\n\n#Obtain the ANOVA table for the individual-level variables\nanova(random_intercept_model_English)\n\nType III Analysis of Variance Table with Satterthwaite's method\n                          Sum Sq Mean Sq NumDF  DenDF   F value    Pr(&gt;F)    \nJunior.school.year        246034  246034     1 2054.7 2190.0064 &lt; 2.2e-16 ***\nI(Junior.school.year^2)   304860  304860     1 2058.4 2713.6320 &lt; 2.2e-16 ***\nSchool                         1       1     1 1185.0    0.0086  0.925976    \nGender                      7764    7764     1 1491.0   69.1114 &lt; 2.2e-16 ***\nJunior.school.year:Gender   1091    1091     1 2070.6    9.7105  0.001857 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Perform stepwise selection to identify the most important predictors\nstep(random_intercept_model_English, reduce.random = FALSE)\n\nBackward reduced random-effect table:\n\n                 Eliminated npar logLik   AIC    LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;                         8 -13620 27256                         \n(1 | Student.ID)          0    7 -14640 29293 2039.5  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBackward reduced fixed-effect table:\nDegrees of freedom method: Satterthwaite \n\n                          Eliminated Sum Sq Mean Sq NumDF  DenDF   F value\nSchool                             1      1       1     1 1185.0    0.0086\nI(Junior.school.year^2)            0 304863  304863     1 2058.5 2713.6525\nJunior.school.year:Gender          0   1091    1091     1 2070.6    9.7123\n                             Pr(&gt;F)    \nSchool                     0.925976    \nI(Junior.school.year^2)   &lt; 2.2e-16 ***\nJunior.school.year:Gender  0.001855 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nModel found:\nEnglish.test ~ Junior.school.year + I(Junior.school.year^2) + Gender + (1 | Student.ID) + Junior.school.year:Gender\n\n\nThe ANOVA table shows that School was not significant, thus can be removed from the model. Stepwise backward selection also provides the simplified model as the best fitting model: English.test ~ Junior.school.year + I(Junior.school.year^2) + Gender + (1 | Student.ID) + Junior.school.year:Gender\n\n# Fit the simplified model without the interaction term\nsimplified_model_English &lt;- lmer(English.test ~ Junior.school.year + I(Junior.school.year^2) + Gender + (1 | Student.ID) + Junior.school.year:Gender, data = dataset)\nsummary(simplified_model_English)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: English.test ~ Junior.school.year + I(Junior.school.year^2) +  \n    Gender + (1 | Student.ID) + Junior.school.year:Gender\n   Data: dataset\n\nREML criterion at convergence: 27235.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2351 -0.5354  0.0450  0.5638  3.5701 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n Student.ID (Intercept) 393.1    19.83   \n Residual               112.3    10.60   \nNumber of obs: 3236, groups:  Student.ID, 1192\n\nFixed effects:\n                               Estimate Std. Error        df t value Pr(&gt;|t|)\n(Intercept)                     42.2795     0.9374 1538.9423  45.104  &lt; 2e-16\nJunior.school.year              38.8655     0.8513 2055.4362  45.656  &lt; 2e-16\nI(Junior.school.year^2)        -20.7510     0.3983 2058.4707 -52.093  &lt; 2e-16\nGenderGirl                      10.7121     1.2869 1492.6971   8.324  &lt; 2e-16\nJunior.school.year:GenderGirl   -1.4849     0.4765 2070.6376  -3.116  0.00186\n                                 \n(Intercept)                   ***\nJunior.school.year            ***\nI(Junior.school.year^2)       ***\nGenderGirl                    ***\nJunior.school.year:GenderGirl ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Jnr.s. I(J..^ GndrGr\nJnr.schl.yr -0.255                     \nI(Jnr.s.^2)  0.131 -0.915              \nGenderGirl  -0.716  0.096  0.002       \nJnr.sch.:GG  0.241 -0.290 -0.001 -0.337\n\n#Extract variance components\nvar_comp_sim_English &lt;- (VarCorr(simplified_model_English))\nvar_comp_sim_English\n\n Groups     Name        Std.Dev.\n Student.ID (Intercept) 19.827  \n Residual               10.599  \n\n#Between ID variance\nvar_BW_sim_English &lt;- var_comp_sim_English$Student.ID[1]\nvar_BW_sim_English\n\n[1] 393.1045\n\n#Within ID variance\nvar_WW_sim_English &lt;- summary(simplified_model_English)$sigma^2\nvar_WW_sim_English\n\n[1] 112.3442\n\n#Calculate total variance and it's standard deviation\nvar_total_sim_English &lt;- var_BW_sim_English + var_WW_sim_English\nvar_total_sim_English\n\n[1] 505.4486\n\nsd_total_sim_English &lt;- sqrt(var_total_sim_English)\nsd_total_sim_English\n\n[1] 22.48218\n\n#ICC of variance components\nICC_sim_English &lt;- var_BW_sim_English / var_total_sim_English\nICC_sim_English\n\n[1] 0.7777338\n\n# Obtain the ANOVA table for the simplified model\nanova(simplified_model_English, refit=TRUE)\n\nType III Analysis of Variance Table with Satterthwaite's method\n                          Sum Sq Mean Sq NumDF  DenDF   F value    Pr(&gt;F)    \nJunior.school.year        246036  246036     1 2054.7 2190.0208 &lt; 2.2e-16 ***\nI(Junior.school.year^2)   304863  304863     1 2058.5 2713.6525 &lt; 2.2e-16 ***\nGender                      7784    7784     1 1492.7   69.2844 &lt; 2.2e-16 ***\nJunior.school.year:Gender   1091    1091     1 2070.6    9.7123  0.001855 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe ICC of 0.78 shows that 78% of the variance in the model is explained by the difference between children and the other 22% of the variance is due to the differences within an individual child. This model shows that there is an increase in English test score for each increase in Junior School Year. However there is also a negative quadratic relationship, meaning that as Junior School Year increases, the effect of this variable on the outcome diminishes. Gender significantly influence English test scores in this population, with Girls having higher test scores. There is an negative interaction effect between Gender and Junior School Year, indicating that the effect of Junior School Year on the outcome is smaller for girls compared to boys.\n\n\nCompare the two models\n\n# Perform the likelihood ratio test\nanova(simplified_model_English, random_intercept_model_English, refit = TRUE)\n\nData: dataset\nModels:\nsimplified_model_English: English.test ~ Junior.school.year + I(Junior.school.year^2) + Gender + (1 | Student.ID) + Junior.school.year:Gender\nrandom_intercept_model_English: English.test ~ Junior.school.year + I(Junior.school.year^2) + School + Gender + Gender * Junior.school.year + (1 | Student.ID)\n                               npar   AIC   BIC logLik deviance  Chisq Df\nsimplified_model_English          7 27252 27294 -13619    27238          \nrandom_intercept_model_English    8 27254 27302 -13619    27238 0.0087  1\n                               Pr(&gt;Chisq)\nsimplified_model_English                 \nrandom_intercept_model_English     0.9259\n\n\nThe full random intercept model doesn’t perform significantly better than the simplified model, thus we use the simplified model."
  },
  {
    "objectID": "Assignments/Week 5/test.html#model-diagnostics",
    "href": "Assignments/Week 5/test.html#model-diagnostics",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\nAssess the simplified model fit by generating diagnostic plots.\n\n# Extract conditional residuals\nresiduals_cond_English &lt;- resid(simplified_model_English)\n\n# Residuals vs Fitted\nplot(fitted(simplified_model_English), residuals_cond_English,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n\n\n\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond_English)\nqqline(residuals_cond_English, col = \"red\")\n\n\n\n\n\n\n\n\nThere seems to be normality of residuals and homoscedasticity, thus the model assumptions are met."
  },
  {
    "objectID": "Assignments/Week 5/test.html#data-visualisation-of-mathematics-test-scores",
    "href": "Assignments/Week 5/test.html#data-visualisation-of-mathematics-test-scores",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "Data visualisation of Mathematics test scores",
    "text": "Data visualisation of Mathematics test scores\n\n# Summary statistics of Mathematics\ndataset %&gt;%\n  summarize(\n    mean_Math.test = mean(Mathematics.test),\n    variance_Math.test = var(Mathematics.test)\n  )\n\n  mean_Math.test variance_Math.test\n1       26.66193           58.32957\n\n# Save mean statistic of Math grouped by school year\nmean_Math_year &lt;- dataset %&gt;%\n  group_by(Junior.school.year) %&gt;%\n  summarise(mean_Math_year = mean(Mathematics.test, na.rm = TRUE))\nmean_Math_year\n\n# A tibble: 3 × 2\n  Junior.school.year mean_Math_year\n               &lt;int&gt;          &lt;dbl&gt;\n1                  0           25.1\n2                  1           25.1\n3                  2           30.5\n\n# Plot the mean trajectory of Math test over the Junior School Years\nggplot(mean_Math_year, aes(x = Junior.school.year, y = mean_Math_year)) +\n  geom_line() +\n  labs(\n    title = \"Mean Math Test Score Trajectory\",\n    x = \"Junior School Year\",\n    y = \"Mean Math Test Score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Calculate the average Math test score for each School\nSchool_avg_Math.test &lt;- top_Schools_data %&gt;%\n  group_by(School) %&gt;%\n  summarise(mean_Mathematics.test = mean(Mathematics.test, na.rm = TRUE))\n\n# create a scatter plot of Math test score by School\nggplot(top_Schools_data, aes(x = School, y = Mathematics.test)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Math test score by School\",\n       x = \"School\",\n       y = \"Math test score\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_point(data = School_avg_Math.test, aes(x = School, y = mean_Mathematics.test), color = \"red\", size = 3) +  # School-level averages \n  geom_hline(yintercept = mean(School_avg_Math.test$mean_Mathematics.test, na.rm = TRUE), linetype = \"dashed\", color = \"blue\") # overall average\n\n\n\n\n\n\n\n# Filter dataset for the sampled IDs and plot Math test for individual students\ndataset %&gt;%\n  filter(Student.ID %in% sampled_ids) %&gt;%\n   ggplot(aes(x = Junior.school.year, y = Mathematics.test)) +\n  geom_line() +                               \n  geom_point(size = 2, alpha = 0.7) +         \n  facet_wrap(~ Student.ID) +                          \n  labs(\n    title = \"Individual Math Score Trajectories with Data Points\",\n    x = \"Junior school year\",\n    y = \"Math test score\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Compute the mean Math score by school year and gender\nmean_Math_gender &lt;- dataset %&gt;%\n  group_by(Junior.school.year, Gender) %&gt;%\n  summarise(mean_Math_gender = mean(Mathematics.test, na.rm = TRUE))\nmean_Math_gender\n\n# A tibble: 6 × 3\n# Groups:   Junior.school.year [3]\n  Junior.school.year Gender mean_Math_gender\n               &lt;int&gt; &lt;fct&gt;             &lt;dbl&gt;\n1                  0 Boy                24.9\n2                  0 Girl               25.2\n3                  1 Boy                24.8\n4                  1 Girl               25.3\n5                  2 Boy                30.5\n6                  2 Girl               30.5\n\n# Plot the mean trajectories\nggplot(mean_Math_gender, aes(x = Junior.school.year, y = mean_Math_gender, color = Gender)) +\n  geom_line() +\n  labs(\n    title = \"Mean Math Test Score Trajectories by gender\",\n    x = \"Junior School Year\",\n    y = \"Mean Math Test Score\"\n  ) +\n  scale_color_manual(values = c(\"Boy\" = \"blue\", \"Girl\" = \"red\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis data visualisation shows the different trajectories of Math test scores within a random sample of students. The mean trajectory seem to show a linear relationship between Junior School Year and Math Test scores from the first year onwards. There are different mean scores between schools, indicating that school could be a relevant explanatory variable. In addition, Girls seem to have higher mean Math test scores than boys,especially in the first year, indicating a possible relationship between gender and test score."
  },
  {
    "objectID": "Assignments/Week 5/test.html#multi-level-modeling-of-mathematics-test-scores",
    "href": "Assignments/Week 5/test.html#multi-level-modeling-of-mathematics-test-scores",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "Multi-level modeling of Mathematics Test Scores",
    "text": "Multi-level modeling of Mathematics Test Scores\n\nRandom intercept model\nFit a full model with a random intercept. Examine the variance components\n\n#Random intercept model \nrandom_intercept_model_Math &lt;- lmer(Mathematics.test ~ Junior.school.year + School + Gender + Gender*Junior.school.year + (1 | Student.ID), data = dataset)\nsummary(random_intercept_model_Math)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Mathematics.test ~ Junior.school.year + School + Gender + Gender *  \n    Junior.school.year + (1 | Student.ID)\n   Data: dataset\n\nREML criterion at convergence: 20593.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6170 -0.5016  0.0289  0.5406  3.2519 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n Student.ID (Intercept) 37.93    6.159   \n Residual               16.43    4.054   \nNumber of obs: 3236, groups:  Student.ID, 1192\n\nFixed effects:\n                               Estimate Std. Error        df t value Pr(&gt;|t|)\n(Intercept)                   2.349e+01  4.585e-01 1.359e+03  51.231   &lt;2e-16\nJunior.school.year            2.392e+00  1.311e-01 2.086e+03  18.237   &lt;2e-16\nSchool                        1.919e-02  1.294e-02 1.186e+03   1.483    0.138\nGenderGirl                    4.254e-01  4.202e-01 1.628e+03   1.012    0.312\nJunior.school.year:GenderGirl 1.530e-02  1.819e-01 2.086e+03   0.084    0.933\n                                 \n(Intercept)                   ***\nJunior.school.year            ***\nSchool                           \nGenderGirl                       \nJunior.school.year:GenderGirl    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Jnr.s. School GndrGr\nJnr.schl.yr -0.262                     \nSchool      -0.750  0.001              \nGenderGirl  -0.453  0.285 -0.032       \nJnr.sch.:GG  0.188 -0.721  0.000 -0.395\n\n#Extract variance components\nvar_comp_Math &lt;- (VarCorr(random_intercept_model_Math))\nvar_comp_Math\n\n Groups     Name        Std.Dev.\n Student.ID (Intercept) 6.1590  \n Residual               4.0536  \n\n#Between ID variance\nvar_BW_Math &lt;- var_comp_Math$Student.ID[1]\nvar_BW_Math\n\n[1] 37.93366\n\n#Within ID variance\nvar_WW_Math &lt;- summary(random_intercept_model_Math)$sigma^2\nvar_WW_Math\n\n[1] 16.4317\n\n#Calculate total variance, standard deviation and ICC\nvar_total_Math &lt;- var_BW_Math + var_WW_Math\nvar_total_Math\n\n[1] 54.36536\n\nsd_total_Math &lt;- sqrt(var_total_Math)\nsd_total_Math\n\n[1] 7.373287\n\n#ICC of variance components\nICC_Math &lt;- var_BW_Math / var_total_Math\nICC_Math\n\n[1] 0.6977542\n\n\nThe ICC of 0.70 shows that 70% of the variance in the model is explained by the difference between children and the other 30% of the variance is due to the differences within an individual child\n\n\nRefine the fixed effects\nRefine the fixed effects using the ANOVA table of the random slope model\n\n#Obtain the ANOVA table for the individual-level variables\nanova(random_intercept_model_Math)\n\nType III Analysis of Variance Table with Satterthwaite's method\n                           Sum Sq Mean Sq NumDF  DenDF  F value Pr(&gt;F)    \nJunior.school.year        11435.6 11435.6     1 2086.0 695.9455 &lt;2e-16 ***\nSchool                       36.1    36.1     1 1185.5   2.1984 0.1384    \nGender                       16.8    16.8     1 1628.2   1.0247 0.3115    \nJunior.school.year:Gender     0.1     0.1     1 2086.0   0.0071 0.9330    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Perform stepwise selection to identify the most important predictors\nstep(random_intercept_model_Math, reduce.random = FALSE)\n\nBackward reduced random-effect table:\n\n                 Eliminated npar logLik   AIC  LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;                         7 -10297 20608                       \n(1 | Student.ID)          0    6 -11044 22101 1495  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBackward reduced fixed-effect table:\nDegrees of freedom method: Satterthwaite \n\n                          Eliminated  Sum Sq Mean Sq NumDF  DenDF  F value\nJunior.school.year:Gender          1     0.1     0.1     1 2086.0   0.0071\nGender                             2    21.3    21.3     1 1180.7   1.2957\nSchool                             3    38.1    38.1     1 1186.2   2.3181\nJunior.school.year                 0 11451.9 11451.9     1 2087.0 697.2552\n                          Pr(&gt;F)    \nJunior.school.year:Gender 0.9330    \nGender                    0.2552    \nSchool                    0.1281    \nJunior.school.year        &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nModel found:\nMathematics.test ~ Junior.school.year + (1 | Student.ID)\n\n\nThe ANOVA table shows that School, Gender and the interaction term between Gender and Junior School Year were not significant, thus can be removed from the model. Stepwise backward selection also provides the simplified model as the best fitting model: Mathematics.test ~ Junior.school.year + (1 | Student.ID)\n\n# Fit the simplified model without the interaction term\nsimplified_model_Math &lt;- lmer(Mathematics.test ~ Junior.school.year + (1 | Student.ID), data = dataset)\nsummary(simplified_model_Math)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Mathematics.test ~ Junior.school.year + (1 | Student.ID)\n   Data: dataset\n\nREML criterion at convergence: 20588.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6392 -0.5054  0.0284  0.5411  3.2530 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n Student.ID (Intercept) 37.99    6.164   \n Residual               16.42    4.053   \nNumber of obs: 3236, groups:  Student.ID, 1192\n\nFixed effects:\n                    Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)        2.423e+01  2.099e-01 1.631e+03  115.42   &lt;2e-16 ***\nJunior.school.year 2.399e+00  9.085e-02 2.087e+03   26.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nJnr.schl.yr -0.395\n\n#Extract variance components\nvar_comp_sim_Math &lt;- (VarCorr(simplified_model_Math))\nvar_comp_sim_Math\n\n Groups     Name        Std.Dev.\n Student.ID (Intercept) 6.1639  \n Residual               4.0527  \n\n#Between ID variance\nvar_BW_sim_Math &lt;- var_comp_sim_Math$Student.ID[1]\nvar_BW_sim_Math\n\n[1] 37.99391\n\n#Within ID variance\nvar_WW_sim_Math &lt;- summary(simplified_model_Math)$sigma^2\nvar_WW_sim_Math\n\n[1] 16.42428\n\n#Calculate total variance and it's standard deviation\nvar_total_sim_Math &lt;- var_BW_sim_Math + var_WW_sim_Math\nvar_total_sim_Math\n\n[1] 54.41819\n\nsd_total_sim_Math &lt;- sqrt(var_total_sim_Math)\nsd_total_sim_Math\n\n[1] 7.376868\n\n#ICC of variance components\nICC_sim_Math&lt;- var_BW_sim_Math / var_total_sim_Math\nICC_sim_Math\n\n[1] 0.698184\n\n# Obtain the ANOVA table for the simplified model\nanova(simplified_model_Math, refit=TRUE)\n\nType III Analysis of Variance Table with Satterthwaite's method\n                   Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nJunior.school.year  11452   11452     1  2087  697.26 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe ICC of 0.70 shows that 70% of the variance in the model is explained by the difference between children and the other 30% of the variance is due to the differences within an individual child. This model shows that only Junior School Year significantly influences Math test scores in this population, with an increase in Math test scores of 2.399 per increase in Junior School Year.\n\n\nCompare the two models\n\n# Perform the likelihood ratio test\nanova(simplified_model_Math, random_intercept_model_Math, refit = TRUE)\n\nData: dataset\nModels:\nsimplified_model_Math: Mathematics.test ~ Junior.school.year + (1 | Student.ID)\nrandom_intercept_model_Math: Mathematics.test ~ Junior.school.year + School + Gender + Gender * Junior.school.year + (1 | Student.ID)\n                            npar   AIC   BIC logLik deviance  Chisq Df\nsimplified_model_Math          4 20592 20617 -10292    20584          \nrandom_intercept_model_Math    7 20595 20637 -10290    20581 3.6248  3\n                            Pr(&gt;Chisq)\nsimplified_model_Math                 \nrandom_intercept_model_Math     0.3049\n\n\nThe full random intercept model doesn’t perform significantly better than the simplified model, thus we use the simplified model."
  },
  {
    "objectID": "Assignments/Week 5/test.html#model-diagnostics-1",
    "href": "Assignments/Week 5/test.html#model-diagnostics-1",
    "title": "Assignment 5: Multilevel data from the Junior School Project (graded)",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\nAssess the simplified model fit by generating diagnostic plots.\n\n# Extract conditional residuals\nresiduals_cond_Math &lt;- resid(simplified_model_Math)\n\n# Residuals vs Fitted\nplot(fitted(simplified_model_Math), residuals_cond_Math,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n\n\n\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond_Math)\nqqline(residuals_cond_Math, col = \"red\")\n\n\n\n\n\n\n\n\nThere seems to be normality of residuals and homoscedasticity, thus the model assumptions are met."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#coding-schemes-treatment-vs-effects",
    "href": "lectures_2526/BLR_Week_1_reveal.html#coding-schemes-treatment-vs-effects",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Coding Schemes (Treatment vs Effects)",
    "text": "Coding Schemes (Treatment vs Effects)\n\n# A tiny design matrix demo (no execution during presentation)\nset.seed(1)\ndf &lt;- data.frame(\n  group = factor(rep(c(\"A\",\"B\",\"C\"), each = 4)),\n  y = rnorm(12, mean = rep(c(0, 1, 2), each = 4), sd = 1)\n)\n\n# Treatment coding (default)\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))\nmm_treat &lt;- model.matrix(~ group, df)\n\n# Effects coding\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\nmm_effects &lt;- model.matrix(~ group, df)\n\n# Inspect the first few rows\nhead(mm_treat)\n\n  (Intercept) groupB groupC\n1           1      0      0\n2           1      0      0\n3           1      0      0\n4           1      0      0\n5           1      1      0\n6           1      1      0\n\nhead(mm_effects)\n\n  (Intercept) group1 group2\n1           1      1      0\n2           1      1      0\n3           1      1      0\n4           1      1      0\n5           1      0      1\n6           1      0      1\n\n\n\n\nUnder treatment coding, coefficients compare to a reference level.\nUnder effects coding, coefficients represent deviations from the grand mean."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#fitting-the-fe-model-emmeans",
    "href": "lectures_2526/BLR_Week_1_reveal.html#fitting-the-fe-model-emmeans",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Fitting the FE Model & emmeans",
    "text": "Fitting the FE Model & emmeans\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\nfit_fe &lt;- lm(y ~ group, data = df)\nsummary(fit_fe)\n\n\nCall:\nlm(formula = y ~ group, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0042 -0.7413  0.0686  0.3664  1.5161 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.26864    0.25012   5.072  0.00067 ***\ngroup1      -1.18943    0.35373  -3.363  0.00835 ** \ngroup2      -0.08494    0.35373  -0.240  0.81561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8664 on 9 degrees of freedom\nMultiple R-squared:  0.6433,    Adjusted R-squared:  0.564 \nF-statistic: 8.115 on 2 and 9 DF,  p-value: 0.009672\n\n# Estimated marginal means and pairwise comparisons (Tukey)\n# library(emmeans)\n# ems &lt;- emmeans(fit_fe, ~ group)\n# contrast(ems, method = \"pairwise\", adjust = \"tukey\")"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#effect-sizes-η²-ω²-reporting",
    "href": "lectures_2526/BLR_Week_1_reveal.html#effect-sizes-η²-ω²-reporting",
    "title": "Beyond MLR – Week 1: Experimental Design I",
    "section": "Effect Sizes (η², ω²) & Reporting",
    "text": "Effect Sizes (η², ω²) & Reporting\n\n\n  eta2 omega2 \n 0.643  0.542 \n\n\n\nReport: F-statistic, p-value, effect size (η²/ω²), emmeans with multiplicity control, and a 1–2 line assumptions note"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#assumptions-alternatives",
    "href": "lectures_2526/BLR_Week_1_reveal.html#assumptions-alternatives",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Assumptions & Alternatives",
    "text": "Assumptions & Alternatives\n\nHomoscedasticity, normality of residuals â†’ check residual vs fitted, QQ plot\nLeveneâ€™s test for equal variances; Welchâ€™s ANOVA if unequal\n\n\n# car::leveneTest(y ~ group, data = df)\n# oneway.test(y ~ group, data = df, var.equal = FALSE)  # Welch ANOVA"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#re-model-icc",
    "href": "lectures_2526/BLR_Week_1_reveal.html#re-model-icc",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "RE Model & ICC",
    "text": "RE Model & ICC\n\n# library(lme4)\n# fit_re &lt;- lmer(y ~ 1 + (1 | group), data = df)\n# summary(fit_re)\n\n# varcmp &lt;- as.data.frame(VarCorr(fit_re))\n# sigma_b2 &lt;- varcmp$vcov[varcmp$grp == \"group\"]\n# sigma2   &lt;- varcmp$vcov[varcmp$grp == \"Residual\"]\n# ICC &lt;- sigma_b2 / (sigma_b2 + sigma2)\n# ICC\n\n\n\nIn RE, the primary target is variability across levels (ÏƒÂ²_b); ICC quantifies clustering.\nP-values for fixed effects are not the focus; random effects need enough levels for stable estimation."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#fe-vs-re-side-by-side",
    "href": "lectures_2526/BLR_Week_1_reveal.html#fe-vs-re-side-by-side",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "FE vs RE: Side-by-Side",
    "text": "FE vs RE: Side-by-Side\n\n\n\nFixed Effects (FE)\n\nInference about these specific levels\nReport contrasts/emmeans (+ multiplicity)\nEffect sizes: \\(\\\\eta^2\\) / \\(\\\\omega^2\\)\nAssumptions: homoscedasticity, normality\n\n\n\n\nRandom Effects (RE)\n\nInference about variability across possible levels\nReport variance components and ICC\nNeeds sufficient levels; watch singular fits\nFocus on reliability and generalization\n\n\n\n\n\nChoice depends on scope of inference and estimand"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#micro-simulation-conceptual",
    "href": "lectures_2526/BLR_Week_1_reveal.html#micro-simulation-conceptual",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Micro-Simulation (Conceptual)",
    "text": "Micro-Simulation (Conceptual)\n\n# # Vary between-level variance and observe ICC\n# sim_icc &lt;- function(s2_b = 0.5, s2 = 1, k = 4, J = 10){\n#   grp &lt;- factor(rep(1:J, each = k))\n#   b &lt;- rnorm(J, 0, sqrt(s2_b))\n#   y &lt;- 0 + b[grp] + rnorm(J*k, 0, sqrt(s2))\n#   d &lt;- data.frame(grp, y)\n#   m &lt;- lmer(y ~ 1 + (1|grp), data = d)\n#   vc &lt;- as.data.frame(VarCorr(m))\n#   sb2 &lt;- vc$vcov[vc$grp==\"grp\"]; s2e &lt;- vc$vcov[vc$grp==\"Residual\"]\n#   sb2/(sb2+s2e)\n# }\n# sapply(c(0.1, 0.5, 1, 2), sim_icc)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#welcome-plan",
    "href": "lectures_2526/BLR_Week_1_reveal.html#welcome-plan",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "",
    "text": "Course flow: design â†’ model â†’ estimand â†’ diagnostics â†’ reporting\nToday: one-way FE ANOVA, coding schemes, emmeans, effect sizes, assumptions, and the one-way RE model with ICC\nOutcome: decide fixed vs random for a factor and justify; report either contrasts (FE) or variance components (RE)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#learning-objectives",
    "href": "lectures_2526/BLR_Week_1_reveal.html#learning-objectives",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDecide and justify whether a factor is modeled as fixed or random\nInterpret ANOVA coefficients under treatment/effects coding\nUse estimated marginal means and multiplicity-adjusted comparisons\nInterpret variance components and compute ICC in a one-way RE model\nAssess assumptions; know Welch/Levene fallbacks"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#entry-one-way-anova-as-design-model",
    "href": "lectures_2526/BLR_Week_1_reveal.html#entry-one-way-anova-as-design-model",
    "title": "Beyond MLR – Week 1: Experimental Design I",
    "section": "Entry: One-Way ANOVA as Design → Model",
    "text": "Entry: One-Way ANOVA as Design → Model\n\nDesign: three-level factor (e.g., Treatment A/B/C)\nGoal (FE): compare specific group means (contrasts, emmeans)\nData → Model: encode the factor, fit linear model, inspect ANOVA, follow-up with emmeans"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#one-way-random-effects-model-re",
    "href": "lectures_2526/BLR_Week_1_reveal.html#one-way-random-effects-model-re",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "One-Way Random Effects Model (RE)",
    "text": "One-Way Random Effects Model (RE)\n\nContext: factor levels are sampled from a broader population (e.g., nurses, labs)\nEstimands: variance components (between, residual) and ICC"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#fixed-vs-random-decision-tree",
    "href": "lectures_2526/BLR_Week_1_reveal.html#fixed-vs-random-decision-tree",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Fixed vs Random: Decision Tree",
    "text": "Fixed vs Random: Decision Tree\n\nAre levels exhaustive (fixed) or sampled from a population (random)?\nWhatâ€™s the estimand? Contrasts across specific levels (fixed) or variance components/ICC (random)?\nWould adding new levels change the scientific claim (random) or be out of scope (fixed)?"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#examples-classify-and-justify",
    "href": "lectures_2526/BLR_Week_1_reveal.html#examples-classify-and-justify",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Examples: Classify and Justify",
    "text": "Examples: Classify and Justify\n\nDrug A/B/C vs placebo (trial): levels are the target â†’ fixed\nNurses measuring waist circumference: levels sampled â†’ random\nSpecific machines under evaluation (compliance check): fixed\nSchools sampled from a city (student outcomes): random"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#interpretation-fe-outputs",
    "href": "lectures_2526/BLR_Week_1_reveal.html#interpretation-fe-outputs",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Interpretation: FE Outputs",
    "text": "Interpretation: FE Outputs\n\nWith effects coding, the intercept is the grand mean.\nCoefficients are deviations from the grand mean; emmeans recover group means and SEs.\nReport contrasts with Tukey adjustment; include effect sizes \\(\\\\eta^2/\\\\omega^2\\)."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#interpretation-re-outputs",
    "href": "lectures_2526/BLR_Week_1_reveal.html#interpretation-re-outputs",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Interpretation: RE Outputs",
    "text": "Interpretation: RE Outputs\n\nReport variance components: \\(\\\\sigma^2_{\\\\text{between}}\\) (group), \\(\\\\sigma^2_{\\\\text{residual}}\\).\nICC \\(= \\\\sigma^2_{\\\\text{between}} / (\\\\sigma^2_{\\\\text{between}} + \\\\sigma^2_{\\\\text{residual}})\\): proportion of total variance due to grouping.\nEmphasis on reliability and generalization across potential new levels."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#icc-what-values-mean-rule-of-thumb",
    "href": "lectures_2526/BLR_Week_1_reveal.html#icc-what-values-mean-rule-of-thumb",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "ICC: What Values Mean (Rule of Thumb)",
    "text": "ICC: What Values Mean (Rule of Thumb)\n\nâ‰ˆ 0.00â€“0.05: weak clustering; FE often fine if scope is specific.\nâ‰ˆ 0.05â€“0.20: meaningful clustering; RE advantageous; blocking helps.\n\n0.20: strong clustering; design/analysis must account for grouping."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#assumption-checks-quick-rubric",
    "href": "lectures_2526/BLR_Week_1_reveal.html#assumption-checks-quick-rubric",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Assumption Checks: Quick Rubric",
    "text": "Assumption Checks: Quick Rubric\n\nResiduals vs fitted: random scatter (ok); funneling (heteroscedasticity) â†’ Welch/transform.\nQQ plot: mild curvature acceptable with nâ‰¥30; heavy tails â†’ robust SEs or transformation.\nFor RE: inspect BLUPs qualitatively; beware singular fits (variance ~ 0)."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#reporting-templates-examples",
    "href": "lectures_2526/BLR_Week_1_reveal.html#reporting-templates-examples",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Reporting Templates (Examples)",
    "text": "Reporting Templates (Examples)\n\nFE: â€œA one-way ANOVA detected a treatment effect, F(2, 117)=â€¦, p=â€¦. Effect size Ï‰Â²=â€¦. Tukey-adjusted comparisons showed A&gt;B (p=â€¦), A&gt;C (p=â€¦), Bâ‰ˆC (p=â€¦). Assumptions were checked (no major deviations).â€\nRE: â€œA random-intercept model estimated between-nurse variance ÏƒÂ²_b=â€¦, residual variance ÏƒÂ²=â€¦, ICC=â€¦. Diagnostics did not indicate major violations.â€"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#micro-simulation-conceptual-1",
    "href": "lectures_2526/BLR_Week_1_reveal.html#micro-simulation-conceptual-1",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Micro-Simulation (Conceptual)",
    "text": "Micro-Simulation (Conceptual)\n\nCoding swap: effects vs treatment; interpret one coefficient in plain English\nFE vs RE â€œhot seatâ€: decide fixed or random for short vignettes and justify\nQuick diagnostics: identify if Welch/Levene is needed from a plot description"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#in-class-activities",
    "href": "lectures_2526/BLR_Week_1_reveal.html#in-class-activities",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "In-Class Activities",
    "text": "In-Class Activities\n\nCoding swap: effects vs treatment; interpret one coefficient in plain English\nFE vs RE â€œhot seatâ€: decide fixed or random for short vignettes and justify\nQuick diagnostics: identify if Welch/Levene is needed from a plot description"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#key-takeaways",
    "href": "lectures_2526/BLR_Week_1_reveal.html#key-takeaways",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nChoose FE when inference targets specific levels; RE when targeting variability across possible levels.\nAlways align analysis to the estimand: contrasts vs variance components.\nReport with effect sizes (FE) or ICC/variance components (RE), plus a brief assumptions note."
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#references",
    "href": "lectures_2526/BLR_Week_1_reveal.html#references",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "References",
    "text": "References\n\nOehlert â€” design and ANOVA\nRoback & Legler â€” mixed models context\nR4DS â€” workflow & plotting"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-anova-fe-model-and-hypothesis",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-anova-fe-model-and-hypothesis",
    "title": "Beyond MLR – Week 1: Experimental Design I",
    "section": "Detailed: One-Way ANOVA (FE) — Model and Hypothesis",
    "text": "Detailed: One-Way ANOVA (FE) — Model and Hypothesis\n\nModel (effects coding): Y_ij = mu + tau_i + e_ij, with sum_i tau_i = 0 and e_ij ~ N(0, sigma^2)\nGroup mean: mu_i = mu + tau_i; estimand is the set of pairwise contrasts among mu_i\nHypothesis: H0: tau_1 = tau_2 = … = tau_k = 0 (all means equal)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-anova-computations",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-anova-computations",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Detailed: ANOVA Computations",
    "text": "Detailed: ANOVA Computations\n\nBetween SS: SS_Tr = sum_i n_i (ybar_i. - ybar_..)^2\nWithin SS: SS_E = sum_i sum_j (y_ij - ybar_i.)^2\nMS_Tr = SS_Tr/(k-1); MS_E = SS_E/(N-k); F = MS_Tr / MS_E ~ F_{k-1, N-k} under H0\nEffect sizes: \\(\\\\eta^2\\) / \\(\\\\omega^2\\)\n\neta^2 = SS_Tr / (SS_Tr + SS_E) (biased upward)\nomega^2 = (SS_Tr - (k-1) MS_E) / (SS_Tr + SS_E + MS_E) (preferred)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-coding-schemes-example-matrices",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-coding-schemes-example-matrices",
    "title": "Beyond MLR – Week 1: Experimental Design I",
    "section": "Detailed: Coding Schemes — Example Matrices",
    "text": "Detailed: Coding Schemes — Example Matrices\n\nTreatment coding (reference = A) for 3 levels (A,B,C) has columns for B and C (contrasts vs A)\nEffects coding has columns that sum to zero; coefficients are deviations from grand mean\nMapping to means with effects coding: mu_A = mu + tau_A, etc., with tau_A + tau_B + tau_C = 0"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-re-model-and-icc",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-re-model-and-icc",
    "title": "Beyond MLR – Week 1: Experimental Design I",
    "section": "Detailed: One-Way RE — Model and ICC",
    "text": "Detailed: One-Way RE — Model and ICC\n\nModel: Y_ij = mu + b_i + e_ij, b_i ~ N(0, sigma_b^2), e_ij ~ N(0, sigma^2)\nVariance decomposition: Var(Y_ij) = sigma_b^2 + sigma^2\nICC (rho) = sigma_b^2 / (sigma_b^2 + sigma^2)\nInterpretation: probability two observations from same group are more similar; higher rho implies stronger clustering"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-blups-and-shrinkage-intuition",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-blups-and-shrinkage-intuition",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Detailed: BLUPs And Shrinkage (Intuition)",
    "text": "Detailed: BLUPs And Shrinkage (Intuition)\n\nRandom-intercept estimate for group i shrinks the raw group mean toward the overall mean\nShrinkage factor: n_isigma_b^2 / (n_isigma_b^2 + sigma^2)\nSmall n_i or small sigma_b^2 â†’ stronger shrinkage (more pooling)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html",
    "href": "lectures_2526/BLR_Week_1_reveal.html",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "",
    "text": "Course flow: design â†’ model â†’ estimand â†’ diagnostics â†’ reporting\nToday: one-way FE ANOVA, coding schemes, emmeans, effect sizes, assumptions, and the one-way RE model with ICC\nOutcome: decide fixed vs random for a factor and justify; report either contrasts (FE) or variance components (RE)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#entry-one-way-anova-as-design-â-model",
    "href": "lectures_2526/BLR_Week_1_reveal.html#entry-one-way-anova-as-design-â-model",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Entry: One-Way ANOVA as Design â†’ Model",
    "text": "Entry: One-Way ANOVA as Design â†’ Model\n\nDesign: three-level factor (e.g., Treatment A/B/C)\nGoal (FE): compare specific group means (contrasts, emmeans)\nData â†’ Model: encode the factor, fit linear model, inspect ANOVA, follow-up with emmeans"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#one-way-anova-fe-model",
    "href": "lectures_2526/BLR_Week_1_reveal.html#one-way-anova-fe-model",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "One-Way ANOVA (FE) — Model",
    "text": "One-Way ANOVA (FE) — Model\n\\[\nY_{ij} = \\mu + \\tau_i + \\varepsilon_{ij},\\quad \\sum_{i=1}^k \\tau_i = 0,\\quad \\varepsilon_{ij} \\sim \\mathcal N(0,\\sigma^2)\n\\]\n\nGroup mean: \\(\\mu_i = \\mu + \\tau_i\\)\nNull hypothesis: \\(H_0\\!:\\; \\tau_1 = \\cdots = \\tau_k = 0\\)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#anova-quantities",
    "href": "lectures_2526/BLR_Week_1_reveal.html#anova-quantities",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "ANOVA Quantities",
    "text": "ANOVA Quantities\n\nBetween SS: \\(SS_\\mathrm{Tr} = \\sum_i n_i\\,(\\bar y_{i\\cdot} - \\bar y_{\\cdot\\cdot})^2\\)\nWithin SS: \\(SS_\\mathrm{E} = \\sum_i \\sum_j (y_{ij} - \\bar y_{i\\cdot})^2\\)\n\\(F = \\dfrac{SS_\\mathrm{Tr}/(k-1)}{SS_\\mathrm{E}/(N-k)} \\sim F_{k-1,\\,N-k}\\) under \\(H_0\\)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#effect-sizes-eta2-omega2-reporting",
    "href": "lectures_2526/BLR_Week_1_reveal.html#effect-sizes-eta2-omega2-reporting",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Effect Sizes (\\(\\\\eta^2\\), \\(\\\\omega^2\\)) & Reporting",
    "text": "Effect Sizes (\\(\\\\eta^2\\), \\(\\\\omega^2\\)) & Reporting\n\nan &lt;- anova(fit_fe)\nSST &lt;- sum(an$\"Sum Sq\")\nSSTR &lt;- an$\"Sum Sq\"[1]\nSSE &lt;- an$\"Sum Sq\"[2]\ndf_tr &lt;- an$Df[1]; df_e &lt;- an$Df[2]\nMSE &lt;- SSE / df_e\neta2 &lt;- SSTR / SST\nomega2 &lt;- (SSTR - df_tr*MSE) / (SST + MSE)\nround(c(eta2 = eta2, omega2 = omega2), 3)\n\n  eta2 omega2 \n 0.643  0.542 \n\n\n\nReport: F-statistic, p-value, effect size (\\(\\\\eta^2/\\\\omega^2\\)), emmeans with multiplicity control, and a 1â€“2 line assumptions note"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-anova-fe-â-model-and-hypothesis",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-anova-fe-â-model-and-hypothesis",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Detailed: One-Way ANOVA (FE) â€” Model and Hypothesis",
    "text": "Detailed: One-Way ANOVA (FE) â€” Model and Hypothesis\n\nModel (effects coding): Y_ij = mu + tau_i + e_ij, with sum_i tau_i = 0 and e_ij ~ N(0, sigma^2)\nGroup mean: mu_i = mu + tau_i; estimand is the set of pairwise contrasts among mu_i\nHypothesis: H0: tau_1 = tau_2 = … = tau_k = 0 (all means equal)"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-coding-schemes-â-example-matrices",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-coding-schemes-â-example-matrices",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Detailed: Coding Schemes â€” Example Matrices",
    "text": "Detailed: Coding Schemes â€” Example Matrices\n\nTreatment coding (reference = A) for 3 levels (A,B,C) has columns for B and C (contrasts vs A)\nEffects coding has columns that sum to zero; coefficients are deviations from grand mean\nMapping to means with effects coding: mu_A = mu + tau_A, etc., with tau_A + tau_B + tau_C = 0"
  },
  {
    "objectID": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-re-â-model-and-icc",
    "href": "lectures_2526/BLR_Week_1_reveal.html#detailed-one-way-re-â-model-and-icc",
    "title": "Beyond MLR â€“ Week 1: Experimental Design I",
    "section": "Detailed: One-Way RE â€” Model and ICC",
    "text": "Detailed: One-Way RE â€” Model and ICC\n\nModel: Y_ij = mu + b_i + e_ij, b_i ~ N(0, sigma_b^2), e_ij ~ N(0, sigma^2)\nVariance decomposition: Var(Y_ij) = sigma_b^2 + sigma^2\nICC (rho) = sigma_b^2 / (sigma_b^2 + sigma^2)\nInterpretation: probability two observations from same group are more similar; higher rho implies stronger clustering"
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html",
    "href": "PART1_Experimental_Design_Outline.html",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Build intuition for design-first thinking before connecting to regression.\nMake fixed vs random factor decisions explicit and justified.\nInterpret variance components (one-way random effects) and compute ICC.\nCommunicate results with effect sizes (for FE) or variance components/ICC (for RE) and clear assumptions checks.\n\n\n\n\n\nLead with one-way ANOVA as the design-to-model path; only later show it as a linear model special case.\nAnchor with two concrete contexts:\n\nFixed levels: drug A/B/C (treatment differences are the target).\nRandom levels: nurses/labs/machines (levels sampled from a population; variability is the target).\n\n\n\n\n\n\nThree-question test:\n\nAre the levels the only ones of interest (fixed) or a sample from a broader population (random)?\nIs the estimand level-specific contrasts (fixed) or variance components/ICC (random)?\nWould adding new levels change the scientific claim (random) or be out of scope (fixed)?\n\nScope-of-inference ladder:\n\nFixed: statements about these specific levels; emphasize contrasts and emmeans.\nRandom: statements about between-level variability and reliability; emphasize variance components and ICC.\n\nEstimand spotlight for every example: clearly state “what is estimated” and “how reported”.\n\n\n\n\n\nPart A — One-way FE ANOVA\n\nCoding schemes: treatment vs effects; show model.matrix(); map coefficients to group means.\nEstimated marginal means and pairwise comparisons (Tukey recommended).\nEffect sizes: eta-squared and omega-squared; add a short reporting template.\nAssumptions: residual vs fitted, QQ; Levene test; Welch ANOVA fallback.\n\nPart B — One-way RE model\n\nVariance components (between vs residual); ICC calculation and interpretation.\nEmphasize that the estimand is the variance structure, not pairwise mean differences.\nNote on p-values in lme4 and when to bring in lmerTest.\n\nPart C — Side-by-side comparison\n\nFit FE and RE to the same dataset; compare targets of inference and reporting outputs.\nMicro-simulation: increase between-level variance to show ICC growth and motivation for RE.\n\nDeliverable (Week 1)\n\nChoose FE or RE for a given vignette and justify in 3–5 sentences.\nFE: report ANOVA, effect sizes, emmeans with multiplicity control, and a brief assumptions note.\nRE: report variance components and ICC with interpretation, plus diagnostics note.\n\n\n\n\n\n\nCRD vs RB variance story (visual): show how blocking reduces within-block error; link to precision.\nFixed vs random blocks:\n\nFixed if blocks are the specific conditions of interest; random if blocks represent sampled nuisance heterogeneity.\n\nReplicated RB and interactions:\n\nRandom Treatment×Block interaction; LRT under REML with refit = FALSE; plain-English interpretation of the LRT.\n\nUnbalanced/missing cells:\n\nShow why mixed models are more robust than two-way ANOVA in practice.\n\nDeliverable (Week 2)\n\nFit two-way ANOVA (blocks fixed) and mixed model (1 | block); pick a final model with rationale.\nQuantify variance reduction (e.g., ICC or variance components) and report treatment comparisons with multiplicity control.\n\n\n\n\n\n\nCoding swap: effects vs treatment; compute emmeans; interpret one coefficient in plain English.\nFE vs RE hot seat: 6 short vignettes; students vote and justify fixed/random.\nTiny sim: CRD vs RB precision under varying block variance; discuss when blocking pays off.\nVariance table interpretation: given between and residual variances, compute ICC and write a one-sentence claim.\n\n\n\n\n\nLab 1 (FE one-way)\n\nDefault eval = TRUE; add model.matrix() demo; add emmeans with Tukey; add Levene/Welch.\nAdd effect sizes (eta^2, omega^2) and a reporting template.\n\nLab 2 (RE one-way)\n\nAdd explicit variance components table; ICC calculation; residual and QQ plots with a short rubric.\n\nLab 3 (Randomized block)\n\nCompare two-way ANOVA (blocks fixed) vs mixed (1 | block); discuss equivalence/df differences.\nUse emmeans for treatment comparisons; compute ICC for blocks.\n\nLab 4 (Replicated RB)\n\nInclude random Treatment×Block interaction; LRT under REML with refit = FALSE; guidance on model choice.\n\n\n\n\n\n\nWeek 1\n\nFE path: effect sizes present; contrasts correctly interpreted; assumptions addressed.\nRE path: variance components and ICC correctly reported; interpretation targets variability, not pairwise means.\n\nWeek 2\n\nClear justification of fixed vs random blocks; correct use of LRT for interaction (if replicated design); multiplicity control for treatment effects.\n\n\n\n\n\n\nToo few levels (&lt;= 3) for random effects: warn about unstable variance estimates; consider fixed effects.\nSingular fits: what they mean and how to communicate.\nDo not treat subject/cluster IDs as fixed (except pedagogically); they are typically random.\nTwo-way ANOVA with missing cells: highlight limitations; prefer mixed models.\n\n\n\n\n\nPipeline figure: raw means → coding → coefficients → emmeans.\nVariance bar chart: CRD vs RB error components.\nSide-by-side outputs: two-way ANOVA vs mixed model; highlight df and inference targets.\n“Estimand card” on each example: what, scale, and how reported.\n\n\n\n\n\nOehlert (design & ANOVA), selected chapters.\nRoback & Legler (mixed models context), selected sections.\nR for Data Science (workflow and plotting tips)."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#goals-and-outcomes",
    "href": "PART1_Experimental_Design_Outline.html#goals-and-outcomes",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Build intuition for design-first thinking before connecting to regression.\nMake fixed vs random factor decisions explicit and justified.\nInterpret variance components (one-way random effects) and compute ICC.\nCommunicate results with effect sizes (for FE) or variance components/ICC (for RE) and clear assumptions checks."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#entry-strategy",
    "href": "PART1_Experimental_Design_Outline.html#entry-strategy",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Lead with one-way ANOVA as the design-to-model path; only later show it as a linear model special case.\nAnchor with two concrete contexts:\n\nFixed levels: drug A/B/C (treatment differences are the target).\nRandom levels: nurses/labs/machines (levels sampled from a population; variability is the target)."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#fixed-vs-random-decision-aids",
    "href": "PART1_Experimental_Design_Outline.html#fixed-vs-random-decision-aids",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Three-question test:\n\nAre the levels the only ones of interest (fixed) or a sample from a broader population (random)?\nIs the estimand level-specific contrasts (fixed) or variance components/ICC (random)?\nWould adding new levels change the scientific claim (random) or be out of scope (fixed)?\n\nScope-of-inference ladder:\n\nFixed: statements about these specific levels; emphasize contrasts and emmeans.\nRandom: statements about between-level variability and reliability; emphasize variance components and ICC.\n\nEstimand spotlight for every example: clearly state “what is estimated” and “how reported”."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#week-1-plan-one-way-fe-and-re",
    "href": "PART1_Experimental_Design_Outline.html#week-1-plan-one-way-fe-and-re",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Part A — One-way FE ANOVA\n\nCoding schemes: treatment vs effects; show model.matrix(); map coefficients to group means.\nEstimated marginal means and pairwise comparisons (Tukey recommended).\nEffect sizes: eta-squared and omega-squared; add a short reporting template.\nAssumptions: residual vs fitted, QQ; Levene test; Welch ANOVA fallback.\n\nPart B — One-way RE model\n\nVariance components (between vs residual); ICC calculation and interpretation.\nEmphasize that the estimand is the variance structure, not pairwise mean differences.\nNote on p-values in lme4 and when to bring in lmerTest.\n\nPart C — Side-by-side comparison\n\nFit FE and RE to the same dataset; compare targets of inference and reporting outputs.\nMicro-simulation: increase between-level variance to show ICC growth and motivation for RE.\n\nDeliverable (Week 1)\n\nChoose FE or RE for a given vignette and justify in 3–5 sentences.\nFE: report ANOVA, effect sizes, emmeans with multiplicity control, and a brief assumptions note.\nRE: report variance components and ICC with interpretation, plus diagnostics note."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#week-2-plan-blocking-and-mixed-models",
    "href": "PART1_Experimental_Design_Outline.html#week-2-plan-blocking-and-mixed-models",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "CRD vs RB variance story (visual): show how blocking reduces within-block error; link to precision.\nFixed vs random blocks:\n\nFixed if blocks are the specific conditions of interest; random if blocks represent sampled nuisance heterogeneity.\n\nReplicated RB and interactions:\n\nRandom Treatment×Block interaction; LRT under REML with refit = FALSE; plain-English interpretation of the LRT.\n\nUnbalanced/missing cells:\n\nShow why mixed models are more robust than two-way ANOVA in practice.\n\nDeliverable (Week 2)\n\nFit two-way ANOVA (blocks fixed) and mixed model (1 | block); pick a final model with rationale.\nQuantify variance reduction (e.g., ICC or variance components) and report treatment comparisons with multiplicity control."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#in-class-activities-1015-minutes",
    "href": "PART1_Experimental_Design_Outline.html#in-class-activities-1015-minutes",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Coding swap: effects vs treatment; compute emmeans; interpret one coefficient in plain English.\nFE vs RE hot seat: 6 short vignettes; students vote and justify fixed/random.\nTiny sim: CRD vs RB precision under varying block variance; discuss when blocking pays off.\nVariance table interpretation: given between and residual variances, compute ICC and write a one-sentence claim."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#lab-changes-to-implement",
    "href": "PART1_Experimental_Design_Outline.html#lab-changes-to-implement",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Lab 1 (FE one-way)\n\nDefault eval = TRUE; add model.matrix() demo; add emmeans with Tukey; add Levene/Welch.\nAdd effect sizes (eta^2, omega^2) and a reporting template.\n\nLab 2 (RE one-way)\n\nAdd explicit variance components table; ICC calculation; residual and QQ plots with a short rubric.\n\nLab 3 (Randomized block)\n\nCompare two-way ANOVA (blocks fixed) vs mixed (1 | block); discuss equivalence/df differences.\nUse emmeans for treatment comparisons; compute ICC for blocks.\n\nLab 4 (Replicated RB)\n\nInclude random Treatment×Block interaction; LRT under REML with refit = FALSE; guidance on model choice."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#assessment-and-rubric-notes",
    "href": "PART1_Experimental_Design_Outline.html#assessment-and-rubric-notes",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Week 1\n\nFE path: effect sizes present; contrasts correctly interpreted; assumptions addressed.\nRE path: variance components and ICC correctly reported; interpretation targets variability, not pairwise means.\n\nWeek 2\n\nClear justification of fixed vs random blocks; correct use of LRT for interaction (if replicated design); multiplicity control for treatment effects."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#common-pitfalls-and-guardrails",
    "href": "PART1_Experimental_Design_Outline.html#common-pitfalls-and-guardrails",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Too few levels (&lt;= 3) for random effects: warn about unstable variance estimates; consider fixed effects.\nSingular fits: what they mean and how to communicate.\nDo not treat subject/cluster IDs as fixed (except pedagogically); they are typically random.\nTwo-way ANOVA with missing cells: highlight limitations; prefer mixed models."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#slide-hooks-and-visuals",
    "href": "PART1_Experimental_Design_Outline.html#slide-hooks-and-visuals",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Pipeline figure: raw means → coding → coefficients → emmeans.\nVariance bar chart: CRD vs RB error components.\nSide-by-side outputs: two-way ANOVA vs mixed model; highlight df and inference targets.\n“Estimand card” on each example: what, scale, and how reported."
  },
  {
    "objectID": "PART1_Experimental_Design_Outline.html#resources-and-readings",
    "href": "PART1_Experimental_Design_Outline.html#resources-and-readings",
    "title": "Part 1: Experimental Design — Teaching Outline",
    "section": "",
    "text": "Oehlert (design & ANOVA), selected chapters.\nRoback & Legler (mixed models context), selected sections.\nR for Data Science (workflow and plotting tips)."
  },
  {
    "objectID": "COURSE_DESIGN.html",
    "href": "COURSE_DESIGN.html",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Linear regression is powerful for modeling continuous outcomes, but its assumptions (independent, identically distributed errors) often fail in real medical and public health settings. This course introduces linear mixed-effects models and related methods for clustered, hierarchical, and longitudinal data, and then extends beyond Gaussian outcomes to generalized linear models. Over five weeks, we progress from experimental design and ANOVA to multilevel modeling, longitudinal (growth curve) analysis, and GLMs for counts and binaries. Emphasis is on practical modeling decisions, clear interpretation, reproducibility with R and Quarto, and transparent reporting.\n\n\n\nBy the end of the course, students will be able to: - Apply linear mixed-effects models across medical research contexts, including randomized block designs, within-subject designs, multilevel data, and repeated measurements. - Apply generalized linear models (and where appropriate, mixed GLMs) to analyze clustered binary and count data; diagnose overdispersion and select appropriate alternatives. - Create reproducible reports in Quarto that document analysis, diagnostics, and interpretation clearly and concisely.\n\n\n\nThis document outlines the course structure for BLR and specifies learning objectives for the four core modules: Experimental Design, Multilevel Data, Longitudinal Measurements, and Beyond Continuous Outcomes.\n\n\n\n\nDuration: 5 teaching weeks (4 modules + integrative GLM week)\nModality per week:\n\nPre‑class: collaborative reading (Perusall) + short concept checks\nIn‑class: interactive lecture (30–40m) + guided R lab (60–70m) + wrap‑up (10–15m)\nPost‑class: lab assignment (rendered .html + .qmd) + brief reflection\n\nDeliverables: weekly pass/fail; graded students submit a final portfolio\nTools: R, Quarto (.qmd), tidyverse, lme4/lmerTest, emmeans, plus topic‑specific packages\n\n\n\n\n\nWeek 1 — Experimental Design I: One‑Way Fixed/Random Effects, ANOVA\n\nLabs: BLR_lab_FE_oneway.qmd, BLR_lab_RE_oneway.qmd\nSlides: Lectures_2425/BLR Week 1.pdf\n\nWeek 2 — Experimental Design II: (Replicated) Randomized Block, Two‑Way ANOVA, Mixed vs Fixed Blocks\n\nLabs: BLR_lab_randomized_block.qmd, BLR_lab_replicated_randomized_block.qmd\nSlides: Lectures_2425/BLR Week 2.pdf\n\nWeek 3 — Multilevel Data in Epidemiology/Public Health\n\nLab: BLR_lab_MLA.qmd\nSlides: Lectures_2425/BLR Week 3.pdf\n\nWeek 4 — Longitudinal Measurements (Growth Curve Models)\n\nLab: BLR_lab_longitudinal.qmd\nSlides: Lectures_2425/BLR Week 4.pdf\n\nWeek 5 — Beyond Continuous Outcomes (GLMs: Poisson/Logistic; model fit)\n\nLab: BLR_lab_Poisson.qmd (+ optional logistic extension)\nSlides: Lectures_2425/Lecture week 5.pdf\n\n\n\n\n\n\n\nStudents will be able to: - Formulate and analyze one‑factor experiments using fixed‑effects ANOVA; connect coding schemes (treatment vs effects) to group means and model coefficients. - Decide and justify when a factor is modeled as fixed vs random; interpret variance components in a one‑way random‑effects model. - Use estimated marginal means and multiplicity‑adjusted pairwise comparisons; report effect sizes (η²/ω²) with clear interpretation. - Diagnose assumptions (normality, homoscedasticity); apply remedies/alternatives (Levene/Welch, transformation when appropriate). - Explain and quantify the precision/power implications of design choices at a high level.\nAssociated materials: - Labs: BLR_lab_FE_oneway.qmd, BLR_lab_RE_oneway.qmd, BLR_lab_randomized_block.qmd, BLR_lab_replicated_randomized_block.qmd - Slides: Weeks 1–2\n\n\n\nStudents will be able to: - Explain hierarchical data structures (subjects within contexts; cluster randomization) and quantify clustering via ICC. - Fit and interpret random‑intercept models; add level‑1 and level‑2 covariates; center continuous predictors and interpret the intercept. - Assess cross‑level interactions; describe how adding covariates affects within‑ vs between‑cluster variance components. - Compare ANOVA/mixed approaches conceptually; justify modeling choices under imbalance/missingness.\nAssociated materials: - Lab: BLR_lab_MLA.qmd - Slides: Week 3\n\n\n\nStudents will be able to: - Frame longitudinal data as multilevel (measurement occasions nested in individuals) and specify growth‑curve models. - Compare random‑intercept vs random‑slope models; select random‑effects structure using LRTs under REML (no refit), then finalize fixed effects under ML. - Interpret subject‑specific (mixed) effects vs population‑average trends; produce and read diagnostic plots. - Discuss practical issues (missingness patterns; zero‑inflation caveat where relevant) and implications for inference.\nAssociated materials: - Lab: BLR_lab_longitudinal.qmd - Slides: Week 4\n\n\n\nStudents will be able to: - Select appropriate GLM families/links (Poisson/logistic) and interpret coefficients on the link scale. - Diagnose overdispersion; apply offsets; discuss when to consider negative binomial or zero‑inflated models. - Evaluate goodness‑of‑fit (Pearson residuals/chi‑square) and communicate model adequacy. - Extend the mixed‑model mindset to non‑Gaussian outcomes conceptually (awareness level if time constrained).\nAssociated materials: - Lab: BLR_lab_Poisson.qmd (counts); optional logistic extension - Slides: Week 5\n\n\n\n\n\nWeekly assignments (pass/fail): renderable .qmd/.html, core analyses completed, brief reflection (2–4 sentences on assumptions/limitations).\nPortfolio (graded students):\n\nContents: all weekly assignments (qmd + html) + one individual dataset analysis.\nCriteria: correctness of analysis/code, interpretation accuracy, quality of the rendered output (layout/format/presentation), and clarity of justifications.\nSubmission: by posted deadline (see slide deck Week 5).\n\n\n\n\n\n\nPre‑class Perusall reading with 3–5 targeted concept checks per week.\nRecommended references: Roback & Legler, Beyond Multiple Linear Regression (for Labs 5+); course slide notes for design modules.\n\n\n\n\n\nOehlert GW. A First Course in Design and Analysis of Experiments. http://users.stat.umn.edu/~gary/Book.html\nLeyland AH, Groenewegen PP. Multilevel Modelling for Public Health and Health Services Research. https://link.springer.com/book/10.1007/978-3-030-34801-4\nRoback P, Legler J. Beyond Multiple Linear Regression. https://bookdown.org/roback/bookdown-BeyondMLR/\nWickham H, Cetinkaya-Rundel M, and Grolemund G. R for Data Science (2nd ed.). https://r4ds.hadley.nz/\n\n\n\n\n\nIntroductory statistics and comfort with R.\nRecommended: Chapters 1–8 (“The Whole Game”) of R for Data Science before the course.\n\n\n\n\n\nCertificate: complete pre-class readings, participate in at least 80% of in-class activities, and submit all weekly assignments.\nGraded students (e.g., RM or Epidemiologist B): portfolio graded at end of course, consisting of all weekly assignments (qmd + HTML) plus one individual dataset analysis; rubric on Brightspace.\n\n\n\n\n\n3 EC\n\n\n\n\n\nDouwe Postmus\n\n\n\n\n\nDefault chunk options: warning: false, message: false, eval: true (override per chunk as needed).\nReproducible paths: keep datasets under data/; use project root consistently.\nContrasts: set explicitly when needed, e.g., options(contrasts = c(\"contr.sum\", \"contr.poly\")) for effects coding.\nReporting: always include model specification, key estimates with uncertainty, diagnostics summary, and practical interpretation.\n\n\n\n\n\nAdd side‑by‑side coding illustration (model.matrix) and link to emmeans.\nInclude effect sizes (η²/ω²) and Tukey pairwise comparisons in Lab 1.\nAdd Levene’s/Welch’s checks and a lightweight power illustration for ANOVA.\nFor blocks: compare two‑way ANOVA (block fixed) vs mixed (1|block); quantify ICC; small simulation showing precision gains under blocking.\n\n\n\n\n\nExperimental Design: Labs 1–4 (simulated data)\nMultilevel: Lab 5 — data/airbnb.csv\nLongitudinal: Lab 6 — data/alcoholpp.sav\nBeyond Continuous: Lab 7 — data/asthma_data.csv\n\n\n\n\n\nWeek −1: publish syllabus, datasets in data/, and lab templates\nWeek 1–2: emphasize design decisions, coding schemes, and mixed vs fixed\nWeek 3: multilevel fundamentals and variance components\nWeek 4: random slopes and model‑building workflow (REML/ML)\nWeek 5: GLMs; fit/diagnose Poisson; optional logistic extension\nFinal week: portfolio due; optional office hour clinic\n\n\n\n\n\nProvide code‑light summaries and interpretation guides.\nMaintain consistent figure themes and readable defaults.\nOffer brief “Quarto/R tips” each week and a troubleshooting FAQ."
  },
  {
    "objectID": "COURSE_DESIGN.html#course-description",
    "href": "COURSE_DESIGN.html#course-description",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Linear regression is powerful for modeling continuous outcomes, but its assumptions (independent, identically distributed errors) often fail in real medical and public health settings. This course introduces linear mixed-effects models and related methods for clustered, hierarchical, and longitudinal data, and then extends beyond Gaussian outcomes to generalized linear models. Over five weeks, we progress from experimental design and ANOVA to multilevel modeling, longitudinal (growth curve) analysis, and GLMs for counts and binaries. Emphasis is on practical modeling decisions, clear interpretation, reproducibility with R and Quarto, and transparent reporting."
  },
  {
    "objectID": "COURSE_DESIGN.html#global-learning-objectives",
    "href": "COURSE_DESIGN.html#global-learning-objectives",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "By the end of the course, students will be able to: - Apply linear mixed-effects models across medical research contexts, including randomized block designs, within-subject designs, multilevel data, and repeated measurements. - Apply generalized linear models (and where appropriate, mixed GLMs) to analyze clustered binary and count data; diagnose overdispersion and select appropriate alternatives. - Create reproducible reports in Quarto that document analysis, diagnostics, and interpretation clearly and concisely."
  },
  {
    "objectID": "COURSE_DESIGN.html#purpose",
    "href": "COURSE_DESIGN.html#purpose",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "This document outlines the course structure for BLR and specifies learning objectives for the four core modules: Experimental Design, Multilevel Data, Longitudinal Measurements, and Beyond Continuous Outcomes."
  },
  {
    "objectID": "COURSE_DESIGN.html#structure",
    "href": "COURSE_DESIGN.html#structure",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Duration: 5 teaching weeks (4 modules + integrative GLM week)\nModality per week:\n\nPre‑class: collaborative reading (Perusall) + short concept checks\nIn‑class: interactive lecture (30–40m) + guided R lab (60–70m) + wrap‑up (10–15m)\nPost‑class: lab assignment (rendered .html + .qmd) + brief reflection\n\nDeliverables: weekly pass/fail; graded students submit a final portfolio\nTools: R, Quarto (.qmd), tidyverse, lme4/lmerTest, emmeans, plus topic‑specific packages"
  },
  {
    "objectID": "COURSE_DESIGN.html#weekly-spine-option-a",
    "href": "COURSE_DESIGN.html#weekly-spine-option-a",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Week 1 — Experimental Design I: One‑Way Fixed/Random Effects, ANOVA\n\nLabs: BLR_lab_FE_oneway.qmd, BLR_lab_RE_oneway.qmd\nSlides: Lectures_2425/BLR Week 1.pdf\n\nWeek 2 — Experimental Design II: (Replicated) Randomized Block, Two‑Way ANOVA, Mixed vs Fixed Blocks\n\nLabs: BLR_lab_randomized_block.qmd, BLR_lab_replicated_randomized_block.qmd\nSlides: Lectures_2425/BLR Week 2.pdf\n\nWeek 3 — Multilevel Data in Epidemiology/Public Health\n\nLab: BLR_lab_MLA.qmd\nSlides: Lectures_2425/BLR Week 3.pdf\n\nWeek 4 — Longitudinal Measurements (Growth Curve Models)\n\nLab: BLR_lab_longitudinal.qmd\nSlides: Lectures_2425/BLR Week 4.pdf\n\nWeek 5 — Beyond Continuous Outcomes (GLMs: Poisson/Logistic; model fit)\n\nLab: BLR_lab_Poisson.qmd (+ optional logistic extension)\nSlides: Lectures_2425/Lecture week 5.pdf"
  },
  {
    "objectID": "COURSE_DESIGN.html#learning-objectives-by-module",
    "href": "COURSE_DESIGN.html#learning-objectives-by-module",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Students will be able to: - Formulate and analyze one‑factor experiments using fixed‑effects ANOVA; connect coding schemes (treatment vs effects) to group means and model coefficients. - Decide and justify when a factor is modeled as fixed vs random; interpret variance components in a one‑way random‑effects model. - Use estimated marginal means and multiplicity‑adjusted pairwise comparisons; report effect sizes (η²/ω²) with clear interpretation. - Diagnose assumptions (normality, homoscedasticity); apply remedies/alternatives (Levene/Welch, transformation when appropriate). - Explain and quantify the precision/power implications of design choices at a high level.\nAssociated materials: - Labs: BLR_lab_FE_oneway.qmd, BLR_lab_RE_oneway.qmd, BLR_lab_randomized_block.qmd, BLR_lab_replicated_randomized_block.qmd - Slides: Weeks 1–2\n\n\n\nStudents will be able to: - Explain hierarchical data structures (subjects within contexts; cluster randomization) and quantify clustering via ICC. - Fit and interpret random‑intercept models; add level‑1 and level‑2 covariates; center continuous predictors and interpret the intercept. - Assess cross‑level interactions; describe how adding covariates affects within‑ vs between‑cluster variance components. - Compare ANOVA/mixed approaches conceptually; justify modeling choices under imbalance/missingness.\nAssociated materials: - Lab: BLR_lab_MLA.qmd - Slides: Week 3\n\n\n\nStudents will be able to: - Frame longitudinal data as multilevel (measurement occasions nested in individuals) and specify growth‑curve models. - Compare random‑intercept vs random‑slope models; select random‑effects structure using LRTs under REML (no refit), then finalize fixed effects under ML. - Interpret subject‑specific (mixed) effects vs population‑average trends; produce and read diagnostic plots. - Discuss practical issues (missingness patterns; zero‑inflation caveat where relevant) and implications for inference.\nAssociated materials: - Lab: BLR_lab_longitudinal.qmd - Slides: Week 4\n\n\n\nStudents will be able to: - Select appropriate GLM families/links (Poisson/logistic) and interpret coefficients on the link scale. - Diagnose overdispersion; apply offsets; discuss when to consider negative binomial or zero‑inflated models. - Evaluate goodness‑of‑fit (Pearson residuals/chi‑square) and communicate model adequacy. - Extend the mixed‑model mindset to non‑Gaussian outcomes conceptually (awareness level if time constrained).\nAssociated materials: - Lab: BLR_lab_Poisson.qmd (counts); optional logistic extension - Slides: Week 5"
  },
  {
    "objectID": "COURSE_DESIGN.html#assessments-and-grading",
    "href": "COURSE_DESIGN.html#assessments-and-grading",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Weekly assignments (pass/fail): renderable .qmd/.html, core analyses completed, brief reflection (2–4 sentences on assumptions/limitations).\nPortfolio (graded students):\n\nContents: all weekly assignments (qmd + html) + one individual dataset analysis.\nCriteria: correctness of analysis/code, interpretation accuracy, quality of the rendered output (layout/format/presentation), and clarity of justifications.\nSubmission: by posted deadline (see slide deck Week 5)."
  },
  {
    "objectID": "COURSE_DESIGN.html#readings-and-preparation",
    "href": "COURSE_DESIGN.html#readings-and-preparation",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Pre‑class Perusall reading with 3–5 targeted concept checks per week.\nRecommended references: Roback & Legler, Beyond Multiple Linear Regression (for Labs 5+); course slide notes for design modules."
  },
  {
    "objectID": "COURSE_DESIGN.html#textbooks-freely-available-online",
    "href": "COURSE_DESIGN.html#textbooks-freely-available-online",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Oehlert GW. A First Course in Design and Analysis of Experiments. http://users.stat.umn.edu/~gary/Book.html\nLeyland AH, Groenewegen PP. Multilevel Modelling for Public Health and Health Services Research. https://link.springer.com/book/10.1007/978-3-030-34801-4\nRoback P, Legler J. Beyond Multiple Linear Regression. https://bookdown.org/roback/bookdown-BeyondMLR/\nWickham H, Cetinkaya-Rundel M, and Grolemund G. R for Data Science (2nd ed.). https://r4ds.hadley.nz/"
  },
  {
    "objectID": "COURSE_DESIGN.html#prerequisites",
    "href": "COURSE_DESIGN.html#prerequisites",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Introductory statistics and comfort with R.\nRecommended: Chapters 1–8 (“The Whole Game”) of R for Data Science before the course."
  },
  {
    "objectID": "COURSE_DESIGN.html#evaluation-program-requirements",
    "href": "COURSE_DESIGN.html#evaluation-program-requirements",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Certificate: complete pre-class readings, participate in at least 80% of in-class activities, and submit all weekly assignments.\nGraded students (e.g., RM or Epidemiologist B): portfolio graded at end of course, consisting of all weekly assignments (qmd + HTML) plus one individual dataset analysis; rubric on Brightspace."
  },
  {
    "objectID": "COURSE_DESIGN.html#credits",
    "href": "COURSE_DESIGN.html#credits",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "3 EC"
  },
  {
    "objectID": "COURSE_DESIGN.html#course-coordinator",
    "href": "COURSE_DESIGN.html#course-coordinator",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Douwe Postmus"
  },
  {
    "objectID": "COURSE_DESIGN.html#rquarto-workflow-standards",
    "href": "COURSE_DESIGN.html#rquarto-workflow-standards",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Default chunk options: warning: false, message: false, eval: true (override per chunk as needed).\nReproducible paths: keep datasets under data/; use project root consistently.\nContrasts: set explicitly when needed, e.g., options(contrasts = c(\"contr.sum\", \"contr.poly\")) for effects coding.\nReporting: always include model specification, key estimates with uncertainty, diagnostics summary, and practical interpretation."
  },
  {
    "objectID": "COURSE_DESIGN.html#suggested-improvements-weeks-12-priorities",
    "href": "COURSE_DESIGN.html#suggested-improvements-weeks-12-priorities",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Add side‑by‑side coding illustration (model.matrix) and link to emmeans.\nInclude effect sizes (η²/ω²) and Tukey pairwise comparisons in Lab 1.\nAdd Levene’s/Welch’s checks and a lightweight power illustration for ANOVA.\nFor blocks: compare two‑way ANOVA (block fixed) vs mixed (1|block); quantify ICC; small simulation showing precision gains under blocking."
  },
  {
    "objectID": "COURSE_DESIGN.html#data-and-labs-mapping",
    "href": "COURSE_DESIGN.html#data-and-labs-mapping",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Experimental Design: Labs 1–4 (simulated data)\nMultilevel: Lab 5 — data/airbnb.csv\nLongitudinal: Lab 6 — data/alcoholpp.sav\nBeyond Continuous: Lab 7 — data/asthma_data.csv"
  },
  {
    "objectID": "COURSE_DESIGN.html#milestones-and-timeline",
    "href": "COURSE_DESIGN.html#milestones-and-timeline",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Week −1: publish syllabus, datasets in data/, and lab templates\nWeek 1–2: emphasize design decisions, coding schemes, and mixed vs fixed\nWeek 3: multilevel fundamentals and variance components\nWeek 4: random slopes and model‑building workflow (REML/ML)\nWeek 5: GLMs; fit/diagnose Poisson; optional logistic extension\nFinal week: portfolio due; optional office hour clinic"
  },
  {
    "objectID": "COURSE_DESIGN.html#accessibility-and-support",
    "href": "COURSE_DESIGN.html#accessibility-and-support",
    "title": "Beyond Multiple Linear Regression (BLR) — Course Design (2024–2025)",
    "section": "",
    "text": "Provide code‑light summaries and interpretation guides.\nMaintain consistent figure themes and readable defaults.\nOffer brief “Quarto/R tips” each week and a troubleshooting FAQ."
  }
]