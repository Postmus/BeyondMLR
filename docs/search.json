[
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html",
    "href": "Assignments/Week 5/Assignment_week_5.html",
    "title": "Assignment Week 5",
    "section": "",
    "text": "In this assignment, you will analyze multilevel data to describe the development of students’ English and Mathematics test scores over time. The data come from the Junior School Project (Mortimore et al.), which examines factors influencing academic progress in junior schools. There are over 1000 students measured over three school years with 3236 records included in this dataset.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#introduction",
    "href": "Assignments/Week 5/Assignment_week_5.html#introduction",
    "title": "Assignment Week 5",
    "section": "",
    "text": "In this assignment, you will analyze multilevel data to describe the development of students’ English and Mathematics test scores over time. The data come from the Junior School Project (Mortimore et al.), which examines factors influencing academic progress in junior schools. There are over 1000 students measured over three school years with 3236 records included in this dataset.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#dataset-description",
    "href": "Assignments/Week 5/Assignment_week_5.html#dataset-description",
    "title": "Assignment Week 5",
    "section": "Dataset description",
    "text": "Dataset description\nThe dataset consists of the following variables:\n\nSchool: School ID.\nStudent.ID: Student ID.\nGender: A categorical variable representing the gender of the student\nJunior.school.year: Year of the study (0, 1, or 2).\nEnglish.test: English test score in year 1.\nMathematics.test: Mathematics test score in year 1.\n\nThe dataset can be downloaded from the link provided in the Downloads section below. When reading the dataset into R, ensure that the Gender variable is correctly encoded as a factor."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#objectives",
    "href": "Assignments/Week 5/Assignment_week_5.html#objectives",
    "title": "Assignment Week 5",
    "section": "Objectives",
    "text": "Objectives\nYour objectives are to:\n\nDevelop an appropriate model to describe the development of students’ English test scores over time\n\nInclude random intercepts to account for the nesting of longitudinal measurements within students and the subsequent nesting of students within schools\nExplore systematic differences in the mean “growth curves” of English test scores over time between boys and girls\nConsider interaction terms such as Gender * Junior.school.year to explore gender-specific trends\n\nDevelop an appropriate model to describe the development of students’ Mathematics test scores over time\n\nInclude random intercepts to account for the nesting of longitudinal measurements within students and the subsequent nesting of students within schools\nExplore systematic differences in the mean “growth curves” of Mathematics test scores over time between boys and girls\nConsider interaction terms such as Gender * Junior.school.year to explore gender-specific trends"
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#requirements-for-the-report",
    "href": "Assignments/Week 5/Assignment_week_5.html#requirements-for-the-report",
    "title": "Assignment Week 5",
    "section": "Requirements for the report",
    "text": "Requirements for the report\nYour report should clearly explain:\n\nThe reasoning behind your choice of model structure, supported by the results of the exploratory data analysis\nThe interpretation of key model parameters in the context of the research questions\nAny limitations or assumptions affecting your analysis\n\nSubmit both the Quarto source file (.qmd) and the rendered HTML file.\n\n\n\n\n\n\nTip\n\n\n\nThe time variable Junior.school.year is represented as a continuous variable in the dataset. However, you may transform it into a categorical variable in your analysis if you find it more appropriate. For example, you could treat it as a factor with three levels (0, 1, and 2) to represent the three years of the study. This transformation may help you interpret the results more easily.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhile conceptually it is possible to also include a random slope for the time variable in your models, you are not required to do so for this assignment (depending on the coding of the time variable, there are either not sufficient degrees of freedom to fit this model or you may run into convergence/boundary fit issues. You may therefore focus on random intercepts to keep the analysis manageable."
  },
  {
    "objectID": "Assignments/Week 5/Assignment_week_5.html#downloads",
    "href": "Assignments/Week 5/Assignment_week_5.html#downloads",
    "title": "Assignment Week 5",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html",
    "href": "Assignments/Week 3/Assignment_week_3.html",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "",
    "text": "In this assignment, you will analyze a dataset collected by the Inner London Education Authority (ILEA) to examine the effectiveness of schools. The dataset consists of examination records of 15,362 students from 140 secondary schools over the years 1985, 1986, and 1987. This dataset was sourced from the data library of the Centre for Multilevel Modelling at the University of Bristol."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#introduction",
    "href": "Assignments/Week 3/Assignment_week_3.html#introduction",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "",
    "text": "In this assignment, you will analyze a dataset collected by the Inner London Education Authority (ILEA) to examine the effectiveness of schools. The dataset consists of examination records of 15,362 students from 140 secondary schools over the years 1985, 1986, and 1987. This dataset was sourced from the data library of the Centre for Multilevel Modelling at the University of Bristol."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#dataset-description",
    "href": "Assignments/Week 3/Assignment_week_3.html#dataset-description",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Dataset Description",
    "text": "Dataset Description\nThe dataset consists of the following variables:\n\nSchool: A numeric variable representing the school identifier (codes 1 to 139)\nExamScore: A numeric variable representing the exam score of each student\nPercentFSM: The percentage of students in the school eligible for free school meals (an indicator of socioeconomic status)\nGender: A categorical variable representing the gender of the student\nVRBand: The verbal reasoning band of the student (VR1, VR2, or VR3). VR band is an indicator of the student’s assessed ability level, with VR1 typically representing the highest ability group, VR2 representing intermediate ability, and VR3 representing lower ability.\nSchoolDenomination: The denomination of the school (Maintained, Church of England, Roman Catholic)"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#objective",
    "href": "Assignments/Week 3/Assignment_week_3.html#objective",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Objective",
    "text": "Objective\nYour goals are to determine:\n\nHow much of the variability in exam scores can be attributed to:\n\nDifferences between students\nDifferences between schools\n\nWhether individual-level factors (e.g., Gender, VRBand) significantly influence student exam scores\nWhether school-level factors (e.g., PercentFSM) significantly influence student exam scores"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 3/Assignment_week_3.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Steps to Complete the Analysis",
    "text": "Steps to Complete the Analysis\n\nLoad the Dataset\nDownload the dataset (see link in the Downloads section below) and read it into R. Make sure all character variables are correctly encoded as factors.\n\n\n\n\n\n\nTipHint\n\n\n\nWhen loading the data, convert the School variable to a factor. This will make it easier to use reorder() in ggplot2 when creating visualizations that order schools by their mean exam scores.\n\n# Load the data\nilea_data &lt;- read.csv(\"downloads/ilea_data.csv\")\n\n# Convert all character variables into factors\nilea_data &lt;- ilea_data %&gt;%\n  mutate_if(is.character, as.factor) %&gt;%\n  mutate(School = as.factor(School))\n\n\n\n\n\nExploratory Data Analysis (EDA):\n\nExplore the distribution of the outcome variable (ExamScore)\nExplore the variance components (i.e., make a plot displaying the within- and between-school variation)\nExplore the relationships between fixed effects and the outcome variable\n\n\n\nMulti-Level Modeling\n\nStart by fitting a null model (i.e., a random intercept model without any predictors) to partition the variance in exam scores between students and schools. Assess how much of the variability in exam scores is due to differences between students and schools.\nNext, add individual-level variables (Gender, VRBand) to the model to explore how these factors influence exam scores.\nAfter that, add context-level variables (e.g., PercentFSM) to your model to understand how factors at the school level contribute to differences in exam scores.\nFinally, explore potential cross-level interactions between individual-level and context-level variables.\n\n\n\nInterpret the Results\nInterpret the findings from your analysis, focusing on the variance components and the effects of individual-level and context-level variables."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#requirements-for-the-report",
    "href": "Assignments/Week 3/Assignment_week_3.html#requirements-for-the-report",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The HTML file should be rendered with code visibility enabled (echo = TRUE)."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#downloads",
    "href": "Assignments/Week 3/Assignment_week_3.html#downloads",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html",
    "href": "Assignments/Week 1/Assignment_week_1.html",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that examines the effect of different rehabilitation programs on the mobility of stroke patients. The dataset includes mobility improvement measurements taken using the 6-Minute Walk Test (6MWT), a standard assessment to evaluate physical mobility and endurance.\nPatients in the study were randomly assigned to one of three rehabilitation programs:\n\nControl: Standard physical therapy.\nRobotic-Assisted Therapy: Rehabilitation involving robotic devices designed to support movement.\nAquatic Therapy: Water-based exercises aimed at improving mobility with reduced joint stress."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#introduction",
    "href": "Assignments/Week 1/Assignment_week_1.html#introduction",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that examines the effect of different rehabilitation programs on the mobility of stroke patients. The dataset includes mobility improvement measurements taken using the 6-Minute Walk Test (6MWT), a standard assessment to evaluate physical mobility and endurance.\nPatients in the study were randomly assigned to one of three rehabilitation programs:\n\nControl: Standard physical therapy.\nRobotic-Assisted Therapy: Rehabilitation involving robotic devices designed to support movement.\nAquatic Therapy: Water-based exercises aimed at improving mobility with reduced joint stress."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#objective",
    "href": "Assignments/Week 1/Assignment_week_1.html#objective",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Objective",
    "text": "Objective\nYour objective is to determine whether there is a statistically significant difference in mobility improvement among the three rehabilitation groups. To complete this analysis, follow these steps:\n\nExplore the Data: Perform an exploratory data analysis (EDA) to understand the distribution of mobility improvements across treatment groups.\nFit a One-Way ANOVA Model: Fit a one-way ANOVA model to test for overall group differences.\nPost-Hoc Comparisons: If you identify significant group differences, calculate estimated marginal means and conduct post-hoc comparisons to determine which groups differ.\nModel Diagnostics: Conduct diagnostic tests and visualizations to evaluate model assumptions, including homoscedasticity and normality of residuals."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#requirements-for-the-report",
    "href": "Assignments/Week 1/Assignment_week_1.html#requirements-for-the-report",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The quarto source file should include all R code and annotations, and the html file should be rendered with code visibility enabled (echo: true, which is the default setting used in the template). The Quarto file in the downloads section below provides a template that you can use for this assignment."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#downloads",
    "href": "Assignments/Week 1/Assignment_week_1.html#downloads",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Downloads",
    "text": "Downloads\n\nDownload dataset\nDownload Quarto Template"
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html",
    "href": "BLR_lab_replicated_randomized_block.html",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "",
    "text": "NotePreliminary setup\n\n\n\nIn this lab, we will use the R packages ggplot2, dplyr, emmeans, lmerTest, and broom.mixed. You can use the script below to automatically install and load them using the pacman package.\n\n# Check whether pacman is available and install if needed\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\n# Use pacman to install (if needed) and load the required packages\npacman::p_load(dplyr, ggplot2, emmeans, lmerTest, broom.mixed)\nIn last week’s lab, we considered a traditional randomized block design without replication, where each treatment was applied once within each block (laboratory). This design allowed us to control for variability between laboratories and efficiently estimate the effect of treatment. However, a key limitation of this approach is that it does not allow us to assess the extent to which the effect of treatment varies across blocks, a concept known as interaction.\nAn interaction occurs when the effect of one factor (e.g., treatment) is not consistent across levels of another factor (e.g., laboratory). In other words, the effect of a treatment might vary depending on the laboratory conditions. Replicating the treatments within each block allows us to estimate these interaction effects and better understand the variability in treatment outcomes across different settings.\nIn this lab, we extend the randomized block design by adding replication within blocks, so we can estimate the variability within each block and assess the extent to which treatment effects vary across blocks."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo explore the data and investigate the presence of a potential interaction between treatments and laboratories, we create an interaction plot:\n\n# Create an interaction plot\nggplot(data_rep_block, aes(x = Treatment, y = WoundHealing, \n  group = Laboratory, color = Laboratory)) +\n    stat_summary(fun = mean, geom = \"point\", size = 3) +\n    stat_summary(fun = mean, geom = \"line\") +\n    labs(title = \"Interaction Plot\",\n         y = \"Mean Wound Healing Measure\",\n         x = \"Treatment\") +\n    theme_minimal()\n\nIn addition to the interaction plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_rep_block |&gt;\n  group_by(Treatment) |&gt;\n  summarise(\n    n = n(),\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing),\n    .groups = \"drop\"\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_rep_block |&gt;\n  group_by(Laboratory) |&gt;\n  summarise(\n    n = n(),\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing),\n    .groups = \"drop\"\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\nsummary_stats_laboratory\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nDoes the interaction plot indicate a potential interaction between treatment and laboratory?\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nDoes the plot suggest any differences in the overall effectiveness of the treatments (i.e., main effect of treatment) across all laboratories?\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhat does the plot suggest about variability between laboratories? Are some laboratories consistently higher or lower in wound healing across all treatments?"
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-replicated-randomized-block-design",
    "href": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-replicated-randomized-block-design",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "A Mixed Effects Model for the Replicated Randomized Block Design",
    "text": "A Mixed Effects Model for the Replicated Randomized Block Design\nAs in the previous lab, laboratory is included as a random effect and treatment as a fixed effect in the model. The key new feature is the treatment-by-laboratory interaction term, which is also modeled as a random effect.\nTo understand why the interaction term must also be modeled as random, we need to consider the nature of random effects in this context. Since laboratory is treated as a random effect, we are assuming that the laboratories in the experiment represent a random sample from a larger population of possible laboratory conditions. This means that we are not just interested in the specific laboratories in the study, but in how the treatments would perform across any set of laboratories with varying conditions.\nWhen we include an interaction term between treatment and laboratory, we are asking whether the effect of each treatment depends on the laboratory environment. If we had modeled laboratory as a fixed effect (i.e., we were only interested in those specific laboratories), the interaction could also be treated as fixed. However, because laboratory is random, the interaction must also be treated as random to reflect the idea that the variability in treatment effects across laboratories applies not just to the specific laboratories in the study, but to any laboratory from the broader population.\n\nModel Specification\nThe mixed-effects model for the replicated randomized block design is specified as:\n\\[\nY_{ijk} = \\mu + \\tau_i + b_j + (tb)_{ij} + \\epsilon_{ijk}\n\\]\nwhere:\n\n\\(Y_{ijk}\\): Response (wound healing) for the \\(k\\)-tjh replicate of Treatment \\(i\\) in Laboratory \\(j\\).\n\\(\\mu\\): Overall mean response\n\\(\\tau_{i}\\): Fixed effect of Treatment \\(i\\).\n\\(b_{j}\\):Random effect of Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{b}\\).\n\\((tb)_{ij}\\): Random interaction effect between treatment \\(i\\) and Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{tb}\\).\n\\(\\epsilon_{ijk}\\): Residual error term, assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2\\).\n\n\n\nModel Estimation\nSimilar as in the previous lab, we fit the mixed effects model using the lmer() function from the lmeTest package:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + \n  (1 | Treatment:Laboratory), data = data_rep_block)\nsummary(model_block)\n\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory):\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments.\n(1 | Laboratory): This specifies the random effect for laboratory, representing laboratory-specific deviations from the overall mean.\n(1 | Treatment:Laboratory): This specifies the random interaction term between Treatment and Laboratory.\n\n\n\nUnderstanding the model output\nWhen we run summary(model_block), the output provides two main components: fixed effects and variance components. Together, these summarize the estimated treatment differences and the variability captured by the random effects.\n\nFixed effects\n\nThe intercept represents the overall mean wound-healing measure across all treatments and laboratories (estimated as 56.47)\n\nThe coefficients for Treatment A (-1.04) and Treatment B (+1.03) indicate how each treatment’s mean differs from the overall mean\n\nWith effects coding, the coefficients must sum to zero, so the mean for Treatment C is slightly below the overall mean (≈ -0.01)\n\nThese coefficients represent the average treatment effects across all laboratories, after adjusting for differences in baseline wound-healing levels between laboratories.\n\n\nVariance components\nThe model includes two random terms that capture distinct sources of variability:\n\nThe laboratory-level random intercept (variance = 1.446) represents systematic differences in average wound healing between laboratories\n\nThe treatment-by-laboratory interaction (variance = 0.475) captures how treatment effects vary across laboratories\n\nThe residual variance (0.909) represents unexplained variability within each treatment–laboratory combination\n\n\n\n\nAssessing the fixed effect of Wound healing treatment\nThe fixed effect of wound healing treatment can be assessed by examining the ANOVA table from the mixed-effects model. This shows whether the average wound-healing differs significantly across treatments, after accounting for variability between laboratories and treatment–laboratory interactions.\n\n# Extract the ANOVA table\nanova(model_block)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nInspect the ANOVA table and report whether the overall treatment effect is statistically significant.\n\n\n\n\n\n\n\n\nImportantExercise\n\n\n\nUse the emmeans package to perform pairwise comparisons between treatments and explore which pairs differ.\n\n\n\n\nAssessing the variance components\nThe variance components can be assessed using the intra-class correlation coefficient (ICC), which expresses how much of the total unexplained variance arises from each random effect:\n\n# Extract variance components from the fitted model and\n# square the standard deviations to obtain variances\nvc &lt;- tidy(model_block, effects = \"ran_pars\") |&gt;\n  mutate(variance = estimate^2)\nvc\n\n# Compute ICCs from the variance components\nvar_total &lt;- sum(vc$variance)\nicc_lab &lt;- vc$variance[vc$group == \"Laboratory\"] / var_total\nicc_int &lt;- vc$variance[vc$group == \"Treatment:Laboratory\"] / var_total\nicc_lab\nicc_int\n\nExplanation: The tidy() function from the broom.mixed package takes complex model output and organizes it into a standardized tidy data frame, where each row corresponds to one model parameter (e.g., fixed effect, random-effect variance, residual variance). Here, we use it to extract the random-effect variance components from the fitted model object (argument effects = \"ran_pars\")\n\nThe laboratory ICC quantifies how strongly wound-healing outcomes are correlated within the same laboratory, reflecting baseline differences between labs\nThe interaction ICC quantifies the proportion of total variability attributable to differences in treatment effects across laboratories\n\nThe larger these ICCs, the greater the divergence between a mixed-effects model and an OLS analysis that ignores the grouping structure.\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow large is the ICC for the laboratory effect? What does this tell us about differences in baseline wound-healing across labs?\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow large is the ICC for the treatment-by-laboratory interaction? Does this suggest that treatment effects vary meaningfully across laboratories, or are they relatively consistent?\n\n\n\n\nModel diagnostics\nThe process of performing model diagnostics for the replicated randomized block design is the same as for the traditional randomized block design. Therefore, we refer to the previous lab for detailed instructions on assessing model assumptions and performing diagnostic checks."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#exploring-the-impact-of-omitting-the-random-interaction-term-from-the-mixed-effects-model",
    "href": "BLR_lab_replicated_randomized_block.html#exploring-the-impact-of-omitting-the-random-interaction-term-from-the-mixed-effects-model",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "Exploring the impact of omitting the random interaction term from the mixed effects model",
    "text": "Exploring the impact of omitting the random interaction term from the mixed effects model\nTo explore how the inclusion of the random treatment-by-laboratory interaction impacts inference for the fixed effect of wound healing treatment, we now fit a simpler mixed-effects model that includes only a random intercept for laboratory.\n\n# Fit the model without random interaction term\nmodel_block_simple &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_rep_block)\nsummary(model_block_simple)\n\n\n# Print the ANOVA tables for the models without (top) \n# and with (bottom) random interaction terms\nanova(model_block_simple)\nanova(model_block)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nInspect the model summaries and ANOVA tables for both models. What do you obverve?\n\n\n\nExplanation\n\nThe simpler model assumes identical treatment effects across laboratories\n\nAll differences between labs are captured by a single random intercept\nThis ignores any lab-to-lab variation in how the treatments perform\nAs a result, treatment effects appear more precise (smaller SEs and lower p-values)\n\nThe full model allows treatment effects to vary across laboratories via a random Treatment×Laboratory term\n\nEncodes that laboratories may show different treatment contrasts\nTreats treatment-by-lab heterogeneity as additional uncertainty about the common effect\nIncreases the SE and typically the p-value for the overall treatment effect because lab-specific deviations reduce the information for estimating a single average effect\n\n\nIn short, the main treatment effect represents the average across all laboratories. When only a few labs are available, allowing for random treatment-by-lab heterogeneity makes that average more uncertain. In this example, the difference is minor because the interaction ICC is low (0.167), meaning that little variability arises from treatment-by-lab heterogeneity. When the interaction ICC is larger, treatment effects become less certain (reflected in larger standard errors and higher p-values) because more of the total variability is due to differences in treatment performance across laboratories."
  },
  {
    "objectID": "BLR_lab_MLA.html",
    "href": "BLR_lab_MLA.html",
    "title": "Beyond MLR Lab 5: multi-level analysis of cross-sectional observational data",
    "section": "",
    "text": "NotePreliminary setup\n\n\n\nIn this lab, we will use the R packages ggplot2, dplyr, emmeans, lmerTest. You can use the script below to automatically install and load them using the pacman package.\n\n# Check whether pacman is available and install if needed\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\n# Use pacman to install (if needed) and load the required packages\npacman::p_load(dplyr, ggplot2, emmeans, lmerTest)"
  },
  {
    "objectID": "BLR_lab_MLA.html#exploratory-data-analysis",
    "href": "BLR_lab_MLA.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 5: multi-level analysis of cross-sectional observational data",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nLet’s load the data and use the str() function to inspect the structure of the dataset.\n\n# Load the Chicago AirBnB data. Note that the call below assumes the csv file is placed in the 'data' folder directly above the root folder of the project. Update the string as needed if the file is located elsewhere.\nchicago_airbnb &lt;- read.csv(\"data/airbnb.csv\")\n\n# Convert all character variables into factors\nchicago_airbnb &lt;- chicago_airbnb |&gt;\n  mutate_if(is.character, as.factor)\n\n# Inspect the structure of the dataset\nstr(chicago_airbnb)\n\nThis initial inspection makes clear that the Airbnb dataset has a hierarchical structure: 1,561 individual listings are nested within 43 neighborhoods. While the dataset also includes a district variable that groups neighborhoods into 9 broader districts, for educational purposes we will treat this as a two-level hierarchical structure with listings (level 1) nested within neighborhoods (level 2), ignoring the higher-level clustering of neighborhoods into districts.\n\nGrouping structure\nTo get a better feeling for the grouping structure, we create a summary table showing the number of listings within each neighborhood and visualize it with a bar chart:\n\n# Create a summary table showing listings per neighborhood\nneighborhood_summary &lt;- chicago_airbnb |&gt;\n  group_by(neighborhood) |&gt;\n  summarise(num_listings = n(), .groups = \"drop\") |&gt;\n  arrange(desc(num_listings))\n\n# Create a bar chart showing listings per neighborhood (top 20)\nneighborhood_summary |&gt;\n  top_n(20, num_listings) |&gt;\n  ggplot(aes(x = reorder(neighborhood, num_listings), y = num_listings)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  coord_flip() +\n  labs(title = \"Number of Listings per Neighborhood (Top 20)\",\n       x = \"Neighborhood\",\n       y = \"Number of Listings\") +\n  theme_minimal()\n\nExplanation:\n\ngroup_by(neighborhood): groups the data by neighborhood so that we can count listings within each neighborhood.\nn(): counts the total number of listings within each neighborhood.\narrange(desc(num_listings)): sorts the table by the number of listings in descending order.\ntop_n(20, num_listings): selects the 20 neighborhoods with the most listings for visualization.\nreorder(neighborhood, num_listings): reorders the neighborhood factor levels based on the values of num_listings, arranging neighborhoods from lowest to highest number of listings for easier interpretation.\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhich neighborhoods have the most Airbnb listings? Is there substantial variation in the number of listings across neighborhoods?\n\n\n\n\nOutcome variable\nNext, we create a histogram to visualize the distribution of the outcome variable price:\n\n# Create a histogram of price\nggplot(chicago_airbnb, aes(x = price)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribution of Listing Prices\",\n       x = \"Nightly Price (USD)\",\n       y = \"Frequency\") +\n  theme_minimal()\n\nWhile normality of the outcome is not strictly required for a mixed-effects model, transforming a right-skewed variable like price can help stabilize variance and linearize relationships. We therefore create a new variable, log_price, to store the log-transformed prices:\n\n# Log-transform the price variable\nchicago_airbnb &lt;- chicago_airbnb |&gt;\n  mutate(log_price = log(price))\n\n\n\nVariance components\nWe also want to get a sense of the variability in the listing prices within and between neighborhoods. For this, we are going to randomly select 10 neighborhoods and create a scatter plot with the log-transformed price on the y-axis and the neighborhood on the x-axis:\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Randomly select 10 unique neighborhoods\nrandom_neighborhoods &lt;- sample(unique(chicago_airbnb$neighborhood), size = 10)\n\n# Filter the data to include only the randomly selected neighborhoods\nrandom_neighborhood_data &lt;- chicago_airbnb |&gt;\n  filter(neighborhood %in% random_neighborhoods)\n\n# Calculate the average log_price for each neighborhood\nneighborhood_avg_price &lt;- random_neighborhood_data |&gt;\n  group_by(neighborhood) |&gt;\n  summarise(avg_log_price = mean(log_price, na.rm = TRUE), .groups = \"drop\")\n\n# Calculate the overall grand mean across all neighborhoods\ngrand_mean &lt;- mean(chicago_airbnb$log_price, na.rm = TRUE)\n\n# Create scatter plot with jittered observations\nggplot(random_neighborhood_data, aes(x = reorder(neighborhood, log_price, FUN = mean), y = log_price)) +\n  geom_hline(yintercept = grand_mean, linetype = \"solid\", color = \"black\", linewidth = 1) +\n  geom_jitter(alpha = 0.3, width = 0.2, size = 1, color = \"gray60\") +\n  geom_point(data = neighborhood_avg_price, aes(x = neighborhood, y = avg_log_price),\n             size = 4, shape = 18, color = \"red\") +\n  labs(title = \"Variation in listing prices: within and between neighborhoods\",\n       subtitle = \"Points = individual listings; Diamonds = neighborhood means; Solid line = grand mean (all data)\",\n       x = \"Neighborhood (ordered by mean log price)\",\n       y = \"Log-transformed price\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhat does this plot suggest about the variability in listing prices within and between neighborhoods?\n\n\n\n\nCovariate effects\nBefore fitting models with covariates, it is useful to explore the relationships between potential predictors and the outcome variable. Let us examine how some subject-level characteristics relate to listing prices.\nFirst, we will look at the relationship between the number of reviews and log-transformed price:\n\n# Scatterplot with smooth line for reviews vs log_price\nggplot(chicago_airbnb, aes(x = reviews, y = log_price)) +\n  geom_point(color = \"gray60\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"steelblue\", linewidth = 1.5) +\n  labs(title = \"Relationship between number of reviews and listing price\",\n       x = \"Number of reviews\",\n       y = \"Log-transformed price\") +\n  theme_minimal()\n\nNext, let us examine how listing prices vary across different room types:\n\n# Boxplot for room_type vs log_price\nggplot(chicago_airbnb, aes(x = room_type, y = log_price, fill = room_type)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(title = \"Listing prices by room type\",\n       x = \"Room type\",\n       y = \"Log-transformed price\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\nImportantCoding exercise\n\n\n\nCreate similar visualizations to explore the relationships between:\n\nOverall satisfaction rating and log-transformed price (scatterplot with smooth line)\nNumber of bedrooms and log-transformed price (boxplot)\n\nWhat patterns do you observe? Do higher satisfaction ratings and more bedrooms tend to be associated with higher or lower prices?"
  },
  {
    "objectID": "BLR_lab_MLA.html#random-intercept-model",
    "href": "BLR_lab_MLA.html#random-intercept-model",
    "title": "Beyond MLR Lab 5: multi-level analysis of cross-sectional observational data",
    "section": "Random intercept model",
    "text": "Random intercept model\nTo model the variability in listing prices within and between neighborhoods, we start by fitting a random intercept model to account for the nesting of listings within neighborhoods. This model is specified as follows:\n\n# Fit the random intercept model\nrandom_intercept_model &lt;- lmer(log_price ~ 1 + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of within-neighborhood and between-neighborhood variability to the total variability in listing prices?"
  },
  {
    "objectID": "BLR_lab_MLA.html#extending-the-random-intercept-model-with-subject-level-variables",
    "href": "BLR_lab_MLA.html#extending-the-random-intercept-model-with-subject-level-variables",
    "title": "Beyond MLR Lab 5: multi-level analysis of cross-sectional observational data",
    "section": "Extending the random intercept model with subject-level variables",
    "text": "Extending the random intercept model with subject-level variables\nAs a second step, we extend the random intercept model with subject-level variables. To facilitate the interpretation of the model coefficients, we start by setting the coding scheme for categorical variables to effects coding. We also center the numerical variables by subtracting the mean value from each observation. This step is important to reduce multicollinearity, improve numerical stability, and make the intercept more interpretable.\n\n# Use effects coding for the categorical variables\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\n# Center the continuous subject-level variables\nchicago_airbnb &lt;- chicago_airbnb |&gt;\n  mutate(overall_satisfaction_c = scale(overall_satisfaction, scale = FALSE),\n         accommodates_c = scale(accommodates, scale = FALSE),\n         bedrooms_c = scale(bedrooms, scale = FALSE),\n         minstay_c = scale(minstay, scale = FALSE))\n\nNext, we fit the random intercept model with the subject-level variables included:\n\n# Fit the random intercept model with subject-level variables\nrandom_intercept_model_L1variables &lt;- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_L1variables)\n\n# Display the coding scheme for the room_type variable\ncontrasts(chicago_airbnb$room_type)\n\n# Obtain the ANOVA table for the subject-level variables\nanova(random_intercept_model_L1variables)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow does centering the continuous variables affect the interpretation of the intercept?\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow does the inclusion of individual-level variables affect the estimated variance components? More specifically, does the inclusion of individual-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhich of the individual-level variables are significantly associated with listing prices? How do you interpret the coefficients for these variables?"
  },
  {
    "objectID": "BLR_lab_MLA.html#including-context-level-variables",
    "href": "BLR_lab_MLA.html#including-context-level-variables",
    "title": "Beyond MLR Lab 5: multi-level analysis of cross-sectional observational data",
    "section": "Including context-level variables",
    "text": "Including context-level variables\nAs a third step, we extend the previously fitted model with context-level variables. We start by centering the context-level variables:\n\n# Center the context-level variables\nchicago_airbnb &lt;- chicago_airbnb |&gt;\n  mutate(WalkScore_c = scale(WalkScore, scale = FALSE),\n         TransitScore_c = scale(TransitScore, scale = FALSE),\n         BikeScore_c = scale(BikeScore, scale = FALSE))\n\nNext, we fit the random intercept model with both subject-level and context-level variables included:\n\n# Fit the random intercept model with subject-level and context-level variables\nrandom_intercept_model_L1L2variables &lt;- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_L1L2variables)\n\n# Obtain the ANOVA table\nanova(random_intercept_model_L1L2variables)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow does the inclusion of context-level variables affect the estimated variance components? More specifically, does the inclusion of context-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?\n\n\n\nModel selection using stepwise elimination\nNot all the context-level variables included in the model are significant predictors of listing prices. To obtain a more parsimonious model, we can use the step() function from the lmerTest package to perform a backward elimination of the fixed-effect terms.\nThe step() function implements backward elimination in two stages:\n\nFirst stage (random effects): By default, step() first eliminates random-effect terms using likelihood ratio tests (via the ranova() function)\nSecond stage (fixed effects): Then it eliminates fixed-effect terms by repeatedly calling drop1(), which uses F-tests\n\nBackward elimination process for fixed effects:\n\nStarting with the full covariate model (after any random effects elimination), drop1() computes F-tests for all marginal fixed-effect terms (i.e., terms that can be dropped while respecting the hierarchy of terms in the model)\nstep() identifies the term with the highest (least significant) p-value from the F-tests\nIf that p-value exceeds the significance threshold (default α = 0.05 for fixed effects), the term is removed\nThe process repeats with the new reduced model until no more terms can be removed\n\nThe F-tests used by drop1() are based on Satterthwaite’s approximation for the denominator degrees of freedom, which is appropriate for mixed models.\n\n\n\n\n\n\nNoteControlling what step() eliminates\n\n\n\nThe drop1() function is specifically designed for testing fixed effects. The step() function, by default, can eliminate both random effects (using likelihood ratio tests) and fixed effects (using F-tests). However, this behavior can be controlled using the reduce.random and reduce.fixed parameters:\n\nreduce.random = TRUE (default): allows elimination of random effects\nreduce.fixed = TRUE (default): allows elimination of fixed effects\n\nIn this lab, we focus on selecting fixed effects for our random intercept model, so we will set reduce.random = FALSE to prevent any changes to the random effect structure. Testing different random effect structures (such as whether to include random slopes) will be covered in more detail in the next lab on longitudinal data analysis.\n\n\n\n# Perform stepwise selection to identify the most important predictors\n# Set reduce.random = FALSE to only eliminate fixed effects (not random effects)\nstep(random_intercept_model_L1L2variables, reduce.random = FALSE)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhich individual-level and context-level variables are retained in the final model after the stepwise selection procedure?"
  },
  {
    "objectID": "BLR_lab_MLA.html#exploring-cross-level-interactions",
    "href": "BLR_lab_MLA.html#exploring-cross-level-interactions",
    "title": "Beyond MLR Lab 5: multi-level analysis of cross-sectional observational data",
    "section": "Exploring cross-level interactions",
    "text": "Exploring cross-level interactions\nFinally, we explore the possibility of cross-level interactions between individual-level and context-level variables.\nThe relationship between the overall satisfaction rating of an individual listing and its price may depend on neighborhood characteristics such as their walkability and access to public transit. For instance, higher satisfaction ratings might have a stronger effect on prices in less walkable or transit-accessible neighborhoods, where positive reviews could help compensate for the disadvantages of limited walkability or transit options. In contrast, in neighborhoods with high walkability or access to public transit ratings, these location-based amenities might already drive prices, reducing the added impact of satisfaction ratings.\nTo test whether the overall_satisfaction × WalkScore interaction is significant, we can fit a model with the interaction and use drop1() or anova() to test its contribution:\n\n# Fit model with WalkScore interaction\nmodel_interaction_walk &lt;- lmer(log_price ~ overall_satisfaction_c * WalkScore_c + room_type + accommodates_c + bedrooms_c + minstay_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\n\n# Test the interaction term\ndrop1(model_interaction_walk)\n\nThe drop1() output will show whether the interaction term overall_satisfaction_c:WalkScore_c significantly contributes to the model. Look for the p-value in the Pr(&gt;F) column for this interaction term.\n\n\n\n\n\n\nImportantQuestion\n\n\n\nBased on the F-test from drop1(), is the overall_satisfaction × WalkScore interaction statistically significant? What does this tell you about whether the effect of satisfaction on price depends on neighborhood walkability?\n\n\n\nInterpreting the interaction\nIf the interaction is significant, we can use the emmeans package to compute estimated marginal means (EMMs) at specific combinations of satisfaction ratings and walkability scores. These estimated marginal means represent the model’s predicted log prices at particular values of the predictors, holding all other variables constant at their reference levels. By calculating EMMs at representative values (such as low, average, and high levels), we can create a clear visualization of how the effect of satisfaction on price varies across different walkability levels.\n\n# Use representative values based on the data distribution\n# For interpretability, we'll use low (Q1), medium (mean = 0), and high (Q3) values\nsatisfaction_low &lt;- quantile(chicago_airbnb$overall_satisfaction_c, 0.25, na.rm = TRUE)\nsatisfaction_high &lt;- quantile(chicago_airbnb$overall_satisfaction_c, 0.75, na.rm = TRUE)\n\nwalkscore_low &lt;- quantile(chicago_airbnb$WalkScore_c, 0.25, na.rm = TRUE)\nwalkscore_high &lt;- quantile(chicago_airbnb$WalkScore_c, 0.75, na.rm = TRUE)\n\n# Create a 3x3 grid using low (Q1), average (0), and high (Q3) values\npredictions_grid &lt;- emmeans(model_interaction_walk,\n                            specs = ~ overall_satisfaction_c * WalkScore_c,\n                            at = list(overall_satisfaction_c = c(satisfaction_low, 0, satisfaction_high),\n                                     WalkScore_c = c(walkscore_low, 0, walkscore_high)),\n                            lmer.df = \"satterthwaite\")\n\n# Display the 3x3 grid of predictions\nprint(predictions_grid)\n\nExplanation of the emmeans() arguments:\n\nThe first argument is the fitted model object (model_interaction_walk)\nspecs = ~ overall_satisfaction_c * WalkScore_c specifies which variables to compute marginal means for, including their interaction\nat = list(...) specifies the exact values at which to evaluate the predictors. Here we use three levels for each variable: Q1 (low), 0 (average, since variables are centered), and Q3 (high)\nlmer.df = \"satterthwaite\" specifies the method for computing degrees of freedom and confidence intervals. We use Satterthwaite’s approximation to be consistent with the default method used by lmerTest for F-tests\nAll other predictors in the model (room type, accommodates, bedrooms, etc.) are automatically held at their reference levels or means\n\nThe output shows a 3 × 3 grid of estimated marginal means with their standard errors and confidence intervals, representing the estimated log price at each combination of satisfaction and walkability levels.\nNow we can visualize these estimated marginal means using an interaction plot:\n\n# Convert predictions to data frame for plotting\npred_df &lt;- as.data.frame(predictions_grid)\n\n# Add descriptive labels for the factor levels\npred_df$satisfaction_label &lt;- factor(pred_df$overall_satisfaction_c,\n                                     levels = c(satisfaction_low, 0, satisfaction_high),\n                                     labels = c(\"Low (Q1)\", \"Average (Mean)\", \"High (Q3)\"))\n\npred_df$walkscore_label &lt;- factor(pred_df$WalkScore_c,\n                                  levels = c(walkscore_low, 0, walkscore_high),\n                                  labels = c(\"Low (Q1)\", \"Average (Mean)\", \"High (Q3)\"))\n\n# Create interaction plot\nggplot(pred_df, aes(x = satisfaction_label, y = emmean,\n                    color = walkscore_label, group = walkscore_label)) +\n  geom_point(size = 3) +\n  geom_line(linewidth = 1) +\n  labs(title = \"Interaction between Satisfaction and Walkability\",\n       subtitle = \"Estimated log prices at different combinations of satisfaction and walkability\",\n       x = \"Overall Satisfaction Level\",\n       y = \"Estimated Log Price\",\n       color = \"Walkability Level\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nThis visualization shows:\n\nThree lines representing neighborhoods with low, average, and high walkability\nSlopes indicating how satisfaction relates to price at each walkability level\nIf the lines are parallel, the interaction effect is weak or non-significant\nIf the lines have different slopes, it indicates that the satisfaction-price relationship varies by walkability\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nBased on the interaction plot, how does the relationship between satisfaction ratings and listing prices differ across neighborhoods with varying walkability levels? Do satisfaction ratings matter more (have a stronger effect) in low-walkability or high-walkability neighborhoods?\n\n\n\n\n\n\n\n\nImportantCoding exercise\n\n\n\nFollowing the example above, test whether the overall_satisfaction × TransitScore interaction is statistically significant.\n\nFit a model that includes the overall_satisfaction × TransitScore interaction\nUse drop1() to test whether the interaction term is significant\nInterpret the results: Is the interaction significant? What does this suggest about how satisfaction ratings relate to prices in neighborhoods with different levels of transit accessibility?\n\n\n\n\n\n\n\n\n\nNoteTesting strategy for mixed models\n\n\n\nIn this lab, we have used F-tests (via step() and drop1()) to test fixed effects in our mixed models. These tests:\n\nUse Satterthwaite’s approximation for degrees of freedom\nWork with REML estimation (the default for lmer(), which gives better variance component estimates)\nAre appropriate for testing whether fixed effect terms should be included in the model\n\nThis approach provides a consistent workflow for testing and selecting fixed effects. For testing random effects (such as whether to include random slopes in addition to random intercepts), we use likelihood ratio tests (LRT), which we will cover in the next lab on longitudinal data analysis.\n\n\n\n\nModel diagnostics\nThe process of performing model diagnostics for the random intercept models fitted in this lab is similar to the one described in the previous labs. Therefore, we refer to those labs for more detailed instructions on assessing model assumptions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R labs for the Beyond MLR course",
    "section": "",
    "text": "This website hosts the R labs for the beyond MLR course. You can navigate between the different labs using the menu above."
  },
  {
    "objectID": "BLR_lab_FE_oneway.html",
    "href": "BLR_lab_FE_oneway.html",
    "title": "Beyond MLR Lab 1: One-way ANOVA",
    "section": "",
    "text": "NotePreliminary setup\n\n\n\nIn this lab, we will use the R packages ggplot2, dplyr, and emmeans. You can use the script below to automatically install and load them using the pacman package.\n\n# Check whether pacman is available and install if needed\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\n# Use pacman to install (if needed) and load the required packages\npacman::p_load(dplyr, ggplot2, emmeans, lmerTest)"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "href": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 1: One-way ANOVA",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo understand the distribution of blood pressure reduction across treatment groups, we start by creating a boxplot:\n\n# Visualizing the results\nggplot(data_oneway, aes(x = Treatment, y = BP_change, fill = Treatment)) +\n  geom_boxplot() +\n  labs(title = NULL,\n       x = \"Treatment\", y = \"Change in SBP (mm Hg)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\nWe also calculate some summary statistics:\n\n# Generating summary statistics\nsummary_stats &lt;- data_oneway |&gt;\n  group_by(Treatment) |&gt;\n  summarise(\n    Mean_BP_change = mean(BP_change),\n    SD_BP_change = sd(BP_change)\n  )\nsummary_stats\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow do the mean changes in SBP compare among the treatment groups?"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "href": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "title": "Beyond MLR Lab 1: One-way ANOVA",
    "section": "Performing a One-Way ANOVA",
    "text": "Performing a One-Way ANOVA\n\nModel Specification\nUsing effects coding, the one-way Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The change in SBP for the \\(j\\)-th patient in the \\(i\\)-th treatment group.\n\\(\\mu\\): The mean change in SBP across all treatment groups.\n\\(\\tau_i\\): The effect of the \\(i\\)-th treatment (deviation from the overall mean).\n\\(\\epsilon_{ij}\\): The residual error term, assumed to be independent and normally distributed with mean zero and constant variance.\n\n\n\n\n\n\n\nNoteCoding schemes for categorical variables\n\n\n\nIn regression models, categorical variables are represented using coding schemes that allow their inclusion as explanatory variables. While dummy coding is widely used in multiple linear regression models, effects coding is more common in ANOVA models as it enables interpretation of group differences relative to the grand mean rather than a single reference category. This interpretative difference makes effects coding particularly useful for examining group-level effects in experimental designs.\nTo change the coding scheme globally to effects coding:\n\n# Set effects coding as the default coding scheme for unordered (nominal) factors\n# Keep the default polynomial coding for ordered (ordinal) factors\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\nTo reset the coding scheme to the default dummy coding:\n\n# Reset the coding scheme for unordered factors to dummy coding\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n\n\n\n\n\nModel Estimation\nWe can fit the one-way ANOVA model using the lm() function:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\")) # Effects coding\ncontrasts(data_oneway$Treatment) # Print contrast matrix for Treatment\n\n# Fit the one-way ANOVA model\nmodel_oneway &lt;- lm(BP_change ~ Treatment, data = data_oneway)\nsummary(model_oneway)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow do the estimated coefficients relate to the group means?\n\n\n\n\nANOVA Table\nTo test whether the effect of treatment is statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_oneway)\nanova_results\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\nEstimated Marginal Means\nEstimated marginal means, also known as least-squares means, are model-based means that represent the predicted (or expected) response at each level of a factor, averaged over the levels of other variables in the model.\nIn the context of a one-way ANOVA, where there is only one factor (e.g., treatment group), the estimated marginal means are equal to the observed group means. In more complex models with multiple factors, estimated marginal means provide predicted group means that are averaged over the levels of these additional factors. For example, in a model with both treatment and age as factors, the estimated marginal means for the treatment groups show the treatment means averaged over age, illustrating what these group means are expected to be at specific values of age (or averaged over a grid of age values).\nWe can calculate the estimated marginal means using the emmeans() function from the emmeans package:\n\n# Obtain estimated marginal means\nemms &lt;- emmeans(model_oneway, ~ Treatment)\nemms  # displays EMMs with standard errors and 95% confidence intervals\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow do the estimated marginal means compare to the observed group means calculated during the exploratory data analysis?\n\n\n\n\nPairwise comparisons\nSince we found a significant treatment effect, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another. We perform these pairwise comparisons using the pairs() function from the emmeans package. To account for the increased risk of Type I error due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled.\n\n# Performing post-hoc analysis with emmeans\npairs(emms, adjust=\"Bonferroni\")\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\nModel Diagnostics\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance) for the errors. A random scatter of residuals around zero indicates equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Residuals following the reference line suggest normally distributed errors.\n\n\n# Residuals vs Fitted\nplot(model_oneway, which = 1, main = \"Residuals vs Fitted\")\n\n# Normal Q-Q\nplot(model_oneway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?\n\n\n\n\nReporting\nA one-way ANOVA showed a statistically significant effect of treatment on the change in systolic blood pressure, F(2, 117) = 43.86, p &lt; 0.001. Estimated marginal means (95% CI) were -20.1 (-22.9, -17.2) mm Hg for Drug A, -4.9 (-7.8, -2.1) mm Hg for Drug B, and -1.6 (-4.4, 1.3) mm Hg for the Control group. Pairwise comparisons (Bonferroni-adjusted) indicated statistically significant differences between Drug A and both Drug B (p &lt; 0.001) and the Control group (p &lt; 0.001), but not between Drug B and the Control group (p = 0.291)."
  },
  {
    "objectID": "BLR_lab_randomized_block.html",
    "href": "BLR_lab_randomized_block.html",
    "title": "Beyond MLR Lab 2: Randomized Block Designs",
    "section": "",
    "text": "NotePreliminary setup\n\n\n\nIn this lab, we will use the R packages ggplot2, dplyr, emmeans, and lmerTest. You can use the script below to automatically install and load them using the pacman package.\n\n# Check whether pacman is available and install if needed\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\n# Use pacman to install (if needed) and load the required packages\npacman::p_load(dplyr, ggplot2, emmeans, lmerTest)"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 2: Randomized Block Designs",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo explore the data and investigate the possible presence of a laboratory effect, we start by creating a scatter plot with the wound healing variable on the x-axis and the laboratory facility variable on the y-axis:\n\nggplot(data_block, aes(x = WoundHealing, y = Laboratory, color = Treatment)) +\n  geom_point(size = 4) +\n  labs(title = \"Wound Healing by Treatment and Laboratory\",\n       x = \"Wound Healing Measure\",\n       y = \"Laboratory\") +\n  theme_minimal()\n\nIn addition to the scatter plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_block |&gt;\n  group_by(Treatment) |&gt;\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_block |&gt;\n  group_by(Laboratory) |&gt;\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\nsummary_stats_laboratory\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment and laboratory based on the plot and summary statistics?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "href": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "title": "Beyond MLR Lab 2: Randomized Block Designs",
    "section": "A Mixed Effects Model for the Randomized Block Design",
    "text": "A Mixed Effects Model for the Randomized Block Design\nIn a mixed-effects model, both fixed effects and random effects are used to account for different sources of variation.\nIn the wound healing example, it is essential to account for the laboratory facility because differences between laboratories (such as variations in environmental conditions) could influence the outcome. By including laboratory as a blocking variable, we can more efficiently estimate the treatment effects by controlling for this source of variability. This can be statistically achieved by modeling laboratory as either a fixed effect or a random effect.\nWhile we could model laboratory as a fixed effect, treating it as a random effect is preferred in this case for two reasons: first, it better reflects reality, as the laboratories are considered a random sample of possible laboratory conditions; second, it reduces the number of parameters we need to estimate, making the model more parsimonious. Modeling the lab as random allows us to account for variability between laboratories without estimating a separate effect for each one, which ultimately helps to isolate the treatment effects more effectively.\nOn the other hand, treatment is modeled as a fixed effect because we are specifically interested in estimating and comparing the effectiveness of the three particular wound healing treatments (Treatment A, Treatment B, and Treatment C). These treatments are not considered random samples from a larger population of treatments; rather, they are the specific interventions under study. By modeling treatment as a fixed effect, we aim to draw conclusions about the differences between these particular treatments, and their impact on wound healing.\n\nModel Specification\nThe mixed-effects model for our randomized block design can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + b_j + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The observed wound healing response for treatment \\(i\\) in laboratory \\(j\\).\n\\(\\mu\\): The overall mean response across all treatments and laboratories.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\), representing the deviation of treatment \\(i\\) from the overall mean \\(\\mu\\).\n\\(b_j\\): The random effect of laboratory \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\)).\n\\(\\epsilon_{ij}\\): The residual error term, assumed to be independent and normally distributed with mean zero and variance \\(\\sigma^2\\).\n\n\n\n\n\n\n\nNoteNotation convention\n\n\n\nIn mixed-effects models, fixed effects are typically represented by Greek letters, while random effects are represented by Roman letters. This helps differentiate between the two types of effects in model specification.\n\n\n\n\nModel Estimation\nTo fit the previously specified mixed effects model, we use the lmer() function from the lmeTest package:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\ncontrasts(data_block$Treatment) # Print contrast matrix for Treatment\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_block)\nsummary(model_block)\n\n\nSyntax overview\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory)\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments. Note that the intercept is included by default in the model, so WoundHealing ~ Treatment is essentially a shortcut for WoundHealing ~ 1 + Treatment. Also remember that with effects coding, the intercept represents the overall mean across all levels of the treatment variable, and the treatment coefficients represent deviations from this mean.\n(1 | Laboratory): This specifies the random effect for Laboratory, representing laboratory-specific deviations from the overall mean.\n\n\n\nSummary overview\nWhen you run summary(model_block), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean wound healing score averaged across all treatments and laboratories.\nTreatment: The differences in wound healing associated with each treatment relative to the overall mean.\n\nRandom Effects: Estimates of the variance components\n\nLaboratory - Intercept: Between-laboratory variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nWarningCaution: Interpreting p-values in Mixed Effects Models\n\n\n\nWhile the lmerTest package provides p-values for fixed effects, it is important to use them with caution, primarily because methods for calculating degrees of freedom, such as Satterthwaite, are approximations that may not always be reliable, particularly in complex models fitted to imbalanced data. Hypothesis testing based on likelihood ratio tests may be preferred in those settings.\n\n\n\n\n\nAssessing the fixed effects\nIn addition to providing p-values for fixed effects estimates, the lmerTest package allows us to assess the overall significance of fixed effects using the anova() function. To further explore the nature of these effects, we can obtain the estimated marginal means for the factor levels in the model. Rather than using the package’s build in ls_means() function, we will use emmeans() function from the emmeans package, which provides more options and greater flexibility.\n\n# Obtain ANOVA table for the fixed effects\nanova(model_block)\n\n\n# Compute estimated marginal means for the Treatment variable\nemms &lt;- emmeans(model_block, ~ Treatment)\nemms\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\nPairwise comparisons\nSince we found a significant treatment effect, we proceed with computing pairwise differences of the estimated marginal means:\n\n# Perform pairwise comparisons with Bonferroni adjustment\npairs(emms, adjust = \"bonferroni\")\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\nAssessing the variance components\n\n\n\n\n\n\nImportantQuestion\n\n\n\nBased on the estimated variance components from summary(model_block), calculate the intra-class correlation (ICC) and interpret its meaning.\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nConsidering these results, do you think that blocking by laboratory was necessary for this experiment?\n\n\n\n\nModel Diagnostics\nIn mixed-effects models, model diagnostics involve analyzing different types of residuals to evaluate how well the model fits the data and to assess whether key assumptions are satisfied.\nThe default type of residuals used in these models are the conditional residuals, which are calculated based on predicted values that incorporate both fixed effects and estimated random effects. Conditional residuals represent the deviation of the observed data from the model’s predictions, accounting for variability from both sources: fixed effects and random effects. They can be considered estimates of the errors \\(\\epsilon_{ij}\\), which are assumed to be normally distributed with a mean of zero and constant variance.\nTo check these assumptions, we can generate diagnostic plots similar to those used in linear regression models:\n\nResiduals vs. Fitted Plot: This plot helps check for homoscedasticity (constant variance).\nNormal Q-Q Plot: This plot assesses whether the residuals follow a normal distribution.\n\n\n# Extract conditional residuals\nresiduals_cond &lt;- resid(model_block)\n\n# Residuals vs Fitted\nplot(fitted(model_block), residuals_cond,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond)\nqqline(residuals_cond, col = \"red\")\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "BLR_lab_two_way_factorial.html",
    "href": "BLR_lab_two_way_factorial.html",
    "title": "Beyond MLR Lab 3: Two-Way Factorial ANOVA",
    "section": "",
    "text": "NotePreliminary setup\n\n\n\nIn this lab, we will use the R packages ggplot2, dplyr, and emmeans. You can use the script below to automatically install and load them using the pacman package.\n\n# Check whether pacman is available and install if needed\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\n# Use pacman to install (if needed) and load the required packages\npacman::p_load(dplyr, ggplot2, emmeans)"
  },
  {
    "objectID": "BLR_lab_two_way_factorial.html#exploratory-data-analysis",
    "href": "BLR_lab_two_way_factorial.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 3: Two-Way Factorial ANOVA",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo understand how recovery rates vary across therapy type and disease severity, we start by creating an interaction plot. An interaction plot is a graphical tool that helps visualize whether the effect of one factor (in this case, therapy) depends on the levels of another factor (in this case, disease severity). If the lines on the interaction plot are parallel, this suggests there is no interaction, meaning the effect of therapy is the same for both disease severities. If the lines are not parallel, this indicates a potential interaction, meaning the effect of therapy differs depending on the severity of the disease.\n\n# Visualizing the results\nggplot(data_twoway, aes(x = Therapy, y = RecoveryRate, color = Severity, group = Severity)) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  labs(title = NULL,\n       x = \"Therapy Type\", \n       y = \"Mean recovery rate (%)\",\n       color = \"Disease Severity\") +\n  theme_minimal()\n\nWe also calculate summary statistics for each combination of therapy type and disease severity:\n\n# Generating summary statistics by Therapy and Severity\nsummary_stats &lt;- data_twoway |&gt;\n  group_by(Therapy, Severity) |&gt;\n  summarise(\n    n = n(),\n    Mean_RecoveryRate = mean(RecoveryRate),\n    SD_RecoveryRate = sd(RecoveryRate),\n    .groups = \"drop\"\n  )\nsummary_stats\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nBased on the plot and summary statistics, does there appear to be an interaction between therapy type and disease severity?"
  },
  {
    "objectID": "BLR_lab_two_way_factorial.html#two-way-factorial-anova-model",
    "href": "BLR_lab_two_way_factorial.html#two-way-factorial-anova-model",
    "title": "Beyond MLR Lab 3: Two-Way Factorial ANOVA",
    "section": "Two-Way Factorial ANOVA Model",
    "text": "Two-Way Factorial ANOVA Model\n\nModel Specification\nUsing effects coding, the two-way factorial Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\epsilon_{ijk}\n\\]\nwhere:\n\n\\(Y_{ijk}\\): The recovery rate for the \\(k\\)-th patient with therapy type \\(i\\) and disease severity level \\(j\\).\n\\(\\mu\\): The grand mean (overall average recovery rate across all groups).\n\\(\\alpha_i\\): The main effect of therapy type \\(i\\), representing the deviation from the grand mean. Constraint: \\(\\sum_i \\alpha_i = 0\\).\n\\(\\beta_j\\): The main effect of disease severity level \\(j\\), representing the deviation from the grand mean. Constraint: \\(\\sum_j \\beta_j = 0\\).\n\\((\\alpha\\beta)_{ij}\\): The interaction effect between therapy type \\(i\\) and severity level \\(j\\), representing the deviation from additivity. Constraint: \\(\\sum_i (\\alpha\\beta)_{ij} = \\sum_j (\\alpha\\beta)_{ij} = 0\\).\n\\(\\epsilon_{ijk}\\): The residual error term, assumed to be independent and normally distributed with mean zero and constant variance.\n\n\n\nModel Estimation\nWe can fit the two-way ANOVA model using the lm() function. The key feature of the model formula is the interaction term (specified using *), which includes both main effects and their interaction:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\n# Fit the two-way ANOVA model with interaction\nmodel_twoway &lt;- lm(RecoveryRate ~ Therapy * Severity, data = data_twoway)\nsummary(model_twoway)\n\n\n\nANOVA Table and Global Hypothesis Tests\nTo test whether the main effects and interaction are statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_twoway)\nanova_results\n\nThe ANOVA table tests three global hypotheses:\n\nNo interaction: \\(H_0\\!:\\,(\\alpha\\beta)_{ij}=0\\) for all \\(i,j\\)\nNo main effect of Therapy: \\(H_0\\!:\\,\\alpha_i=0\\) for all \\(i\\)\nNo main effect of Severity: \\(H_0\\!:\\,\\beta_j=0\\) for all \\(j\\)\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nWhat do the F-tests and p-values in the ANOVA table tell us about the significance of the interaction and main effects?"
  },
  {
    "objectID": "BLR_lab_two_way_factorial.html#simple-effects-analysis",
    "href": "BLR_lab_two_way_factorial.html#simple-effects-analysis",
    "title": "Beyond MLR Lab 3: Two-Way Factorial ANOVA",
    "section": "Simple Effects Analysis",
    "text": "Simple Effects Analysis\nBecause the interaction effect is significant, we proceed with examining the simple effects: the effect of one factor within each level of the other factor. When analyzing an interaction, we have a choice in how to decompose it. We could examine either the effect of therapy type (Standard vs Enhanced vs Control) separately for each disease severity level, or alternatively, we could examine the effect of disease severity (Mild vs Severe) separately for each therapy type.\nIn this clinical context, we choose to examine the effect of therapy type conditional on disease severity level. This choice is clinically motivated: from a treatment planning perspective, clinicians need to know which therapies work best for patients presenting with different disease severity levels. Understanding how therapy effectiveness varies across severity groups directly informs treatment decisions and allows for severity-stratified recommendations. In other words, the question “which therapy works best for mild cases versus severe cases?” is more clinically actionable than asking “how does severity affect outcomes for each therapy type?”\n\n# Compute simple effects: effect of therapy type within each severity level\nse_severity &lt;- emmeans(model_twoway, ~ Therapy | Severity)\nse_severity\n\nTo test which simple effects are significant, we perform pairwise comparisons within each severity level (using the Bonferroni correction to adjust for multiplicity):\n\n# Pairwise comparisons (Therapy types) within each disease severity level\nse_pairs &lt;- pairs(se_severity, adjust = \"bonferroni\")\nse_pairs\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nFor which disease severity level(s) does therapy type have a significant effect on recovery rate? What is the practical interpretation of this finding?\n\n\n\nAlternative Decomposition: Simple Effects Conditional on Therapy Type\nAs mentioned earlier, we could also decompose the interaction by examining the effect of disease severity separately for each therapy type. While this perspective is less clinically motivated than the severity-stratified approach above, it can still provide useful insights.\n\n\n\n\n\n\nImportantExercise\n\n\n\nPerform a simple effects analysis conditional on therapy type (i.e., examine the effect of disease severity (Mild vs Severe) within each therapy type).\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nFor which therapy type(s) does disease severity have a significant effect on recovery rate?\n\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nHow do these findings complement or differ from the severity-stratified analysis we performed above?\n\n\n\n\nModel Diagnostics\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance). A random scatter around zero suggests equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Points following the reference line suggest normally distributed residuals.\n\n\n# Residuals vs Fitted\nplot(model_twoway, which = 1, main = \"Residuals vs Fitted\")\n\n# Normal Q-Q\nplot(model_twoway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\nImportantQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?"
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html",
    "href": "Assignments/Week 2/Assignment_week_2.html",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that evaluates the effectiveness of different exercise routines on improving functional mobility in patients recovering from knee replacement surgery. The study uses a replicated randomized block design to account for individual variability among patients.\nEach patient participated in all three exercise routines, and each routine was performed three times. Functional mobility was assessed after each session, with scores ranging from 40 to 80 (higher scores indicate better mobility). The dataset contains 54 observations (6 patients x 3 routines x 3 replications) and is provided in the downloads section below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#introduction",
    "href": "Assignments/Week 2/Assignment_week_2.html#introduction",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that evaluates the effectiveness of different exercise routines on improving functional mobility in patients recovering from knee replacement surgery. The study uses a replicated randomized block design to account for individual variability among patients.\nEach patient participated in all three exercise routines, and each routine was performed three times. Functional mobility was assessed after each session, with scores ranging from 40 to 80 (higher scores indicate better mobility). The dataset contains 54 observations (6 patients x 3 routines x 3 replications) and is provided in the downloads section below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#dataset-description",
    "href": "Assignments/Week 2/Assignment_week_2.html#dataset-description",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Dataset Description",
    "text": "Dataset Description\nThe dataset consists of the following variables:\n\nPatient: A numeric variable representing individual patients (blocks).\nExerciseRoutine: A factor variable representing the type of exercise routine:\n\nA: Low-impact walking exercises.\nB: Resistance training exercises.\nC: Balance and flexibility exercises.\n\nFunctionalMobility: A numeric variable (40-80) representing the mobility score measured after each session."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#objective",
    "href": "Assignments/Week 2/Assignment_week_2.html#objective",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Objective",
    "text": "Objective\nYour goal is to determine:\n\nWhether there are significant differences in functional mobility scores between the three exercise routines.\nHow much of the variability in mobility scores can be attributed to:\n\nDifferences between patients.\nDifferences between exercise routines.\nResidual variability (within patient-treatment combinations).\n\n\nTo complete this analysis, follow the detailed steps outlined below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 2/Assignment_week_2.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Steps to Complete the Analysis",
    "text": "Steps to Complete the Analysis\n\n1. Load the dataset\nWhen loading the dataset in R, ensure that the ExerciseRoutine variable is treated as a factor. One way to achieve this is by specifying the column type explicitly using the colClasses argument in the read.csv() function. For example:\n\n# Load the dataset and specify ExerciseRoutine as a factor\ndataset &lt;- read.csv(\"functional_mobility.csv\", colClasses = c(\"ExerciseRoutine\" = \"factor\"))\n\n\n\n2. Perform an Exploratory Data Analysis (EDA)\n\nVisualize the data using an interaction plot.\nCalculate descriptive statistics for each exercise routine and patient.\n\n\n\n3. Fit a Mixed-Effects Model\n\nFit a mixed-effects model with:\n\nFixed Effects: ExerciseRoutine (to estimate differences between exercise routines).\nRandom Effects:\n\nPatient (to account for variability between individuals).\nPatient × ExerciseRoutine (to account for potential variability in how patients respond to different routines).\n\n\nSummarize the model:\n\nReport the fixed effects and variance components.\n\n\n\n\n4. Test for Overall Differences\n\nUse the selected model to test for overall differences in functional mobility scores across exercise routines.\nIf significant overall differences are found, perform pairwise comparisons to identify which routines differ.\n\n\n\n5. Assess variance components\n\nCalculate ICCs to evaluate the variance components\n\n\n\n6. Evaluate Model Assumptions\n\nAssess the model’s assumptions (e.g., normality of residuals, homoscedasticity) using diagnostic plots."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#requirements-for-the-report",
    "href": "Assignments/Week 2/Assignment_week_2.html#requirements-for-the-report",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The quarto source file should include all R code and annotations, and the html file should be rendered with code visibility enabled (echo = TRUE)."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#downloads",
    "href": "Assignments/Week 2/Assignment_week_2.html#downloads",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html",
    "href": "Assignments/Week 4/Assignment_week_4.html",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "",
    "text": "You will work with longitudinal data from a growth curve study. The dataset captures weight measurements of 568 Asian children, recorded during clinic visits on up to five occasions. Ages range from approximately 6 weeks to 27 months. Your task is to model the children’s growth trajectories over time.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#introduction",
    "href": "Assignments/Week 4/Assignment_week_4.html#introduction",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "",
    "text": "You will work with longitudinal data from a growth curve study. The dataset captures weight measurements of 568 Asian children, recorded during clinic visits on up to five occasions. Ages range from approximately 6 weeks to 27 months. Your task is to model the children’s growth trajectories over time.\nThis dataset was sourced from the data library of the centre for Multilevel Modelling, University of Bristol."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#dataset-description",
    "href": "Assignments/Week 4/Assignment_week_4.html#dataset-description",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Dataset description",
    "text": "Dataset description\nThe dataset consists of the following variables:\n\nChildID: Unique identifier for each child\nAge: Child’s age at the time of measurement (months)\nWeight: Child’s weight at the time of measurement (grams)\nGender: Child’s gender (Boy or Girl)"
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#objectives",
    "href": "Assignments/Week 4/Assignment_week_4.html#objectives",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Objectives",
    "text": "Objectives\nYour objectives are to:\n\nDevelop an appropriate model to describe the growth curve of children’s weight over time, considering fixed and random effects.\nUse the model to answer the following research questions:\n\nHow does the weight of children change over time (e.g., constant, linear, quadratic)?\nHow does gender influence the mean growth curve of children’s weight?"
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 4/Assignment_week_4.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Steps to complete the analysis",
    "text": "Steps to complete the analysis\n\nLoad the dataset\nDownload the dataset (see link in the Downloads section below) and read it into R. Ensure that the Gender variable is correctly encoded as a factor.\n\n\nExploratory data analysis\n\nExplore the individual and mean trajectories of weight gain over time.\n\n\n\nModel building\n\nBegin with a comprehensive (saturated) model and iteratively simplify it to determine the best fixed and random effects structure.\nUse likelihood ratio tests to refine random effects (models not refitted with ML).\nUse likelihood ratio tests with models refitted using ML to refine fixed effects.\n\n\n\nInterpret the results\nInterpret the findings from your analysis, focusing on answering the research questions outlined in the Objectives section."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#requirements-for-the-report",
    "href": "Assignments/Week 4/Assignment_week_4.html#requirements-for-the-report",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Requirements for the report",
    "text": "Requirements for the report\nYour report should clearly explain:\n\nThe reasoning behind your choice of model structure.\nThe interpretation of key model parameters in the context of the research questions.\nAny limitations or assumptions affecting your analysis.\n\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. Ensure that the HTML file includes visible code (echo = TRUE) for reproducibility."
  },
  {
    "objectID": "Assignments/Week 4/Assignment_week_4.html#downloads",
    "href": "Assignments/Week 4/Assignment_week_4.html#downloads",
    "title": "Assignment Week 4: Longitudinal Data Analysis",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  }
]