[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R labs for the Beyond MLR course",
    "section": "",
    "text": "This website hosts the R labs for the beyond MLR course. You can navigate between the different labs using the menu above."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html",
    "href": "BLR_lab_replicated_randomized_block.html",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "",
    "text": "In the previous lab, we considered a traditional randomized block design without replication, where each treatment was applied once within each block (laboratory). This design allowed us to control for variability between laboratories and efficiently estimate the main effects of the treatments. However, a key limitation of this approach is that it does not allow us to assess whether the treatment effects vary across blocks, a concept known as interaction.\nThe lack of replication in the traditional design means we can only test for main effects of the treatments and laboratories, but not whether the effectiveness of a treatment depends on the specific laboratory conditions. For example, a treatment might work well in one laboratory but not in another due to environmental differences (e.g., humidity or temperature), indicating a treatment-by-laboratory interaction.\nAn interaction occurs when the effect of one factor (e.g., treatment) is not consistent across levels of another factor (e.g., laboratory). In other words, the effect of a treatment might vary depending on the laboratory conditions. Replicating the treatments within each block allows us to estimate these interaction effects and better understand the variability in treatment outcomes across different settings.\nIn this lab, we introduce replication within blocks, allowing us to estimate the variability within treatment-block combinations and assess whether treatment effects are consistent across blocks."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo explore the data and investigate the presence of a potential interaction between treatments and laboratories, we create an interaction plot. An interaction plot is a graphical tool that helps visualize whether the effect of one factor (in this case, treatment) depends on the levels of another factor (in this case, laboratory). Specifically, it shows how the mean response (wound healing) for each treatment varies across different laboratories. If the lines on the interaction plot are parallel, this suggests there is no interaction, meaning the treatment effect is consistent across laboratories. If the lines are not parallel, this indicates a potential interaction, meaning the effect of treatment differs depending on the laboratory.\n\n# Calculate mean Wound Healing for each Treatment-Laboratory combination\nlibrary(dplyr)\nmean_data &lt;- data_rep_block %&gt;%\n  group_by(Laboratory, Treatment) %&gt;%\n  summarise(Mean_WoundHealing = mean(WoundHealing))\n\n# Display the produced summary table with the group means\nmean_data\n\n# Create an interaction plot\nlibrary(ggplot2)\nggplot(mean_data, aes(x = Treatment, y = Mean_WoundHealing, group = Laboratory, color = Laboratory)) +\n  geom_point(size = 3) +\n  geom_line() +\n  labs(title = \"Interaction Plot\",\n       y = \"Mean Wound Healing Measure\",\n       x = \"Treatment\") +\n  theme_minimal()\n\n\n\n\n\n\n\nQuestion\n\n\n\nDoes the interaction plot indicate a potential interaction between treatment and laboratory?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDoes the plot suggest any differences in the overall effectiveness of the treatments (i.e., main effect of treatment) across all laboratories?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the plot suggest about variability between laboratories? Are some laboratories consistently higher or lower in wound healing across all treatments?"
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "href": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "title": "Beyond MLR Lab 4: Replicated Randomized Block Designs",
    "section": "A Mixed Effects Model for the Randomized Block Design",
    "text": "A Mixed Effects Model for the Randomized Block Design\nSimilar to the previous lab, laboratory is included as a random effect and treatment as a fixed effect in the model. The key new feature is the treatment-by-laboratory interaction term, which is also modeled as a random effect.\nTo understand why the interaction term must also be modeled as random, we need to consider the nature of random effects in this context. Since laboratory is treated as a random effect, we are assuming that the laboratories in the experiment represent a random sample from a larger population of possible laboratory conditions. This means that we are not just interested in the specific laboratories in the study, but in how the treatments would perform across any set of laboratories with varying conditions.\nWhen we include an interaction term between treatment and laboratory, we are asking whether the effect of each treatment depends on the laboratory environment. If we had modeled laboratory as a fixed effect (i.e., we were only interested in those specific laboratories), the interaction could also be treated as fixed. However, because laboratory is random, the interaction must also be treated as random to reflect the idea that the variability in treatment effects across laboratories applies not just to the specific laboratories in the study, but to any laboratory from the broader population.\nIn other words, by modeling the interaction as random, we are assuming that the variation in treatment effects is not unique to the five laboratories in the study, but rather represents random fluctuations in treatment effectiveness that could occur in any laboratory setting. This approach allows us to generalize our findings beyond the laboratories in the experiment, making the model more realistic and applicable to a wider range of scenarios.\n\nModel Specification\nThe mixed-effects model for the replicated randomized block design is specified as:\n\\[\nY_{ijk} = \\mu + \\tau_i + b_j + (tb)_{ij} + \\epsilon_{ijk}\n\\]\nwhere:\n\n\\(Y_{ijk}\\): Response (wound healing) for the \\(k\\)-tjh replicate of Treatment \\(i\\) in Laboratory \\(j\\).\n\\(\\mu\\): Overall mean response\n\\(\\tau_{i}\\): Fixed effect of Treatment \\(i\\).\n\\(b_{j}\\):Random effect of Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{b}\\).\n\\((tb)_{ij}\\): Random interaction effect between treatment \\(i\\) and Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{tb}\\).\n\\(\\epsilon_{ijk}\\): Random error term, assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2\\).\n\n\n\nModel Estimation\nSimilar as in the previous lab, we fit the mixed effects model using the lmer() function from the lmeTest package:\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory), data = data_rep_block)\nsummary(model_block)\n\n\nSyntax overview\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory):\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments.\n(1 | Laboratory): This specifies the random effect for laboratory, representing laboratory-specific deviations from the overall mean.\n(1 | Treatment:Laboratory): This specifies the random interaction term between Treatment and Laboratory.\n\n\n\nSummary overview\nWhen we run summary(model_random), the following output is displayed:\n\nFixed Effects\n\nThe intercept represents the overall mean wound healing measure across all treatments and laboratories, which is estimated as 56.47.\nThe coefficient for Treatment1 (-1.04) indicates that the mean wound healing for Treatment A is 1.04 units lower than the overall mean.\nThe coefficient for Treatment2 (1.03) shows that the mean wound healing for Treatment B is 1.03 units higher than the overall mean.\nTreatment C is not directly shown in the output because, with effects coding, the sum of the treatment coefficients must equal zero. Treatment C can be inferred as having a mean very close to the overall mean (around 0.01 units below it).\n\n\n\n\nVariance components\n\nThe random effect for Laboratory has a variance of 1.4462, indicating considerable variability in baseline wound healing levels across different laboratories.\nThe random effect for the Treatment-by-Laboratory Interaction has a variance of 0.4747, showing that the treatment effects vary across laboratories. This means the effectiveness of treatments is not entirely consistent across laboratories, though the variability in this interaction is smaller compared to the variability between laboratory baselines and may not be statistically significant (more about that later).\nThe residual variance is 0.9089, which represents the unexplained variability within each treatment-laboratory combination.\n\n\n\n\n\nAssessing the variance components\nIn our model, the treatment-by-laboratory interaction is modeled as a random effect. To determine whether this variance component is necessary, we perform a likelihood ratio test to compare the full model (i.e., the previously fitted model with both the random laboratory effect and the random treatment-by-laboratory interaction effect) to a reduced model that includes only the random laboratory effect:\n\n# Fit the full model with the random interaction term\nfull_model &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory), \n                   data = data_rep_block)\n\n# Fit the reduced model without the random interaction term\nreduced_model &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), \n                      data = data_rep_block)\n\n# Perform the likelihood ratio test\nanova(full_model, reduced_model, refit=FALSE)\n\nWhen given two or more arguments representing fitted models, the anova() function from the lmerTest package produces likelihood ratio tests to compare these models. By default, these models are refitted using maximum likelihood (ML) estimation, which is suitable for testing fixed effects but not ideal for testing random effects. Random effects are better assessed using restricted maximum likelihood (REML).\nTo keep the REML estimation intact for testing random effects, we use the refit=FALSE argument in the anova() function. This ensures that the models are compared without being refitted using ML.\nThe output provides the likelihood ratio test statistic and p-value, indicating whether the random interaction term significantly improves the model fit.\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the likelihood ratio test, is it necessary to include the random interaction term in the model, or is the simpler model (without the interaction term) sufficient?\n\n\n\n\n\n\n\n\nMaximum Likelihood (ML) versus Restricted Maximum Likelihood (REML) estimation\n\n\n\n\n\n\nMaximum Likelihood (ML): This method estimates all model parameters simultaneously, including both fixed and random effects. It provides unbiased estimates for fixed effects but can lead to biased estimates of the variance components.\nRestricted Maximum Likelihood (REML): REML focuses on estimating variance components while accounting for the loss of degrees of freedom associated with fixed effects. This method provides more accurate estimates of random effects.\n\nEstimates of the fixed effects parameters are generally comparable between ML and REML. However, variance component estimates will typically be larger with REML given that the method was developed to overcome the downward bias of the maximum likelihood estimates of variance components. For this reason, REML is the default estimation approach when fitting mixed effects models with the lmer() function. However, there are also situations where REML cannot be used, particularly during the model-building phase when comparing models with different fixed effects structures. In these cases, the models need to be refitted using ML.\n\n\n\n\n\nAssessing the fixed effects\nThe fixed effects can be assessed using an approach similar to that used in the previous lab. This includes testing for the overall significance of the treatment effect and, if significant, exploring the differences between specific treatment groups through estimated marginal means and pairwise comparisons.\nHowever, before performing these tests, we need to determine which model to use: the full model with the random interaction term or the reduced model without it. This choice is based on the results of the likelihood ratio test performed earlier. If the likelihood ratio test indicates that the random interaction term is necessary, we will use the full model for testing the fixed effects. Conversely, if the likelihood ratio test suggests that the random interaction term is unnecessary, we will use the simpler model without it. This aligns with the general scientific principle of preferring more parsimonious models that adequately explain the data while minimizing complexity.\n\n\nModel diagnostics\nThe process of performing model diagnostics for the replicated randomized block design is the same as for the traditional randomized block design. Therefore, we refer to the previous lab for detailed instructions on assessing model assumptions and performing diagnostic checks."
  },
  {
    "objectID": "BLR_lab_MLA.html",
    "href": "BLR_lab_MLA.html",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "",
    "text": "In this lab, we will explore the analysis of multilevel data, focusing on situations where subjects are nested within larger contexts, such as schools, neighborhoods, or clinics. The data include subject-level characteristics (e.g., age, gender), which reflect differences between individuals and help explain variation in their outcomes within a specific context. They also include context-level characteristics (e.g., school funding, neighborhood income), which account for differences between contexts and help explain variation in subject-level outcomes across these contexts."
  },
  {
    "objectID": "BLR_lab_MLA.html#exploratory-data-analysis",
    "href": "BLR_lab_MLA.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nLet’s load the data and use the str() function to inspect the structure of the dataset.\n\n# Load the required libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lmerTest)\n\n# Load the Chicago AirBnB data. Note that the call below assumes the csv file is placed in the 'data' folder directly above the root folder of the project. Update the string as needed if the file is located elsewhere.\nchicago_airbnb &lt;- read.csv(\"data/airbnb.csv\")\n\n# Convert all character variables into factors\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate_if(is.character, as.factor)\n\n# Inspect the structure of the dataset\nstr(chicago_airbnb)\n\nThis initial inspection makes clear that the Airbnb dataset has a multilevel structure: 1,561 individual listings are nested within 43 neighborhoods, which are further nested within 9 districts. To get a better feeling for this grouping structure, we begin by summarizing the number of listings in each neighborhood:\n\n# Summarize number of listings within each neighborhood\nlisting_summary &lt;- chicago_airbnb %&gt;%\n  group_by(neighborhood) %&gt;%\n  summarise(num_listings = n())\n\n# Visualize the distribution of listings across neighborhoods\nggplot(listing_summary, aes(x = reorder(neighborhood, num_listings), y = num_listings)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  coord_flip() +\n  labs(title = \"Number of Listings per Neighborhood\",\n       x = \"Neighborhood\",\n       y = \"Number of Listings\")\n\nExplanation:\n\ngroup_by(neighborhood): groups the data by the neighborhood column so that operations like counting can be applied to each group separately.\nAfter grouping, summarise() calculates the number of rows (listings) in each group (neighborhood) using the n() function. The result is stored in a new data fame with two columns:\n\nneighborhood: the name of the neighborhood;\nnum_listings: the number of listings in that neighborhood.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the plot tell us about the distribution of Airbnb listings across neighborhoods?\n\n\n\n\n\n\n\n\nCoding excerise\n\n\n\nCreate a similar plot to visualize the distribution of neighborhoods across districts. Hint: group the dataset by the district column and count the number of unique neighborhoods in each district. See ?summarise for a list of useful functions to use within summarise().\n\n\nNext, we create a histogram to visualize the distribution of the outcome variable price:\n\n# Create a histogram of price\nggplot(chicago_airbnb, aes(x = price)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Histogram of Listing Prices\",\n       x = \"Price\",\n       y = \"Frequency\")\n\nWhile normality of the outcome is not strictly required for a mixed-effects model, transforming a right-skewed variable like price can help stabilize variance and linearize relationships. We therefore create a new variable, log_price, to store the log-transformed prices:\n\n# Log-transform the price variable\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate(log_price = log(price))\n\nWe also want to get a sense of the variability in the listing prices within and between neighborhoods. For this, we are going to select the 10 neighborhoods with the most listings and create a scatter plot with the log-transformed price on the y-axis and the neighborhood on the x-axis:\n\n# Select the top 10 neighborhoods with the most listings\ntop_neighborhoods &lt;- listing_summary %&gt;%\n  slice_max(num_listings, n = 10) %&gt;%\n  pull(neighborhood)\n\n# Filter the data to include only the top neighborhoods\ntop_neighborhood_data &lt;- chicago_airbnb %&gt;%\n  filter(neighborhood %in% top_neighborhoods)\n\nExplanation:\n\nslice_max(num_listings, n = 10): selects the top 10 neighborhoods with the most listings based on the num_listings column.\npull(neighborhood): extracts the neighborhood names from the resulting tibble as a vector.\nfilter(neighborhood %in% top_neighborhoods): filters the chicago_airbnb dataset to include only rows where the neighborhood column matches one of the neighborhoods in the top_neighborhoods vector.\n\n\n# Calculate the average log_price for each neighborhood\nneighborhood_avg_price &lt;- top_neighborhood_data %&gt;%\n  group_by(neighborhood) %&gt;%\n  summarise(avg_log_price = mean(log_price, na.rm = TRUE))\n\n# create a scatter plot of log_price by neighborhood\nggplot(top_neighborhood_data, aes(x = neighborhood, y = log_price)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Price by Neighborhood\",\n       x = \"Neighborhood\",\n       y = \"Log-transformed price\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_point(data = neighborhood_avg_price, aes(x = neighborhood, y = avg_log_price), color = \"red\", size = 3) +  # neighborhood-level averages \n  geom_hline(yintercept = mean(neighborhood_avg_price$avg_log_price, na.rm = TRUE), linetype = \"dashed\", color = \"blue\") # overall average\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does this plot suggest about the variability in listing prices within and between neighborhoods?"
  },
  {
    "objectID": "BLR_lab_MLA.html#random-intercept-model",
    "href": "BLR_lab_MLA.html#random-intercept-model",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Random intercept model",
    "text": "Random intercept model\nTo model the variability in listing prices within and between neighborhoods, we start by fitting a random intercept model to account for the nesting of listings within neighborhoods, ignoring the higher-level nesting of neighborhoods into districts. The model is specified as follows:\n\n# Fit the random intercept model\nrandom_intercept_model &lt;- lmer(log_price ~ 1 + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model)\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of within-neighborhood and between-neighborhood variability to the total variability in listing prices?"
  },
  {
    "objectID": "BLR_lab_MLA.html#extending-the-random-intercept-model-with-subject-level-variables",
    "href": "BLR_lab_MLA.html#extending-the-random-intercept-model-with-subject-level-variables",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Extending the random intercept model with subject-level variables",
    "text": "Extending the random intercept model with subject-level variables\nAs a second step, we extend the random intercept model with subject-level variables. To facilitate the interpretation of the model coefficients, we start by setting the coding scheme for categorical variables to effects coding. We also center the numerical variables by subtracting the mean value from each observation. This step is important to reduce multicollinearity, improve numerical stability, and make the coefficients more interpretable.\n\n# Use effects coding for the categorical variables\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n\n# Center the continuous subject-levl variables\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate(overall_satisfaction_c = scale(overall_satisfaction, scale = FALSE),\n         accommodates_c = scale(accommodates, scale = FALSE),\n         bedrooms_c = scale(bedrooms, scale = FALSE),\n         minstay_c = scale(minstay, scale = FALSE))\n\nNext, we fit the random intercept model with the subject-level variables included:\n\n# Fit the random intercept model with subject-level variables    \nrandom_intercept_model_L1variables &lt;- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_L1variables)\n\n# Display the coding scheme for the room_type variable\ncontrasts(chicago_airbnb$room_type)\n\n# Obtain the ANOVA table for the subject-level variables\nanova(random_intercept_model_L1variables)\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow does centering the continuous variables affect the interpretation of the intercept?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow does the inclusion of individual-level variables affect the estimated variance components? More specifically, does the inclusion of individual-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of the individual-level variables are significantly associated with listing prices? How do you interpret the coefficients for these variables?"
  },
  {
    "objectID": "BLR_lab_MLA.html#including-context-level-variables",
    "href": "BLR_lab_MLA.html#including-context-level-variables",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Including context-level variables",
    "text": "Including context-level variables\nAs a third step, we extend the previously fitted model with context-level variables. We start by centering the context-level variables:\n\n# Center the context-level variables\nchicago_airbnb &lt;- chicago_airbnb %&gt;%\n  mutate(WalkScore_c = scale(WalkScore, scale = FALSE),\n         TransitScore_c = scale(TransitScore, scale = FALSE),\n         BikeScore_c = scale(BikeScore, scale = FALSE))\n\nNext, we fit the random intercept model with both subject-level and context-level variables included:\n\n# Fit the random intercept model with subject-level and context-level variables\nrandom_intercept_model_L1L2variables &lt;- lmer(log_price ~ overall_satisfaction_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_L1L2variables)\n\n# Obtain the ANOVA table\nanova(random_intercept_model_L1L2variables)  \n\n\n\n\n\n\n\nQuestion\n\n\n\nHow does the inclusion of context-level variables affect the estimated variance components? More specifically, does the inclusion of context-level variables affect the within-neighborhood variance, the between-neighborhood variance, or both? Can you explain why?\n\n\nNot all the context-level variables included in the model are significant predictors of listing prices. To obtain a more parsimonious model, we use the step() function from the lmerTest package to perform a backward elimination of the fixed-effect terms:\n\n# Perform stepwise selection to identify the most important predictors\nstep(random_intercept_model_L1L2variables, reduce.random = FALSE)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich individual-level and context-level variables are retained in the final model after the stepwise selection procedure?"
  },
  {
    "objectID": "BLR_lab_MLA.html#exploring-cross-level-interactions",
    "href": "BLR_lab_MLA.html#exploring-cross-level-interactions",
    "title": "Beyond MLR Lab 5: multilevel analysis",
    "section": "Exploring cross-level interactions",
    "text": "Exploring cross-level interactions\nFinally, we explore the possibility of cross-level interactions between individual-level and context-level variables.\nThe relationship between the overall satisfaction rating of an individual listing and its price may depend on neighborhood characteristics such as their walkability and access to public transit. For instance, higher satisfaction ratings might have a stronger effect on prices in less walkable or transit-accessible neighborhoods, where positive reviews could help compensate for the disadvantages of limited walkability or transit options. In contrast, in neighborhoods with high walkability or access to public transit ratings, these location-based amenities might already drive prices, reducing the added impact of satisfaction ratings.\nTo test whether the effect of the individual-level variable overall_satisfaction on listing prices varies across different values of the context-level variable WalkScore, we refit the model with an interaction term between these two variables:\n\n# Fit the model with the interaction between overall_satisfaction and WalkScore\nrandom_intercept_model_interaction &lt;- lmer(log_price ~ overall_satisfaction_c * WalkScore_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_interaction)\n\n\n\n\n\n\n\nQuestion\n\n\n\nIs there evidence of a significant interaction between overall satisfaction ratings and neighborhood walkability in predicting listing prices? If so, how do you interpret the interaction term coefficient?\n\n\nSimilarly, to test whether the effect of the individual-level variable overall_satisfaction varies across different values of the context-level variable TransitScore, we refit the model with an interaction term between these two variables:\n\n# Fit the model with the interaction between overall_satisfaction and WalkScore\nrandom_intercept_model_interaction &lt;- lmer(log_price ~ overall_satisfaction_c * WalkScore_c + room_type + accommodates_c + bedrooms_c + minstay_c + WalkScore_c + TransitScore_c + BikeScore_c + (1 | neighborhood), data = chicago_airbnb)\nsummary(random_intercept_model_interaction)\n\n\n\n\n\n\n\nQuestion\n\n\n\nIs there evidence of a significant interaction between overall satisfaction ratings and neighborhood walkability in predicting listing prices? If so, how do you interpret the interaction term coefficient?\n\n\n\nModel diagnostics\nThe process of performing model diagnostics for the random intercept models fitted in this lab is similar to the one described in the previous labs. Therefore, we refer to those labs for more detailed instructions on assessing model assumptions."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html",
    "href": "Assignments/Week 3/Assignment_week_3.html",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "",
    "text": "In this assignment, you will analyze a dataset collected by the Inner London Education Authority (ILEA) to examine the effectiveness of schools. The dataset consists of examination records of 15,362 students from 140 secondary schools over the years 1985, 1986, and 1987. This dataset was sourced from the data library of the Centre for Multilevel Modelling at the University of Bristol."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#introduction",
    "href": "Assignments/Week 3/Assignment_week_3.html#introduction",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "",
    "text": "In this assignment, you will analyze a dataset collected by the Inner London Education Authority (ILEA) to examine the effectiveness of schools. The dataset consists of examination records of 15,362 students from 140 secondary schools over the years 1985, 1986, and 1987. This dataset was sourced from the data library of the Centre for Multilevel Modelling at the University of Bristol."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#dataset-description",
    "href": "Assignments/Week 3/Assignment_week_3.html#dataset-description",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Dataset Description",
    "text": "Dataset Description\nThe dataset consists of the following variables:\n\nSchool: A numeric variable representing the school identifier (codes 1 to 139)\nExamScore: A numeric variable representing the exam score of each student\nPercentFSM: The percentage of students in the school eligible for free school meals (an indicator of socioeconomic status)\nGender: A categorical variable representing the gender of the student\nVRBand: The verbal reasoning band of the student (VR1, VR2, or VR3). VR band is an indicator of the student’s assessed ability level, with VR1 typically representing the highest ability group, VR2 representing intermediate ability, and VR3 representing lower ability.\nSchoolDenomination: The denomination of the school (Maintained, Church of England, Roman Catholic)"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#objective",
    "href": "Assignments/Week 3/Assignment_week_3.html#objective",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Objective",
    "text": "Objective\nYour goals are to determine:\n\nHow much of the variability in exam scores can be attributed to:\n\nDifferences between students\nDifferences between schools\n\nWhether individual-level factors (e.g., Gender, VRBand) significantly influence student exam scores\nWhether school-level factors (e.g., PercentFSM) significantly influence student exam scores"
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 3/Assignment_week_3.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Steps to Complete the Analysis",
    "text": "Steps to Complete the Analysis\n\nLoad the Dataset\nDownload the dataset (see link in the Downloads section below) and read it into R. Make sure all character variables are correctly encoded as factors.\n\n\nExploratory Data Analysis (EDA):\n\nVisualize the nesting structure of the data (i.e., number of students per school)\nExplore the distribution of the outcome variable (ExamScore)\n\n\n\nMulti-Level Modeling\n\nStart by fitting a null model (i.e., a random intercept model without any predictors) to partition the variance in exam scores between students and schools. Assess how much of the variability in exam scores is due to differences between students and schools.\nNext, add individual-level variables (Gender, VRBand) to the model to explore how these factors influence exam scores.\nAfter that, add context-level variables (e.g., PercentFSM) to your model to understand how factors at the school level contribute to differences in exam scores.\nFinally, explore potential cross-level interactions between individual-level and context-level variables.\n\n\n\nInterpret the Results\nInterpret the findings from your analysis, focusing on the variance components and the effects of individual-level and context-level variables."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#requirements-for-the-report",
    "href": "Assignments/Week 3/Assignment_week_3.html#requirements-for-the-report",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The HTML file should be rendered with code visibility enabled (echo = TRUE)."
  },
  {
    "objectID": "Assignments/Week 3/Assignment_week_3.html#downloads",
    "href": "Assignments/Week 3/Assignment_week_3.html#downloads",
    "title": "Assignment Week 3: Multilevel Analysis of School Effectiveness",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html",
    "href": "Assignments/Week 1/Assignment_week_1.html",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that examines the effect of different rehabilitation programs on the mobility of stroke patients. The dataset includes mobility improvement measurements taken using the 6-Minute Walk Test (6MWT), a standard assessment to evaluate physical mobility and endurance.\nPatients in the study were randomly assigned to one of three rehabilitation programs:\n\nControl: Standard physical therapy.\nRobotic-Assisted Therapy: Rehabilitation involving robotic devices designed to support movement.\nAquatic Therapy: Water-based exercises aimed at improving mobility with reduced joint stress."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#introduction",
    "href": "Assignments/Week 1/Assignment_week_1.html#introduction",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that examines the effect of different rehabilitation programs on the mobility of stroke patients. The dataset includes mobility improvement measurements taken using the 6-Minute Walk Test (6MWT), a standard assessment to evaluate physical mobility and endurance.\nPatients in the study were randomly assigned to one of three rehabilitation programs:\n\nControl: Standard physical therapy.\nRobotic-Assisted Therapy: Rehabilitation involving robotic devices designed to support movement.\nAquatic Therapy: Water-based exercises aimed at improving mobility with reduced joint stress."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#objective",
    "href": "Assignments/Week 1/Assignment_week_1.html#objective",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Objective",
    "text": "Objective\nYour objective is to determine whether there is a statistically significant difference in mobility improvement among the three rehabilitation groups. To complete this analysis, follow these steps:\n\nExplore the Data: Perform an exploratory data analysis (EDA) to understand the distribution of mobility improvements across treatment groups.\nFit a One-Way ANOVA Model: Fit a one-way ANOVA model to test for overall group differences.\nPost-Hoc Comparisons: If you identify significant group differences, calculate estimated marginal means and conduct post-hoc comparisons to determine which groups differ.\nModel Diagnostics: Conduct diagnostic tests and visualizations to evaluate model assumptions, including homoscedasticity and normality of residuals."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#requirements-for-the-report",
    "href": "Assignments/Week 1/Assignment_week_1.html#requirements-for-the-report",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The quarto source file should include all R code and annotations, and the html file should be rendered with code visibility enabled (echo = TRUE, which is the default option). The Quarto file in the downloads section below provides a starter template that you can use for this assignment."
  },
  {
    "objectID": "Assignments/Week 1/Assignment_week_1.html#downloads",
    "href": "Assignments/Week 1/Assignment_week_1.html#downloads",
    "title": "Assignment week 1: Effect of Rehabilitation Programs on Mobility in Stroke Patients",
    "section": "Downloads",
    "text": "Downloads\n\nDownload dataset\nDownload Quarto Template"
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html",
    "href": "Assignments/Week 2/Assignment_week_2.html",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that evaluates the effectiveness of different exercise routines on improving functional mobility in patients recovering from knee replacement surgery. The study uses a replicated randomized block design to account for individual variability among patients.\nEach patient participated in all three exercise routines, and each routine was performed three times. Functional mobility was assessed after each session, with scores ranging from 40 to 80 (higher scores indicate better mobility). The dataset contains 54 observations (6 patients x 3 routines x 3 replications) and is provided in the downloads section below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#introduction",
    "href": "Assignments/Week 2/Assignment_week_2.html#introduction",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "",
    "text": "In this assignment, you will analyze a dataset that evaluates the effectiveness of different exercise routines on improving functional mobility in patients recovering from knee replacement surgery. The study uses a replicated randomized block design to account for individual variability among patients.\nEach patient participated in all three exercise routines, and each routine was performed three times. Functional mobility was assessed after each session, with scores ranging from 40 to 80 (higher scores indicate better mobility). The dataset contains 54 observations (6 patients x 3 routines x 3 replications) and is provided in the downloads section below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#dataset-description",
    "href": "Assignments/Week 2/Assignment_week_2.html#dataset-description",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Dataset Description",
    "text": "Dataset Description\nThe dataset consists of the following variables:\n\nPatient: A numeric variable representing individual patients (blocks).\nExerciseRoutine: A factor variable representing the type of exercise routine:\n\nA: Low-impact walking exercises.\nB: Resistance training exercises.\nC: Balance and flexibility exercises.\n\nFunctionalMobility: A numeric variable (40-80) representing the mobility score measured after each session."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#objective",
    "href": "Assignments/Week 2/Assignment_week_2.html#objective",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Objective",
    "text": "Objective\nYour goal is to determine:\n\nWhether there are significant differences in functional mobility scores between the three exercise routines.\nHow much of the variability in mobility scores can be attributed to:\n\nDifferences between patients.\nDifferences between exercise routines.\nResidual variability (within patient-treatment combinations).\n\n\nTo complete this analysis, follow the detailed steps outlined below."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#steps-to-complete-the-analysis",
    "href": "Assignments/Week 2/Assignment_week_2.html#steps-to-complete-the-analysis",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Steps to Complete the Analysis",
    "text": "Steps to Complete the Analysis\n\n1. Load the dataset\nWhen loading the dataset in R, ensure that the ExerciseRoutine variable is treated as a factor. One way to achieve this is by specifying the column type explicitly using the colClasses argument in the read.csv() function. For example:\n\n# Load the dataset and specify ExerciseRoutine as a factor\ndataset &lt;- read.csv(\"functional_mobility.csv\", colClasses = c(\"ExerciseRoutine\" = \"factor\"))\n\n\n\n2. Perform an Exploratory Data Analysis (EDA)\n\nVisualize the data using an interaction plot.\nCalculate descriptive statistics for each exercise routine and patient.\n\n\n\n3. Fit a Mixed-Effects Model\n\nFit a mixed-effects model with:\n\nFixed Effects: ExerciseRoutine (to estimate differences between exercise routines).\nRandom Effects:\n\nPatient (to account for variability between individuals).\nPatient × ExerciseRoutine (to account for potential variability in how patients respond to different routines).\n\n\nTest whether the Patient × ExerciseRoutine random interaction term is necessary by comparing the full model (with the interaction term) to a reduced model (without the interaction term).\nBased on the results of this test:\n\nIf the interaction term is significant, proceed with the full model for further analysis.\nIf the interaction term is not significant, proceed with the reduced model.\n\nSummarize the chosen model:\n\nReport the fixed effects and variance components.\n\n\n\n\n4. Test for Overall Differences\n\nUse the selected model to test for overall differences in functional mobility scores across exercise routines.\n\n\n\n5. Perform Pairwise Comparisons\n\nIf significant overall differences are found, calculate estimated marginal means and perform pairwise comparisons to identify which routines differ.\n\n\n\n6. Evaluate Model Assumptions\n\nAssess the model’s assumptions (e.g., normality of residuals, homoscedasticity) using diagnostic plots."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#requirements-for-the-report",
    "href": "Assignments/Week 2/Assignment_week_2.html#requirements-for-the-report",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Requirements for the Report",
    "text": "Requirements for the Report\nSubmit both the Quarto source file (.qmd) and the rendered HTML file. The quarto source file should include all R code and annotations, and the html file should be rendered with code visibility enabled (echo = TRUE)."
  },
  {
    "objectID": "Assignments/Week 2/Assignment_week_2.html#downloads",
    "href": "Assignments/Week 2/Assignment_week_2.html#downloads",
    "title": "Assignment Week 2: Effectiveness of Exercise Routines on Functional Mobility",
    "section": "Downloads",
    "text": "Downloads\nDownload dataset"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html",
    "href": "BLR_lab_FE_oneway.html",
    "title": "Beyond MLR Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "Welcome to lab 1 of the Beyond MLR course. In this lab, we make use of the following R packages: gglot2, dplyr, and emmeans. You can use the script below to check if these packages are installed. Any missing packages can be installed using install.packages(\"package_name\").\npackages &lt;- c(\"dplyr\", \"ggplot2\", \"emmeans\")\n\ninstalled &lt;- sapply(packages, requireNamespace, quietly = TRUE)\nif (all(installed)) {\n  message(\"All packages are installed.\")\n} else {\n  missing &lt;- names(installed)[!installed]\n  message(\"The following packages are not installed: \", paste(missing, collapse = \", \"))\n}"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "href": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo understand the distribution of blood pressure reduction across treatment groups, we start by creating a boxplot:\n\n# Visualizing the results\nlibrary(ggplot2)\nggplot(data_oneway, aes(x = Treatment, y = BP_Reduction, fill = Treatment)) +\n  geom_boxplot() +\n  labs(title = \"Blood Pressure Reduction by Treatment\",\n       x = \"Treatment\", y = \"Blood Pressure Reduction (mm Hg)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\nWe also calculate some summary statistics:\n\n# Summarizing data\nlibrary(dplyr)\nsummary_stats &lt;- data_oneway %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_BP_Reduction = mean(BP_Reduction),\n    SD_BP_Reduction = sd(BP_Reduction)\n  )\n\nsummary_stats\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the mean blood pressure reductions compare among the treatment groups?"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "href": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "title": "Beyond MLR Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "Performing a One-Way ANOVA",
    "text": "Performing a One-Way ANOVA\n\nModel Specification\nUsing effects coding, the one-way Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The blood pressure reduction for the \\(j\\)-th patient in the \\(i\\)-th treatment group.\n\\(\\mu\\): The overall mean blood pressure reduction.\n\\(\\tau_i\\): The effect of the \\(i\\)-th treatment (deviation from the overall mean).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and constant variance.\n\n\n\n\n\n\n\nNote 1: Coding schemes for categorical variables\n\n\n\nIn regression models, categorical variables are represented using coding schemes that allow their inclusion as explanatory variables. In R, dummy coding is the default coding scheme for nominal variables, where each level is compared to a reference category. For ordinal variables (i.e., ordered factors), R uses orthogonal polynomials as the default coding scheme, which can capture linear or nonlinear trends across ordered levels.\nWhile dummy coding is widely used in multiple linear regression models, effects coding is more common in ANOVA models, as it enables interpretation of group differences relative to the grand mean rather than a single reference category. This interpretative difference makes effects coding particularly useful for examining group-level effects in experimental designs.\nTo change the coding scheme globally to effects coding:\n\n# Set contrasts to effects coding globally\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nTo reset the coding scheme to the default dummy coding:\n\n# Reset contrasts to default dummy coding\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))  # Dummy coding\n\n\n\n\n\nModel Estimation\nWe can fit the one-way ANOVA model using the lm() function:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\n# Fitting the model with effects coding\nmodel_oneway &lt;- lm(BP_Reduction ~ Treatment, data = data_oneway)\nsummary(model_oneway)\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated coefficients relate to the group means?\n\n\n\n\nANOVA Table\nTo test whether the effect of treatment is statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_oneway)\nanova_results\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\nEstimated Marginal Means\nEstimated marginal means, also known as least-squares means, are model-based means that represent the predicted (or expected) response at each level of a factor, averaged over the levels of other variables in the model.\nIn the context of a one-way ANOVA, where there is only one factor (e.g., treatment group), the estimated marginal means are equal to the observed group means. In more complex models with multiple factors, estimated marginal means provide predicted group means that are averaged over the levels of these additional factors. For example, in a model with both treatment and age as factors, the estimated marginal means for the treatment groups show the treatment means averaged over age, illustrating what these group means are expected to be at specific values of age (or averaged over a grid of age values).\nWe can calculate the estimated marginal means using the emmeans() function from the emmeans package:\n\n# Obtain estimated marginal means\nlibrary(emmeans)\nemms &lt;- emmeans(model_oneway, ~ Treatment)\nemms\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated marginal means compare to the observed group means calculated during the exploratory data analysis?\n\n\n\n\nPairwise comparisons\nSince we found a significant treatment effect, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another. We perform these pairwise comparisons using the contrast() function from the emmeans package. To account for the increased risk of Type I error due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled.\n\n# Performing post-hoc analysis with emmeans\ncontrast(emms, method=\"pairwise\", adjust=\"Bonferroni\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\nModel Diagnostics\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance) for the errors. A random scatter of residuals around zero indicates equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Residuals following the reference line suggest normally distributed errors.\n\n\n# Residuals vs Fitted\nplot(model_oneway, which = 1, main = \"Residuals vs Fitted\")\n\n# Normal Q-Q\nplot(model_oneway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html",
    "href": "BLR_lab_randomized_block.html",
    "title": "Beyond MLR Lab 3: Randomized Block Designs",
    "section": "",
    "text": "Suppose we are conducting an experiment to compare the effectiveness of three different wound healing treatments (Treatment A, Treatment B, and Treatment C) on cell cultures. The experimental units are the cell culture plates. To account for potential variability in laboratory conditions (such as humidity and temperature), we use a randomized block design, with laboratory facility as the blocking factor. Within each laboratory (block), the three treatments are randomly assigned to one cell culture plate each, ensuring that every treatment is represented once within each block. This design helps control for variability between laboratory facilities, allowing us to more effectively isolate the treatment effects.\n\n# Set seed for reproducibility\nset.seed(456)\n\n# Define blocks and treatments\nblocks &lt;- factor(paste0(\"Laboratory \", rep(1:5, each = 3)))  # Labs 1 to 5\ntreatments &lt;- factor(rep(c(\"A\", \"B\", \"C\"), times = 5))\n\n# Simulate data\nblock_effect &lt;- rnorm(5, mean = 0, sd = 2)  # Random effect for each block\ntreatment_effect &lt;- c(A = 5, B = 7, C = 6)  # Fixed effects for treatments\n\n# Create data frame\ndata_block &lt;- data.frame(\n  Laboratory = blocks,\n  Treatment = treatments,\n  WoundHealing = NA\n)\n\n# Assign responses\nfor (i in 1:nrow(data_block)) {\n  b &lt;- as.numeric(data_block$Laboratory[i])\n  t &lt;- data_block$Treatment[i]\n  data_block$WoundHealing[i] &lt;-\n    50 + block_effect[b] + treatment_effect[t] + rnorm(1, mean = 0, sd = 1)\n}\n\nThe R code chunk above simulates wound healing observations (measured on a continuous scale, where higher values indicate better healing) for 15 cell culture plates, divided across five laboratory facilities. The results are stored in the data frame data_block, which consists of the following three variables:\n\nLaboratory: A factor variable indicating the laboratory facility.\nTreatmment: A factor variable indicating the applied treatment.\nWoundHealing: A numeric variable representing the degree of wound healing on a continuous scale.\n\n\n\nTo explore the data and investigate the possible presence of a laboratory effect, we start by creating a scatter plot with the wound healing variable on the x-axis and the laboratory facility variable on the y-axis:\n\nlibrary(ggplot2)\nggplot(data_block, aes(x = WoundHealing, y = Laboratory, color = Treatment)) +\n  geom_point(size = 4) +\n  labs(title = \"Wound Healing by Treatment and Laboratory\",\n       x = \"Wound Healing Measure\",\n       y = \"Laboratory\") +\n  theme_minimal()\n\nIn addition to the scatter plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\nlibrary(dplyr)\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_block %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_block %&gt;%\n  group_by(Laboratory) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\nsummary_stats_laboratory\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment and laboratory based on the plot and summary statistics?\n\n\n\n\n\nIn a mixed-effects model, both fixed effects and random effects are used to account for different sources of variation.\nIn the wound healing example, it is essential to account for the laboratory facility because differences between laboratories (such as variations in environmental conditions) could influence the outcome. By including laboratory as a blocking variable, we can more efficiently estimate the treatment effects by controlling for this source of variability. This can be statistically achieved by modeling laboratory as either a fixed effect or a random effect.\nWhile we could model laboratory as a fixed effect, treating it as a random effect is preferred in this case for two reasons: first, it better reflects reality, as the laboratories are considered a random sample of possible laboratory conditions; second, it reduces the number of parameters we need to estimate, making the model more parsimonious. Modeling the lab as random allows us to account for variability between laboratories without estimating a separate effect for each one, which ultimately helps to isolate the treatment effects more effectively.\nOn the other hand, treatment is modeled as a fixed effect because we are specifically interested in estimating and comparing the effectiveness of the three particular wound healing treatments (Treatment A, Treatment B, and Treatment C). These treatments are not considered random samples from a larger population of treatments; rather, they are the specific interventions under study. By modeling treatment as a fixed effect, we aim to draw conclusions about the differences between these particular treatments, and their impact on wound healing.\n\n\nThe mixed-effects model for our randomized block design can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + b_j + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The observed wound healing response for treatment \\(i\\) in laboratory \\(j\\).\n\\(\\mu\\): The overall mean response across all treatments and laboratories.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\), representing the deviation of treatment \\(i\\) from the overall mean \\(\\mu\\).\n\\(b_j\\): The random effect of laboratory \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\)).\n\\(\\epsilon_{ij}\\): The error term, assumed to be normally distributed with mean zero and variance \\(\\sigma^2\\).\n\n\n\n\nWe previously mentioned that the lme4 package does not provide p-values for the fixed effect estimates. One way around this is to fit the mixed effects model using the lmer() function from the lmeTest package, which extends to original lmer() function from the lme4 to include p-values for the fixed effect estimates. The lmerTest package achieves this by applying Satterthwaite’s approximation to calculate degrees of freedom, which are then used to derive the p-values.\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_block)\nsummary(model_block)\n\n\n\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory)\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments. Note that the intercept is included by default in the model, so WoundHealing ~ Treatment is essentially a shortcut for WoundHealing ~ 1 + Treatment. Also remember that with effects coding, the intercept represents the overall mean across all levels of the treatment variable, and the treatment coefficients represent deviations from this mean.\n(1 | Laboratory): This specifies the random effect for Laboratory, representing laboratory-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_block), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean wound healing score averaged across all treatments and laboratories.\nTreatment: The differences in wound healing associated with each treatment relative to the overall mean.\n\nRandom Effects: Estimates of the variance components\n\nLaboratory - Intercept: Between-laboratory variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nCaution: Interpreting p-values in Mixed Effects Models\n\n\n\nWhile the lmerTest package provides p-values for fixed effects, it is important to use them with caution, primarily because methods for calculating degrees of freedom, such as Satterthwaite, are approximations that may not always be reliable, particularly in complex models fitted to imbalanced data. Generally, this sensitivity is not a concern for the randomized block design considered in this lab.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of laboratory variability and residual error to the total variability in wound healing?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsidering these results, do you think that blocking by laboratory was necessary for this experiment?\n\n\n\n\n\nIn addition to providing p-values for the fixed effects estimates, the lmerTest package also implements the anova() function to test the overall significance of fixed effects in the model. Additionally, the ls_means() function can be used to calculate the estimated marginal means for the factors (i.e., variables that are defined as factors in the data frame or the model formula) included in the fixed effects structure of the model. Alternatively, these estimated marginal means can be calculated using the emmeans() function from the emmeans package, which provides more options and greater flexibility for advanced users.\n\n# Obtain ANOVA table for the fixed effects\nanova(model_block)\n\n# Calculate estimated marginal means for the Treatment variable\nls_means(model_block)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow to the estimated marginal means compare to the observed group means from the exploratory data analysis?\n\n\n\n\nSince we found a significant treatment effect, we proceed with computing pairwise differences of the estimated marginal means. This can be achieved by adding the argument pairwise=TRUE to the call to the ls_means() function. Unlike the emmmeans package, there is no multiplicity correction for pairwise comparisons in the lmerTest package. We therefore use the p.adjust() function from the base R stats package to compute the Bonferroni corrected p-values (i.e., the original p-values multiplied by the number of comparisons).\n\n# Compute pairwise differences of the estimated marginal means \nemms &lt;- ls_means(model_block, pairwise=TRUE)\nemms\n\n# Retrieve the p-values from the emms object and adjust them \n# for multiple testing using the Bonferroni correction\np.adjust(emms$`Pr(&gt;|t|)`, method=\"bonferroni\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\n\nSimilar as in the previous lab, we will inspect the conditional residuals to check the model assumptions regarding the error term:\n\n# Extract conditional residuals\nresiduals_cond &lt;- resid(model_block)\n\n# Residuals vs Fitted\nplot(fitted(model_block), residuals_cond,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond)\nqqline(residuals_cond, col = \"red\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 3: Randomized Block Designs",
    "section": "",
    "text": "To explore the data and investigate the possible presence of a laboratory effect, we start by creating a scatter plot with the wound healing variable on the x-axis and the laboratory facility variable on the y-axis:\n\nlibrary(ggplot2)\nggplot(data_block, aes(x = WoundHealing, y = Laboratory, color = Treatment)) +\n  geom_point(size = 4) +\n  labs(title = \"Wound Healing by Treatment and Laboratory\",\n       x = \"Wound Healing Measure\",\n       y = \"Laboratory\") +\n  theme_minimal()\n\nIn addition to the scatter plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\nlibrary(dplyr)\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_block %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_block %&gt;%\n  group_by(Laboratory) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\nsummary_stats_laboratory\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment and laboratory based on the plot and summary statistics?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "href": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "title": "Beyond MLR Lab 3: Randomized Block Designs",
    "section": "",
    "text": "In a mixed-effects model, both fixed effects and random effects are used to account for different sources of variation.\nIn the wound healing example, it is essential to account for the laboratory facility because differences between laboratories (such as variations in environmental conditions) could influence the outcome. By including laboratory as a blocking variable, we can more efficiently estimate the treatment effects by controlling for this source of variability. This can be statistically achieved by modeling laboratory as either a fixed effect or a random effect.\nWhile we could model laboratory as a fixed effect, treating it as a random effect is preferred in this case for two reasons: first, it better reflects reality, as the laboratories are considered a random sample of possible laboratory conditions; second, it reduces the number of parameters we need to estimate, making the model more parsimonious. Modeling the lab as random allows us to account for variability between laboratories without estimating a separate effect for each one, which ultimately helps to isolate the treatment effects more effectively.\nOn the other hand, treatment is modeled as a fixed effect because we are specifically interested in estimating and comparing the effectiveness of the three particular wound healing treatments (Treatment A, Treatment B, and Treatment C). These treatments are not considered random samples from a larger population of treatments; rather, they are the specific interventions under study. By modeling treatment as a fixed effect, we aim to draw conclusions about the differences between these particular treatments, and their impact on wound healing.\n\n\nThe mixed-effects model for our randomized block design can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + b_j + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The observed wound healing response for treatment \\(i\\) in laboratory \\(j\\).\n\\(\\mu\\): The overall mean response across all treatments and laboratories.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\), representing the deviation of treatment \\(i\\) from the overall mean \\(\\mu\\).\n\\(b_j\\): The random effect of laboratory \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\)).\n\\(\\epsilon_{ij}\\): The error term, assumed to be normally distributed with mean zero and variance \\(\\sigma^2\\).\n\n\n\n\nWe previously mentioned that the lme4 package does not provide p-values for the fixed effect estimates. One way around this is to fit the mixed effects model using the lmer() function from the lmeTest package, which extends to original lmer() function from the lme4 to include p-values for the fixed effect estimates. The lmerTest package achieves this by applying Satterthwaite’s approximation to calculate degrees of freedom, which are then used to derive the p-values.\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_block)\nsummary(model_block)\n\n\n\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory)\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments. Note that the intercept is included by default in the model, so WoundHealing ~ Treatment is essentially a shortcut for WoundHealing ~ 1 + Treatment. Also remember that with effects coding, the intercept represents the overall mean across all levels of the treatment variable, and the treatment coefficients represent deviations from this mean.\n(1 | Laboratory): This specifies the random effect for Laboratory, representing laboratory-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_block), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean wound healing score averaged across all treatments and laboratories.\nTreatment: The differences in wound healing associated with each treatment relative to the overall mean.\n\nRandom Effects: Estimates of the variance components\n\nLaboratory - Intercept: Between-laboratory variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nCaution: Interpreting p-values in Mixed Effects Models\n\n\n\nWhile the lmerTest package provides p-values for fixed effects, it is important to use them with caution, primarily because methods for calculating degrees of freedom, such as Satterthwaite, are approximations that may not always be reliable, particularly in complex models fitted to imbalanced data. Generally, this sensitivity is not a concern for the randomized block design considered in this lab.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of laboratory variability and residual error to the total variability in wound healing?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsidering these results, do you think that blocking by laboratory was necessary for this experiment?\n\n\n\n\n\nIn addition to providing p-values for the fixed effects estimates, the lmerTest package also implements the anova() function to test the overall significance of fixed effects in the model. Additionally, the ls_means() function can be used to calculate the estimated marginal means for the factors (i.e., variables that are defined as factors in the data frame or the model formula) included in the fixed effects structure of the model. Alternatively, these estimated marginal means can be calculated using the emmeans() function from the emmeans package, which provides more options and greater flexibility for advanced users.\n\n# Obtain ANOVA table for the fixed effects\nanova(model_block)\n\n# Calculate estimated marginal means for the Treatment variable\nls_means(model_block)\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow to the estimated marginal means compare to the observed group means from the exploratory data analysis?\n\n\n\n\nSince we found a significant treatment effect, we proceed with computing pairwise differences of the estimated marginal means. This can be achieved by adding the argument pairwise=TRUE to the call to the ls_means() function. Unlike the emmmeans package, there is no multiplicity correction for pairwise comparisons in the lmerTest package. We therefore use the p.adjust() function from the base R stats package to compute the Bonferroni corrected p-values (i.e., the original p-values multiplied by the number of comparisons).\n\n# Compute pairwise differences of the estimated marginal means \nemms &lt;- ls_means(model_block, pairwise=TRUE)\nemms\n\n# Retrieve the p-values from the emms object and adjust them \n# for multiple testing using the Bonferroni correction\np.adjust(emms$`Pr(&gt;|t|)`, method=\"bonferroni\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\n\nSimilar as in the previous lab, we will inspect the conditional residuals to check the model assumptions regarding the error term:\n\n# Extract conditional residuals\nresiduals_cond &lt;- resid(model_block)\n\n# Residuals vs Fitted\nplot(fitted(model_block), residuals_cond,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond)\nqqline(residuals_cond, col = \"red\")\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "BLR_lab_RE_oneway.html",
    "href": "BLR_lab_RE_oneway.html",
    "title": "Beyond MLR Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "Welcome to lab 2 of the Beyond MLR course. In this lab, we make use of the following R packages: gglot2, dplyr, emmeans, and lme4. You can use the script below to check if these packages are installed. Any missing packages can be installed using install.packages(\"package_name\").\npackages &lt;- c(\"dplyr\", \"ggplot2\", \"emmeans\", \"lme4\")\n\ninstalled &lt;- sapply(packages, requireNamespace, quietly = TRUE)\nif (all(installed)) {\n  message(\"All packages are installed.\")\n} else {\n  missing &lt;- names(installed)[!installed]\n  message(\"The following packages are not installed: \", paste(missing, collapse = \", \"))\n}"
  },
  {
    "objectID": "BLR_lab_RE_oneway.html#exploratory-data-analysis",
    "href": "BLR_lab_RE_oneway.html#exploratory-data-analysis",
    "title": "Beyond MLR Lab 2: Random Effects Model for the One-Way Layout",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nBefore modeling, it’s important to visualize and summarize the data to identify any trends, patterns, or anomalies that may impact the analysis. In this case, we aim to explore the variability in waist circumference measurements across nurses and assess the consistency of these measurements.\nWe’ll use two main approaches:\n\nVisualizing the data: A boxplot will be created to compare waist circumference measurements across nurses, highlighting differences in measurement tendencies or variability.\nSummarizing the data: Summary statistics (mean and standard deviation) will be computed for each nurse, providing a numerical overview of central tendency and spread for the measurements.\n\n\n# Create a boxplot\nlibrary(ggplot2)\nggplot(data_waist_circumference, aes(x = Nurse, y = Waist_Circumference, fill = Nurse)) +\n  geom_boxplot() +\n  labs(title = \"Waist Circumference Measurements by Nurse\",\n       x = \"Nurse\", y = \"Waist Circumference (cm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n# Calculate summary statistics\nlibrary(dplyr)\nsummary_stats_random &lt;- data_waist_circumference %&gt;%\n  group_by(Nurse) %&gt;%\n  summarise(\n    Mean_Waist = mean(Waist_Circumference),\n    SD_Waist = sd(Waist_Circumference)\n  )\n\nsummary_stats_random\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the boxplot and summary statistics, do you observe any systematic differences in waist circumference measurements across the nurses? If so, describe the differences and what they might suggest about the measurements."
  },
  {
    "objectID": "BLR_lab_RE_oneway.html#random-effects-model-for-the-one-way-layout",
    "href": "BLR_lab_RE_oneway.html#random-effects-model-for-the-one-way-layout",
    "title": "Beyond MLR Lab 2: Random Effects Model for the One-Way Layout",
    "section": "Random Effects Model for the One-Way Layout",
    "text": "Random Effects Model for the One-Way Layout\nA random effects model represents variations assumed to arise from a larger population. Unlike fixed effects, which estimate specific differences between levels of a factor, random effects account for variability among factor levels by treating them as random samples from a broader population.\nIn the waist circumference example, the four nurses can be considered a random sample from a larger population of nurses. By modeling “Nurse” as a random effect, we aim to generalize the findings about measurement variability to the broader population of nurses, rather than focusing solely on the four in the study.\n\nModel Specification\nThe random effects model can be specified as:\n\\[\nY_{ij} = \\mu + b_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The waist circumference measurement for the \\(j\\)-th observation by the \\(i\\)-th nurse.\n\\(\\mu\\): The overall mean waist circumference.\n\\(b_i\\): The random effect of the \\(i\\)-th nurse, assumed to be normally distributed with mean zero and variance \\(\\sigma^2_{b}\\).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and variance \\(\\sigma^2\\).\n\nThe use of random effects allows us to decompose the total variance in the outcome variable into distinct components, each associated with a different source of variation. In this example, the total variance in waist circumference measurements is split into two variance components:\n\nBetween-nurse variability (\\(\\sigma^2_{b}\\)): This component, represented by the variance of the random effect \\(b_{i}\\), captures the variability in waist circumference measurements attributable to differences among nurses. It reflects how much of the overall variability is due to systematic differences in measurement techniques or practices between nurses.\nResidual variance (\\(\\sigma^2\\)): This component, represented by the variance of the error term \\(\\epsilon_{ij}\\), captures the variability in waist circumference measurements that remains unexplained by nurse-related differences. It includes measurement error, patient-specific factors, and other unmeasured sources of variation.\n\n\n\n\n\n\n\nNotation convention\n\n\n\nIn mixed-effects models, fixed effects are typically represented by Greek letters, while random effects are represented by Roman letters. This helps differentiate between the two types of effects in model specification.\n\n\n\nIntraclass Correlation Coefficient\nThe Intraclass Correlation Coefficient (ICC) is a statistical measure that quantifies the proportion of the total variance in the outcome variable that can be attributed to differences between groups. In this context, the ICC measures the extent to which waist circumference measurements are more similar when taken by the same nurse (within-group), compared to the overall variability across all nurses (between-group). In other words, it tells us how strongly measurements are correlated within the same group.\nMathematically, the ICC is calculated as:\n\\[\nICC = \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2}\n\\]\nInterpretation of ICC:\n\nICC \\(\\approx\\) 0: Indicates that nearly all the variability in waist circumference measurements is due to residual factors (such as patient differences or measurement error). This suggests that nurse-level differences contribute minimally to the total variability, implying a high degree of consistency across nurses in their measurement practices.\nICC \\(\\approx\\) 1: Indicates that nearly all the variability is attributable to differences between nurses. This suggests substantial between-nurse variability, meaning different nurses consistently record different waist circumference measurements.\n\n\n\n\nModel Estimation\nWe will fit the random effects model using the lmer() function from the lme4 package.\n\n# Fitting the random effects model\nlibrary(lme4)\nmodel_random &lt;- lmer(Waist_Circumference ~ 1 + (1 | Nurse), data = data_waist_circumference)\nsummary(model_random)\n\n\nSyntax overview\nLet’s break down the model formula Waist_Circumference ~ 1 + (1 | Nurse)\n\nWaist_Circumference ~ 1: This specifies that Waist_Circumference is the outcome variable and that the fixed effects structure consists of a single intercept, modeled by the term 1, that represents the overall mean waist circumference across all nurses.\n(1 | Nurse): This specifies the random effect for Nurse, representing nurse-specific deviations from the overall mean.\n\n\n\nSummary overview\nWhen you run summary(model_random), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean waist circumference across all nurses.\n\nRandom Effects: Estimates of the two variance components\n\nNurse - Intercept: Between-nurse variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nNo p-values\n\n\n\nThe lme4 package does not provide p-values for fixed effect estimates. This is a deliberate choice by the package authors, based on concerns about the appropriateness of traditional hypothesis testing methods in the context of mixed effects models. In subsequent labs, we will use of the lmerTest package to calculate these p-values and add them to the summary output.\n\n\n\n\n\nAssessing the variance components\n\n\n\n\n\n\nQuestion\n\n\n\nWhat proportion of the total variance is attributable to nurse differences (i.e., what is the value of the ICC)?\n\n\n\n\nModel Diagnostics\nIn mixed-effects models, model diagnostics involve analyzing different types of residuals to evaluate how well the model fits the data and to assess whether key assumptions are satisfied.\nThe default type of residuals used in these models are the conditional residuals, which are calculated based on predicted values that incorporate both fixed effects and estimated random effects. Conditional residuals represent the deviation of the observed data from the model’s predictions, accounting for variability from both sources: fixed effects and random effects. They can be considered estimates of the errors \\(\\epsilon_{ij}\\), which are assumed to be normally distributed with a mean of zero and constant variance.\nTo check these assumptions, we can generate diagnostic plots similar to those used in linear regression models:\n\nResiduals vs. Fitted Plot: This plot helps check for homoscedasticity (constant variance).\nNormal Q-Q Plot: This plot assesses whether the residuals follow a normal distribution.\n\n\n# Extract conditional residuals and predicted values\nresiduals_model_random &lt;- resid(model_random)\nfitted_model_random &lt;- fitted(model_random)\n\n# Residuals vs Fitted\nggplot(data.frame(Fitted = fitted_model_random, Residuals = residuals_model_random), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n# Normal Q-Q\nqqnorm(residuals_model_random, main = \"Normal Q-Q\")\nqqline(residuals_model_random)\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  }
]