[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R labs for the Beyond MLR course",
    "section": "",
    "text": "This website hosts the R labs for the beyond MLR course. You can navigate between the different labs using the menu above."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html",
    "href": "BLR_lab_replicated_randomized_block.html",
    "title": "Beyond Linear Regression Lab 4: Replicated Randomized Block Designs",
    "section": "",
    "text": "In the previous lab, we considered a traditional randomized block design without replication, where each treatment was applied once within each block (laboratory). This design allowed us to control for variability between laboratories and efficiently estimate the main effects of the treatments. However, a key limitation of this approach is that it does not allow us to assess whether the treatment effects vary across blocks, a concept known as interaction.\nThe lack of replication in the traditional design means we can only test for main effects of the treatments and laboratories, but not whether the effectiveness of a treatment depends on the specific laboratory conditions. For example, a treatment might work well in one laboratory but not in another due to environmental differences (e.g., humidity or temperature), indicating a treatment-by-laboratory interaction.\nAn interaction occurs when the effect of one factor (e.g., treatment) is not consistent across levels of another factor (e.g., laboratory). In other words, the effect of a treatment might vary depending on the laboratory conditions. Replicating the treatments within each block allows us to estimate these interaction effects and better understand the variability in treatment outcomes across different settings.\nIn this lab, we introduce replication within blocks, allowing us to estimate the variability within treatment-block combinations and assess whether treatment effects are consistent across blocks."
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_replicated_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond Linear Regression Lab 4: Replicated Randomized Block Designs",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo explore the data and investigate the presence of a potential interaction between treatments and laboratories, we create an interaction plot. An interaction plot is a graphical tool that helps visualize whether the effect of one factor (in this case, treatment) depends on the levels of another factor (in this case, laboratory). Specifically, it shows how the mean response (wound healing) for each treatment varies across different laboratories. If the lines on the interaction plot are parallel, this suggests there is no interaction, meaning the treatment effect is consistent across laboratories. If the lines are not parallel, this indicates a potential interaction, meaning the effect of treatment differs depending on the laboratory.\n\n# Calculate mean Wound Healing for each Treatment-Labortory combination\nlibrary(dplyr)\nmean_data &lt;- data_rep_block %&gt;%\n  group_by(Laboratory, Treatment) %&gt;%\n  summarise(Mean_WoundHealing = mean(WoundHealing))\n\n# Display the produced summary table with the group means\nmean_data\n\n# A tibble: 15 × 3\n# Groups:   Laboratory [5]\n   Laboratory   Treatment Mean_WoundHealing\n   &lt;fct&gt;        &lt;fct&gt;                 &lt;dbl&gt;\n 1 Laboratory 1 A                      55.0\n 2 Laboratory 1 B                      56.2\n 3 Laboratory 1 C                      55.5\n 4 Laboratory 2 A                      55.5\n 5 Laboratory 2 B                      57.0\n 6 Laboratory 2 C                      56.1\n 7 Laboratory 3 A                      57.7\n 8 Laboratory 3 B                      61.3\n 9 Laboratory 3 C                      57.4\n10 Laboratory 4 A                      54.1\n11 Laboratory 4 B                      56.8\n12 Laboratory 4 C                      57.3\n13 Laboratory 5 A                      54.9\n14 Laboratory 5 B                      56.3\n15 Laboratory 5 C                      56.1\n\n# Create an interaction plot\nlibrary(ggplot2)\nggplot(mean_data, aes(x = Treatment, y = Mean_WoundHealing, group = Laboratory, color = Laboratory)) +\n  geom_point(size = 3) +\n  geom_line() +\n  labs(title = \"Interaction Plot\",\n       y = \"Mean Wound Healing Measure\",\n       x = \"Treatment\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDoes the interaction plot indicate a potential interaction between treatment and laboratory?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDoes the plot suggest any differences in the overall effectiveness of the treatments (i.e., main effect of treatment) across all laboratories?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the plot suggest about variability between laboratories? Are some laboratories consistently higher or lower in wound healing across all treatments?"
  },
  {
    "objectID": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "href": "BLR_lab_replicated_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "title": "Beyond Linear Regression Lab 4: Replicated Randomized Block Designs",
    "section": "A Mixed Effects Model for the Randomized Block Design",
    "text": "A Mixed Effects Model for the Randomized Block Design\nSimilar to the previous lab, laboratory is included as a random effect and treatment as a fixed effect in the model. The key new feature is the treatment-by-laboratory interaction term, which is also modeled as a random effect.\nTo understand why the interaction term must also be modeled as random, we need to consider the nature of random effects in this context. Since laboratory is treated as a random effect, we are assuming that the laboratories in the experiment represent a random sample from a larger population of possible laboratory conditions. This means that we are not just interested in the specific laboratories in the study, but in how the treatments would perform across any set of laboratories with varying conditions.\nWhen we include an interaction term between treatment and laboratory, we are asking whether the effect of each treatment depends on the laboratory environment. If we had modeled laboratory as a fixed effect (i.e., we were only interested in those specific laboratories), the interaction could also be treated as fixed. However, because laboratory is random, the interaction must also be treated as random to reflect the idea that the variability in treatment effects across laboratories applies not just to the specific laboratories in the study, but to any laboratory from the broader population.\nIn other words, by modeling the interaction as random, we are assuming that the variation in treatment effects is not unique to the five laboratories in the study, but rather represents random fluctuations in treatment effectiveness that could occur in any laboratory setting. This approach allows us to generalize our findings beyond the laboratories in the experiment, making the model more realistic and applicable to a wider range of scenarios.\n\nModel Specification\nThe mixed-effects model for the replicated randomized block design is specified as:\n\\[\nY_{ijk} = \\mu + \\tau_i + b_j + (tb)_{ij} + \\epsilon_{ijk}\n\\]\nwhere:\n\n\\(Y_{ijk}\\): Response (wound healing) for the \\(k\\)-tjh replicate of Treatment \\(i\\) in Laboratory \\(j\\).\n\\(\\mu\\): Overall mean response\n\\(\\tau_{i}\\): Fixed effect of Treatment \\(i\\).\n\\(b_{j}\\):Random effect of Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{b}\\).\n\\((tb)_{ij}\\): Random interaction effect between treatment \\(i\\) and Laboratory \\(j\\), assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2_{tb}\\).\n\\(\\epsilon_{ijk}\\): Random error term, assumed to follow a normal distribution with mean zero and variance \\(\\sigma^2\\).\n\n\n\nModel Estimation\nSimilar as in the previous lab, we fit the mixed effects model using the lmer() function from the lmeTest package:\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory), data = data_rep_block)\nsummary(model_block)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \nWoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory)\n   Data: data_rep_block\n\nREML criterion at convergence: 98.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.4134 -0.4515 -0.1989  0.4962  2.3865 \n\nRandom effects:\n Groups               Name        Variance Std.Dev.\n Treatment:Laboratory (Intercept) 0.4747   0.6890  \n Laboratory           (Intercept) 1.4462   1.2026  \n Residual                         0.9089   0.9533  \nNumber of obs: 30, groups:  Treatment:Laboratory, 15; Laboratory, 5\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  56.4744     0.5926  4.0000  95.297 7.27e-08 ***\nTreatment1   -1.0438     0.3520  8.0000  -2.966   0.0180 *  \nTreatment2    1.0306     0.3520  8.0000   2.928   0.0191 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) Trtmn1\nTreatment1  0.000       \nTreatment2  0.000 -0.500\n\n\n\nSyntax overview\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory):\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments.\n(1 | Laboratory): This specifies the random effect for laboratory, representing laboratory-specific deviations from the overall mean.\n(1 | Treatment:Laboratory): This specifies the random interaction term between Treatment and Laboratory.\n\n\n\nSummary overview\nWhen we run summary(model_random), the following output is displayed:\n\nFixed Effects\n\nThe intercept represents the overall mean wound healing measure across all treatments and laboratories, which is estimated as 56.47.\nThe coefficient for Treatment1 (-1.04) indicates that the mean wound healing for Treatment A is 1.04 units lower than the overall mean.\nThe coefficient for Treatment2 (1.03) shows that the mean wound healing for Treatment B is 1.03 units higher than the overall mean.\nTreatment C is not directly shown in the output because, with effects coding, the sum of the treatment coefficients must equal zero. Treatment C can be inferred as having a mean very close to the overall mean (around 0.01 units below it).\n\n\n\n\nVariance components\n\nThe random effect for Laboratory has a variance of 1.4462, indicating considerable variability in baseline wound healing levels across different laboratories.\nThe random effect for the Treatment-by-Laboratory Interaction has a variance of 0.4747, showing that the treatment effects vary across laboratories. This means the effectiveness of treatments is not entirely consistent across laboratories, though the variability in this interaction is smaller compared to the variability between laboratory baselines and may not be statistically significant (more about that later).\nThe residual variance is 0.9089, which represents the unexplained variability within each treatment-laboratory combination.\n\n\n\n\n\nAssessing the variance components\nIn our model, the treatment-by-laboratory interaction is modeled as a random effect. To determine whether this variance component is necessary, we perform a likelihood ratio test to compare the full model (i.e., the previously fitted model with both the random laboratory effect and the random treatment-by-laboratory interaction effect) to a reduced model that includes only the random laboratory effect:\n\n# Fit the full model with the random interaction term\nfull_model &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory), \n                   data = data_rep_block)\n\n# Fit the reduced model without the random interaction term\nreduced_model &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), \n                      data = data_rep_block)\n\n# Perform the likelihood ratio test\nanova(full_model, reduced_model, refit=FALSE)\n\nData: data_rep_block\nModels:\nreduced_model: WoundHealing ~ Treatment + (1 | Laboratory)\nfull_model: WoundHealing ~ Treatment + (1 | Laboratory) + (1 | Treatment:Laboratory)\n              npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)\nreduced_model    5 110.08 117.08 -50.038   100.08                     \nfull_model       6 110.67 119.08 -49.335    98.67 1.4068  1     0.2356\n\n\nWhen given two or more arguments representing fitted models, the anova() function from the lmerTest package produces likelihood ratio tests to compare these models. By default, these models are refitted using maximum likelihood (ML) estimation, which is suitable for testing fixed effects but not ideal for testing random effects. Random effects are better assessed using restricted maximum likelihood (REML).\nTo keep the REML estimation intact for testing random effects, we use the refit=FALSE argument in the anova() function. This ensures that the models are compared without being refitted using ML.\nThe output provides the likelihood ratio test statistic and p-value, indicating whether the random interaction term significantly improves the model fit.\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the likelihood ratio test, is it necessary to include the random interaction term in the model, or is the simpler model (without the interaction term) sufficient?\n\n\n\n\n\n\n\n\nMaximum Likelihood (ML) versus Restricted Maximum Likelihood (REML) estimation\n\n\n\n\n\n\nMaximum Likelihood (ML): This method estimates all model parameters simultaneously, including both fixed and random effects. It provides unbiased estimates for fixed effects but can lead to biased estimates of the variance components.\nRestricted Maximum Likelihood (REML): REML focuses on estimating variance components while accounting for the loss of degrees of freedom associated with fixed effects. This method provides more accurate estimates of random effects.\n\nEstimates of the fixed effects parameters are generally comparable between ML and REML. However, variance component estimates will typically be larger with REML given that the method was developed to overcome the downward bias of the maximum likelihood estimates of variance components. For this reason, REML is the default estimation approach when fitting mixed effects models with the lmer() function. However, there are also situations where REML cannot be used, particularly during the model-building phase when comparing models with different fixed effects structures. In these cases, the models need to be refitted using ML.\n\n\n\n\n\nAssessing the fixed effects\nThe fixed effects can be assessed using an approach similar to that used in the previous lab. This includes testing for the overall significance of the treatment effect and, if significant, exploring the differences between specific treatment groups through estimated marginal means and pairwise comparisons.\nHowever, before performing these tests, we need to determine which model to use: the full model with the random interaction term or the reduced model without it. This choice is based on the results of the likelihood ratio test performed earlier. If the likelihood ratio test indicates that the random interaction term is necessary, we will use the full model for testing the fixed effects. Conversely, if the likelihood ratio test suggests that the random interaction term is unnecessary, we will use the simpler model without it. This aligns with the general scientific principle of preferring more parsimonious models that adequately explain the data while minimizing complexity.\n\n\nModel diagnostics\nThe process of performing model diagnostics for the replicated randomized block design is the same as for the traditional randomized block design. Therefore, we refer to the previous lab for detailed instructions on assessing model assumptions and performing diagnostic checks."
  },
  {
    "objectID": "BLR_lab_FE_oneway.html",
    "href": "BLR_lab_FE_oneway.html",
    "title": "Beyond Linear Regression Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "In this lab, we will examine the effect of three different drug treatments (Control, Drug A, and Drug B) on blood pressure reduction in patients. The data for this example are hypothetical and will be created through simulation:\n\n# Generating data for the single-factor experimental design\nset.seed(123)\ncontrol &lt;- rnorm(40, mean = 2, sd = 10)\ndrugA &lt;- rnorm(40, mean = 20, sd = 10)\ndrugB &lt;- rnorm(40, mean = 5, sd = 10)\n\n# Combining data into a data frame\ndata_oneway &lt;- data.frame(\n  Treatment = factor(rep(c(\"Control\", \"DrugA\", \"DrugB\"), each = 40),\n                     levels = c(\"Control\", \"DrugA\", \"DrugB\")),\n  BP_Reduction = c(control, drugA, drugB)\n)\n\nThe above R chunk simulates hypothetical results for 120 parients (40 per treatment group) and stores the results in the data frame data_oneway that consists of the following two columns:\n\nTreatment: Factor variable indicating the treatment group.\nBP_Reduction: Numeric variable representing blood pressure reduction (in mm Hg).\n\n\n\nTo understand the distribution of blood pressure reduction across treatment groups, we start by creating a boxplot:\n\n# Visualizing the results\nlibrary(ggplot2)\nggplot(data_oneway, aes(x = Treatment, y = BP_Reduction, fill = Treatment)) +\n  geom_boxplot() +\n  labs(title = \"Blood Pressure Reduction by Treatment\",\n       x = \"Treatment\", y = \"Blood Pressure Reduction (mm Hg)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nWe also calculate some summary statistics:\n\n# Summarizing data\nlibrary(dplyr)\nsummary_stats &lt;- data_oneway %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_BP_Reduction = mean(BP_Reduction),\n    SD_BP_Reduction = sd(BP_Reduction)\n  )\n\nsummary_stats\n\n# A tibble: 3 × 3\n  Treatment Mean_BP_Reduction SD_BP_Reduction\n  &lt;fct&gt;                 &lt;dbl&gt;           &lt;dbl&gt;\n1 Control                2.45            8.98\n2 DrugA                 19.9             9.60\n3 DrugB                  5.08            8.44\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the mean blood pressure reductions compare among the treatment groups?\n\n\n\n\n\n\n\nUsing effects coding, the one-way Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The blood pressure reduction for the \\(j\\)-th patient in the \\(i\\)-th treatment group.\n\\(\\mu\\): The overall mean blood pressure reduction.\n\\(\\tau_i\\): The effect of the \\(i\\)-th treatment (deviation from the overall mean).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and constant variance.\n\n\n\n\n\n\n\nUnderstanding Coding Schemes\n\n\n\n\n\nIn regression models, categorical variables are represented using coding schemes. Two common coding schemes are:\n\n\n\n\n\nCompares each level of the factor to a reference level.\nIn R, this is the default coding scheme.\nThe first category is used as the reference level (unless specified otherwise).\nThe intercept represents the mean of the reference group.\nCoefficients represent differences from the reference group.\n\n\n\n\n\n\n\nLevel\nDummy Variable for B\nDummy Variable for C\n\n\n\n\nA\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\n\n\nInterpretation:\n\nIntercept: Mean of the reference group (A).\nCoefficient for B: Difference between mean of group A and group B.\nCoefficient for C: Difference between mean of group A and group C.\n\n\n\n\n\n\n\n\n\nCompares each level of the factor to the overall mean.\nThe sum of the coefficients equals zero.\nThe intercept represents the overall mean.\nCoefficients represent deviations from the overall mean.\n\n\n\n\n\n\n\nLevel\nEffects Code for A\nEffects Code for B\n\n\n\n\nA\n1\n0\n\n\nB\n0\n1\n\n\nC\n-1\n-1\n\n\n\n\nInterpretation:\n\nIntercept: Overall mean of all groups.\nCoefficient for A: Deviation of group A’s mean from the overall mean.\nCoefficient for B: Deviation of group B’s mean from the overall mean.\nCoefficient for C: Can be calculated as \\(-(\\beta_{\\text{A}} + \\beta_{\\text{B}})\\) since the sum of coefficients is zero.\n\n\n\n\n\n\nTo change the coding scheme globally to effects coding:\n\n# Set contrasts to effects coding globally\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nTo reset the coding scheme to the default dummy coding:\n\n# Reset contrasts to default dummy coding\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))  # Dummy coding\n\n\n\n\n\n\n\n\nWe can fit the one-way ANOVA model using the lm() function:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\n# Fitting the model with effects coding\nmodel_oneway &lt;- lm(BP_Reduction ~ Treatment, data = data_oneway)\nsummary(model_oneway)\n\n\nCall:\nlm(formula = BP_Reduction ~ Treatment, data = data_oneway)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.0245  -6.0627  -0.4452   5.5324  21.7948 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.1544     0.8232  11.121  &lt; 2e-16 ***\nTreatment1   -6.7026     1.1642  -5.757 7.01e-08 ***\nTreatment2   10.7784     1.1642   9.258 1.22e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.018 on 117 degrees of freedom\nMultiple R-squared:  0.4276,    Adjusted R-squared:  0.4179 \nF-statistic: 43.71 on 2 and 117 DF,  p-value: 6.666e-15\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated coefficients relate to the group means?\n\n\n\n\n\nTo test whether the effect of treatment is statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_oneway)\nanova_results\n\nAnalysis of Variance Table\n\nResponse: BP_Reduction\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTreatment   2 7108.5  3554.2  43.707 6.666e-15 ***\nResiduals 117 9514.3    81.3                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\nEstimated marginal means, also known as least-squares means, are model-based means that represent the predicted (or expected) response at each level of a factor, averaged over the levels of other variables in the model.\nIn the context of a one-way ANOVA, where there is only one factor (e.g., treatment group), the estimated marginal means are equal to the observed group means. In more complex models with multiple factors, estimated marginal means provide predicted group means that are averaged over the levels of these additional factors. For example, in a model with both treatment and age as factors, the estimated marginal means for the treatment groups show the treatment means averaged over age, illustrating what these group means are expected to be at specific values of age (or averaged over a grid of age values).\nWe can calculate the estimated marginal means using the emmeans() function from the emmeans package:\n\n# Obtain estimated marginal means\nlibrary(emmeans)\nemms &lt;- emmeans(model_oneway, ~ Treatment)\nemms\n\n Treatment emmean   SE  df lower.CL upper.CL\n Control     2.45 1.43 117   -0.372     5.28\n DrugA      19.93 1.43 117   17.109    22.76\n DrugB       5.08 1.43 117    2.255     7.90\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated marginal means compare to the observed group means calculated during the exploratory data analysis?\n\n\n\n\n\nSince we found a significant treatment effect, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another. We perform these pairwise comparisons using the contrast() function from the emmeans package. To account for the increased risk of Type I error due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled.\n\n# Performing post-hoc analysis with emmeans\ncontrast(emms, method=\"pairwise\", adjust=\"Bonferroni\")\n\n contrast        estimate   SE  df t.ratio p.value\n Control - DrugA   -17.48 2.02 117  -8.669  &lt;.0001\n Control - DrugB    -2.63 2.02 117  -1.303  0.5857\n DrugA - DrugB      14.85 2.02 117   7.367  &lt;.0001\n\nP value adjustment: bonferroni method for 3 tests \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance) for the errors. A random scatter of residuals around zero indicates equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Residuals following the reference line suggest normally distributed errors.\n\n\n# Residuals vs Fitted\nplot(model_oneway, which = 1, main = \"Residuals vs Fitted\")\n\n\n\n# Normal Q-Q\nplot(model_oneway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?\n\n\n\n\n\n\nA one-way ANOVA was conducted to compare the effect of three treatments on blood pressure reduction. There was a statistically significant effect of treatment on blood pressure reduction [F(2, 117) = 43.71, p &lt; 0.001]. Estimated marginal means indicated that Drug A (M = 19.93 mm Hg, 95% CI = [17.11 mm Hg, 22.76 mm Hg]) resulted in significantly greater blood pressure reduction than both the Control group (M = 2.45 mm Hg, 95% CI = [-0.37 mm Hg, 5.28 mm Hg], p &lt; 0.001) and Drug B (M = 5.08 mm Hg, 95% CI = [2.26 mm Hg, 7.90 mm Hg], p &lt; 0.001). There was no significant difference between the Control group and Drug B (p = 0.586). P-values were adjusted for multiple testing using the Bonferroni correction."
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "href": "BLR_lab_FE_oneway.html#exploratory-data-analysis",
    "title": "Beyond Linear Regression Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "To understand the distribution of blood pressure reduction across treatment groups, we start by creating a boxplot:\n\n# Visualizing the results\nlibrary(ggplot2)\nggplot(data_oneway, aes(x = Treatment, y = BP_Reduction, fill = Treatment)) +\n  geom_boxplot() +\n  labs(title = \"Blood Pressure Reduction by Treatment\",\n       x = \"Treatment\", y = \"Blood Pressure Reduction (mm Hg)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nWe also calculate some summary statistics:\n\n# Summarizing data\nlibrary(dplyr)\nsummary_stats &lt;- data_oneway %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_BP_Reduction = mean(BP_Reduction),\n    SD_BP_Reduction = sd(BP_Reduction)\n  )\n\nsummary_stats\n\n# A tibble: 3 × 3\n  Treatment Mean_BP_Reduction SD_BP_Reduction\n  &lt;fct&gt;                 &lt;dbl&gt;           &lt;dbl&gt;\n1 Control                2.45            8.98\n2 DrugA                 19.9             9.60\n3 DrugB                  5.08            8.44\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the mean blood pressure reductions compare among the treatment groups?"
  },
  {
    "objectID": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "href": "BLR_lab_FE_oneway.html#performing-a-one-way-anova",
    "title": "Beyond Linear Regression Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "Using effects coding, the one-way Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The blood pressure reduction for the \\(j\\)-th patient in the \\(i\\)-th treatment group.\n\\(\\mu\\): The overall mean blood pressure reduction.\n\\(\\tau_i\\): The effect of the \\(i\\)-th treatment (deviation from the overall mean).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and constant variance.\n\n\n\n\n\n\n\nUnderstanding Coding Schemes\n\n\n\n\n\nIn regression models, categorical variables are represented using coding schemes. Two common coding schemes are:\n\n\n\n\n\nCompares each level of the factor to a reference level.\nIn R, this is the default coding scheme.\nThe first category is used as the reference level (unless specified otherwise).\nThe intercept represents the mean of the reference group.\nCoefficients represent differences from the reference group.\n\n\n\n\n\n\n\nLevel\nDummy Variable for B\nDummy Variable for C\n\n\n\n\nA\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\n\n\nInterpretation:\n\nIntercept: Mean of the reference group (A).\nCoefficient for B: Difference between mean of group A and group B.\nCoefficient for C: Difference between mean of group A and group C.\n\n\n\n\n\n\n\n\n\nCompares each level of the factor to the overall mean.\nThe sum of the coefficients equals zero.\nThe intercept represents the overall mean.\nCoefficients represent deviations from the overall mean.\n\n\n\n\n\n\n\nLevel\nEffects Code for A\nEffects Code for B\n\n\n\n\nA\n1\n0\n\n\nB\n0\n1\n\n\nC\n-1\n-1\n\n\n\n\nInterpretation:\n\nIntercept: Overall mean of all groups.\nCoefficient for A: Deviation of group A’s mean from the overall mean.\nCoefficient for B: Deviation of group B’s mean from the overall mean.\nCoefficient for C: Can be calculated as \\(-(\\beta_{\\text{A}} + \\beta_{\\text{B}})\\) since the sum of coefficients is zero.\n\n\n\n\n\n\nTo change the coding scheme globally to effects coding:\n\n# Set contrasts to effects coding globally\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nTo reset the coding scheme to the default dummy coding:\n\n# Reset contrasts to default dummy coding\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))  # Dummy coding\n\n\n\n\n\n\n\n\nWe can fit the one-way ANOVA model using the lm() function:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\n# Fitting the model with effects coding\nmodel_oneway &lt;- lm(BP_Reduction ~ Treatment, data = data_oneway)\nsummary(model_oneway)\n\n\nCall:\nlm(formula = BP_Reduction ~ Treatment, data = data_oneway)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.0245  -6.0627  -0.4452   5.5324  21.7948 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.1544     0.8232  11.121  &lt; 2e-16 ***\nTreatment1   -6.7026     1.1642  -5.757 7.01e-08 ***\nTreatment2   10.7784     1.1642   9.258 1.22e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.018 on 117 degrees of freedom\nMultiple R-squared:  0.4276,    Adjusted R-squared:  0.4179 \nF-statistic: 43.71 on 2 and 117 DF,  p-value: 6.666e-15\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated coefficients relate to the group means?\n\n\n\n\n\nTo test whether the effect of treatment is statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_oneway)\nanova_results\n\nAnalysis of Variance Table\n\nResponse: BP_Reduction\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTreatment   2 7108.5  3554.2  43.707 6.666e-15 ***\nResiduals 117 9514.3    81.3                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\nEstimated marginal means, also known as least-squares means, are model-based means that represent the predicted (or expected) response at each level of a factor, averaged over the levels of other variables in the model.\nIn the context of a one-way ANOVA, where there is only one factor (e.g., treatment group), the estimated marginal means are equal to the observed group means. In more complex models with multiple factors, estimated marginal means provide predicted group means that are averaged over the levels of these additional factors. For example, in a model with both treatment and age as factors, the estimated marginal means for the treatment groups show the treatment means averaged over age, illustrating what these group means are expected to be at specific values of age (or averaged over a grid of age values).\nWe can calculate the estimated marginal means using the emmeans() function from the emmeans package:\n\n# Obtain estimated marginal means\nlibrary(emmeans)\nemms &lt;- emmeans(model_oneway, ~ Treatment)\nemms\n\n Treatment emmean   SE  df lower.CL upper.CL\n Control     2.45 1.43 117   -0.372     5.28\n DrugA      19.93 1.43 117   17.109    22.76\n DrugB       5.08 1.43 117    2.255     7.90\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated marginal means compare to the observed group means calculated during the exploratory data analysis?\n\n\n\n\n\nSince we found a significant treatment effect, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another. We perform these pairwise comparisons using the contrast() function from the emmeans package. To account for the increased risk of Type I error due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled.\n\n# Performing post-hoc analysis with emmeans\ncontrast(emms, method=\"pairwise\", adjust=\"Bonferroni\")\n\n contrast        estimate   SE  df t.ratio p.value\n Control - DrugA   -17.48 2.02 117  -8.669  &lt;.0001\n Control - DrugB    -2.63 2.02 117  -1.303  0.5857\n DrugA - DrugB      14.85 2.02 117   7.367  &lt;.0001\n\nP value adjustment: bonferroni method for 3 tests \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance) for the errors. A random scatter of residuals around zero indicates equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Residuals following the reference line suggest normally distributed errors.\n\n\n# Residuals vs Fitted\nplot(model_oneway, which = 1, main = \"Residuals vs Fitted\")\n\n\n\n# Normal Q-Q\nplot(model_oneway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?\n\n\n\n\n\n\nA one-way ANOVA was conducted to compare the effect of three treatments on blood pressure reduction. There was a statistically significant effect of treatment on blood pressure reduction [F(2, 117) = 43.71, p &lt; 0.001]. Estimated marginal means indicated that Drug A (M = 19.93 mm Hg, 95% CI = [17.11 mm Hg, 22.76 mm Hg]) resulted in significantly greater blood pressure reduction than both the Control group (M = 2.45 mm Hg, 95% CI = [-0.37 mm Hg, 5.28 mm Hg], p &lt; 0.001) and Drug B (M = 5.08 mm Hg, 95% CI = [2.26 mm Hg, 7.90 mm Hg], p &lt; 0.001). There was no significant difference between the Control group and Drug B (p = 0.586). P-values were adjusted for multiple testing using the Bonferroni correction."
  },
  {
    "objectID": "BLR_lab_crossed_effects.html",
    "href": "BLR_lab_crossed_effects.html",
    "title": "Beyond Linear Regression Lab 5: Crossed Effects in Mixed Models",
    "section": "",
    "text": "In this lab, we introduce the concepts of crossed and nested effects in mixed effects models. We will explore how these effects can be modeled and how they impact the interpretation of results.\nIn the previous lab, we encountered an example of a nested effect when we modeled the interaction between treatment (a fixed effect) and lab (a random effect) in a replicated randomized block design. In that case, the treatment effect was nested within each lab, meaning that the variability in treatment effectiveness was specific to each lab. This nested relationship allowed us to understand how treatment performance varied depending on the conditions in each lab.\nNow, we will expand our understanding by exploring both nested and crossed effects:\nIn this lab, you will learn how to analyze data involving both crossed and nested random effects."
  },
  {
    "objectID": "BLR_lab_crossed_effects.html#exploratory-data-analysis",
    "href": "BLR_lab_crossed_effects.html#exploratory-data-analysis",
    "title": "Beyond Linear Regression Lab 5: Crossed Effects in Mixed Models",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nTo explore the data and investigate the possible presence of clinic and lab effects, we will create a scatter plot that visualizes the reduction in bacterial load by treatment, with the nurse effect represented by color and faceting by clinic. This approach will allow us to examine the variability due to nurse effects and treatment effects more clearly.\n\n# Create scatter plot to visualize reduction in bacterial load by treatment within each clinic\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nggplot(wound_healing_data, aes(x = ReductionLoad, y = Treatment, color = Nurse)) +\n  geom_point(size = 4) +\n  facet_wrap(~ Clinic, ncol = 1) +\n  labs(title = \"Reduction in Bacterial Load by Treatment within Clinics\",\n       x = \"Reduction in Bacterial Load\",\n       y = \"Treatment\") +\n  theme_minimal()\n\n\n\n\nThis scatter plot allows us to more easily assess the variability attributed to nurse effects and treatment effects within each clinic, making it clearer to identify differences between clinics and the impact of individual nurses.\nWe will also create a boxplot to visualize the lab effect on the reduction in bacterial load:\n\n# Create boxplot to visualize reduction in bacterial load by lab\nggplot(wound_healing_data, aes(x = Lab, y = ReductionLoad)) +\n  geom_boxplot() +\n  labs(title = \"Reduction in Bacterial Load by Lab\",\n       x = \"Lab\",\n       y = \"Reduction in Bacterial Load\") +\n  theme_minimal()\n\n\n\n\nThe boxplot provides a clearer picture of the variability in reduction in bacterial load attributed to different labs.\nIn addition to the scatter plot and boxplot, we compute descriptive statistics to summarize the reduction in bacterial load within treatments, clinics, and labs. This will help us assess variability across different sources of variability.\nIn addition to the scatter plot and boxplot, we compute descriptive statistics to summarize the reduction in bacterial load within treatments, clinics, and labs. This will help us assess variability across different sources of variability.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- wound_healing_data %&gt;%\n  filter(!is.na(ReductionLoad)) %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_ReductionLoad = mean(ReductionLoad),\n    SD_ReductionLoad = sd(ReductionLoad)\n  )\n\n# Summarizing data by Clinic\nsummary_stats_clinic &lt;- wound_healing_data %&gt;%\n  filter(!is.na(ReductionLoad)) %&gt;%\n  group_by(Clinic) %&gt;%\n  summarise(\n    Mean_ReductionLoad = mean(ReductionLoad),\n    SD_ReductionLoad = sd(ReductionLoad)\n  )\n\n# Summarizing data by Lab\nsummary_stats_lab &lt;- wound_healing_data %&gt;%\n  filter(!is.na(ReductionLoad)) %&gt;%\n  group_by(Lab) %&gt;%\n  summarise(\n    Mean_ReductionLoad = mean(ReductionLoad),\n    SD_ReductionLoad = sd(ReductionLoad)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\n\n# A tibble: 3 × 3\n  Treatment Mean_ReductionLoad SD_ReductionLoad\n  &lt;fct&gt;                  &lt;dbl&gt;            &lt;dbl&gt;\n1 A                       4.03             2.13\n2 B                       6.90             2.46\n3 C                       5.90             2.26\n\nsummary_stats_clinic\n\n# A tibble: 4 × 3\n  Clinic Mean_ReductionLoad SD_ReductionLoad\n  &lt;fct&gt;               &lt;dbl&gt;            &lt;dbl&gt;\n1 1                    6.31             2.18\n2 2                    4.94             2.35\n3 3                    5.59             3.08\n4 4                    5.61             2.60\n\nsummary_stats_lab\n\n# A tibble: 3 × 3\n  Lab   Mean_ReductionLoad SD_ReductionLoad\n  &lt;fct&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n1 1                   3.53             1.65\n2 2                   4.82             1.09\n3 3                   8.48             1.48\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment, clinic, and lab based on the plot and summary statistics?\n\n\n\nModel Specification\nThe mixed-effects model for our crossed effects design can be specified as:\n\\[\nY_{ijkl} = \\mu + \\tau_i + b_j + l_k + n_{jk} + \\epsilon_{ijkl}\n\\]\nwhere:\n\n\\(Y_{ijkl}\\): The observed reduction in bacterial load for patient \\(l\\) in treatment group \\(i\\), clinic \\(j\\), and lab \\(k\\).\n\\(\\mu\\): The overall mean reduction in bacterial load.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\) (ointment A, B, or C).\n\\(b_j\\): The random effect of clinic \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\).\n\\(l_k\\): The random effect of lab \\(k\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_l^2\\).\n\\(n_{mj}\\): The random effect of nurse \\(m\\) nested within clinic \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_n^2\\).\n\\(\\epsilon_{ijkl}\\): The residual error term, assumed to be normally distributed with mean zero and variance \\(\\sigma^2\\).\n\nHere, I’ve updated the indexing for the nurse random effect to avoid using the same index for both nurse and lab. The index \\(m\\) represents nurses nested within each clinic, whereas \\(k\\) refers to the lab. This distinction ensures the indexing is consistent and clear."
  },
  {
    "objectID": "BLR_lab_randomized_block.html",
    "href": "BLR_lab_randomized_block.html",
    "title": "Beyond Linear Regression Lab 3: Randomized Block Designs",
    "section": "",
    "text": "Suppose we are conducting an experiment to compare the effectiveness of three different wound healing treatments (Treatment A, Treatment B, and Treatment C) on cell cultures. The experimental units are the cell culture plates. To account for potential variability in laboratory conditions (such as humidity and temperature), we use a randomized block design, with laboratory facility as the blocking factor. Within each laboratory (block), the three treatments are randomly assigned to one cell culture plate each, ensuring that every treatment is represented once within each block. This design helps control for variability between laboratory facilities, allowing us to more effectively isolate the treatment effects.\n\n# Set seed for reproducibility\nset.seed(456)\n\n# Define blocks and treatments\nblocks &lt;- factor(paste0(\"Laboratory \", rep(1:5, each = 3)))  # Labs 1 to 5\ntreatments &lt;- factor(rep(c(\"A\", \"B\", \"C\"), times = 5))\n\n# Simulate data\nblock_effect &lt;- rnorm(5, mean = 0, sd = 2)  # Random effect for each block\ntreatment_effect &lt;- c(A = 5, B = 7, C = 6)  # Fixed effects for treatments\n\n# Create data frame\ndata_block &lt;- data.frame(\n  Laboratory = blocks,\n  Treatment = treatments,\n  WoundHealing = NA\n)\n\n# Assign responses\nfor (i in 1:nrow(data_block)) {\n  b &lt;- as.numeric(data_block$Laboratory[i])\n  t &lt;- data_block$Treatment[i]\n  data_block$WoundHealing[i] &lt;-\n    50 + block_effect[b] + treatment_effect[t] + rnorm(1, mean = 0, sd = 1)\n}\n\nThe R code chunk above simulates wound healing observations (measured on a continuous scale, where higher values indicate better healing) for 15 cell culture plates, divided across five laboratory facilities. The results are stored in the data frame data_block, which consists of the following three variables:\n\nLaboratory: A factor variable indicating the laboratory facility.\nTreatmment: A factor variable indicating the applied treatment.\nWoundHealing: A numeric variable representing the degree of wound healing on a continuous scale.\n\n\n\nTo explore the data and investigate the possible presence of a laboratory effect, we start by creating a scatter plot with the wound healing variable on the x-axis and the laboratory facility variable on the y-axis:\n\nlibrary(ggplot2)\nggplot(data_block, aes(x = WoundHealing, y = Laboratory, color = Treatment)) +\n  geom_point(size = 4) +\n  labs(title = \"Wound Healing by Treatment and Laboratory\",\n       x = \"Wound Healing Measure\",\n       y = \"Laboratory\") +\n  theme_minimal()\n\n\n\n\nIn addition to the scatter plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\nlibrary(dplyr)\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_block %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_block %&gt;%\n  group_by(Laboratory) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\n\n# A tibble: 3 × 3\n  Treatment Mean_WoundHealing SD_WoundHealing\n  &lt;fct&gt;                 &lt;dbl&gt;           &lt;dbl&gt;\n1 A                      54.4            3.15\n2 B                      57.5            1.89\n3 C                      56.0            2.11\n\nsummary_stats_laboratory\n\n# A tibble: 5 × 3\n  Laboratory   Mean_WoundHealing SD_WoundHealing\n  &lt;fct&gt;                    &lt;dbl&gt;           &lt;dbl&gt;\n1 Laboratory 1              53.5           1.51 \n2 Laboratory 2              57.5           1.26 \n3 Laboratory 3              58.9           0.888\n4 Laboratory 4              54.0           2.83 \n5 Laboratory 5              56.0           1.95 \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment and laboratory based on the plot and summary statistics?\n\n\n\n\n\nIn a mixed-effects model, both fixed effects and random effects are used to account for different sources of variation.\nIn the wound healing example, it is essential to account for the laboratory facility because differences between laboratories (such as variations in environmental conditions) could influence the outcome. By including laboratory as a blocking variable, we can more efficiently estimate the treatment effects by controlling for this source of variability. This can be statistically achieved by modeling laboratory as either a fixed effect or a random effect.\nWhile we could model laboratory as a fixed effect, treating it as a random effect is preferred in this case for two reasons: first, it better reflects reality, as the laboratories are considered a random sample of possible laboratory conditions; second, it reduces the number of parameters we need to estimate, making the model more parsimonious. Modeling the lab as random allows us to account for variability between laboratories without estimating a separate effect for each one, which ultimately helps to isolate the treatment effects more effectively.\nOn the other hand, treatment is modeled as a fixed effect because we are specifically interested in estimating and comparing the effectiveness of the three particular wound healing treatments (Treatment A, Treatment B, and Treatment C). These treatments are not considered random samples from a larger population of treatments; rather, they are the specific interventions under study. By modeling treatment as a fixed effect, we aim to draw conclusions about the differences between these particular treatments, and their impact on wound healing.\n\n\nThe mixed-effects model for our randomized block design can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + b_j + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The observed wound healing response for treatment \\(i\\) in laboratory \\(j\\).\n\\(\\mu\\): The overall mean response across all treatments and laboratories.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\), representing the deviation of treatment \\(i\\) from the overall mean \\(\\mu\\).\n\\(b_j\\): The random effect of laboratory \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\)).\n\\(\\epsilon_{ij}\\): The error term, assumed to be normally distributed with mean zero and variance \\(\\sigma^2\\).\n\n\n\n\nWe previously mentioned that the lme4 package does not provide p-values for the fixed effect estimates. One way around this is to fit the mixed effects model using the lmer() function from the lmeTest package, which extends to original lmer() function from the lme4 to include p-values for the fixed effect estimates. The lmerTest package achieves this by applying Satterthwaite’s approximation to calculate degrees of freedom, which are then used to derive the p-values.\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_block)\nsummary(model_block)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: WoundHealing ~ Treatment + (1 | Laboratory)\n   Data: data_block\n\nREML criterion at convergence: 52.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.66569 -0.29976 -0.05942  0.48477  1.41990 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n Laboratory (Intercept) 4.874    2.208   \n Residual               1.086    1.042   \nNumber of obs: 15, groups:  Laboratory, 5\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  55.9693     1.0233  4.0000  54.692 6.69e-07 ***\nTreatment1   -1.5908     0.3806  8.0000  -4.180  0.00308 ** \nTreatment2    1.5170     0.3806  8.0000   3.986  0.00403 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) Trtmn1\nTreatment1  0.000       \nTreatment2  0.000 -0.500\n\n\n\n\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory)\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments. Note that the intercept is included by default in the model, so WoundHealing ~ Treatment is essentially a shortcut for WoundHealing ~ 1 + Treatment. Also remember that with effects coding, the intercept represents the overall mean across all levels of the treatment variable, and the treatment coefficients represent deviations from this mean.\n(1 | Laboratory): This specifies the random effect for Laboratory, representing laboratory-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_block), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean wound healing score averaged across all treatments and laboratories.\nTreatment: The differences in wound healing associated with each treatment relative to the overall mean.\n\nRandom Effects: Estimates of the variance components\n\nLaboratory - Intercept: Between-laboratory variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nCaution: Interpreting p-values in Mixed Effects Models\n\n\n\nWhile the lmerTest package provides p-values for fixed effects, it is important to use them with caution, primarily because methods for calculating degrees of freedom, such as Satterthwaite, are approximations that may not always be reliable, particularly in complex models fitted to imbalanced data. Generally, this sensitivity is not a concern for the randomized block design considered in this lab.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of laboratory variability and residual error to the total variability in wound healing?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsidering these results, do you think that blocking by laboratory was necessary for this experiment?\n\n\n\n\n\nIn addition to providing p-values for the fixed effects estimates, the lmerTest package also implements the anova() function to test the overall significance of fixed effects in the model. Additionally, the ls_means() function can be used to calculate the estimated marginal means for the factors (i.e., variables that are defined as factors in the data frame or the model formula) included in the fixed effects structure of the model. Alternatively, these estimated marginal means can be calculated using the emmeans() function from the emmeans package, which provides more options and greater flexibility for advanced users.\n\n# Obtain ANOVA table for the fixed effects\nanova(model_block)\n\nType III Analysis of Variance Table with Satterthwaite's method\n          Sum Sq Mean Sq NumDF DenDF F value   Pr(&gt;F)   \nTreatment 24.187  12.093     2     8  11.132 0.004883 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Calculate estimated marginal means for the Treatment variable\nls_means(model_block)\n\nLeast Squares Means table:\n\n           Estimate Std. Error  df t value   lower   upper  Pr(&gt;|t|)    \nTreatmentA  54.3786     1.0918 5.1  49.805 51.5938 57.1633 4.302e-08 ***\nTreatmentB  57.4864     1.0918 5.1  52.651 54.7016 60.2711 3.236e-08 ***\nTreatmentC  56.0430     1.0918 5.1  51.329 53.2583 58.8278 3.686e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  Confidence level: 95%\n  Degrees of freedom method: Satterthwaite \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow to the estimated marginal means compare to the observed group means from the exploratory data analysis?\n\n\n\n\nSince we found a significant treatment effect, we proceed with computing pairwise differences of the estimated marginal means. This can be achieved by adding the argument pairwise=TRUE to the call to the ls_means() function. Unlike the emmmeans package, there is no multiplicity correction for pairwise comparisons in the lmerTest package. We therefore use the p.adjust() function from the base R stats package to compute the Bonferroni corrected p-values (i.e., the original p-values multiplied by the number of comparisons).\n\n# Compute pairwise differences of the estimated marginal means \nemms &lt;- ls_means(model_block, pairwise=TRUE)\nemms\n\nLeast Squares Means table:\n\n                         Estimate Std. Error df t value     lower     upper\nTreatmentA - TreatmentB -3.107786   0.659209  8 -4.7144 -4.627924 -1.587647\nTreatmentA - TreatmentC -1.664484   0.659209  8 -2.5250 -3.184623 -0.144345\nTreatmentB - TreatmentC  1.443302   0.659209  8  2.1894 -0.076837  2.963441\n                        Pr(&gt;|t|)   \nTreatmentA - TreatmentB 0.001513 **\nTreatmentA - TreatmentC 0.035533 * \nTreatmentB - TreatmentC 0.059973 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  Confidence level: 95%\n  Degrees of freedom method: Satterthwaite \n\n# Retrieve the p-values from the emms object and adjust them \n# for multiple testing using the Bonferroni correction\np.adjust(emms$`Pr(&gt;|t|)`, method=\"bonferroni\")\n\n[1] 0.004539079 0.106597860 0.179918675\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\n\nSimilar as in the previous lab, we will inspect the conditional residuals to check the model assumptions regarding the error term:\n\n# Extract conditional residuals\nresiduals_cond &lt;- resid(model_block)\n\n# Residuals vs Fitted\nplot(fitted(model_block), residuals_cond,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond)\nqqline(residuals_cond, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?\n\n\n\n\n\n\n\nA linear mixed-effects model was fitted to assess the effect of treatment on wound healing, with laboratory included as a random effect to account for variability across different laboratory settings. The treatment effect was statistically significant [F(2, 8) = 11.13, p = 0.0045], indicating differences among the treatments. Estimated marginal means analysis revealed that Treatment B had the highest wound healing score (M = 57.5, 95% CI = [54.7, 60.3]), significantly higher than Treatment A (M = 54.4, 95% CI = [51.6, 57.2], p = 0.0045). However, no significant differences were found between Treatment A and Treatment C (M = 56.0, 95% CI = [53.3, 58.8], p = 0.1066), nor between Treatment B and Treatment C (p = 0.1799). Degrees of freedom were calculated using Satterthwaite’s approximation. P-values were adjusted using the Bonferroni correction."
  },
  {
    "objectID": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "href": "BLR_lab_randomized_block.html#exploratory-data-analysis",
    "title": "Beyond Linear Regression Lab 3: Randomized Block Designs",
    "section": "",
    "text": "To explore the data and investigate the possible presence of a laboratory effect, we start by creating a scatter plot with the wound healing variable on the x-axis and the laboratory facility variable on the y-axis:\n\nlibrary(ggplot2)\nggplot(data_block, aes(x = WoundHealing, y = Laboratory, color = Treatment)) +\n  geom_point(size = 4) +\n  labs(title = \"Wound Healing by Treatment and Laboratory\",\n       x = \"Wound Healing Measure\",\n       y = \"Laboratory\") +\n  theme_minimal()\n\n\n\n\nIn addition to the scatter plot, we compute descriptive statistics to summarize the wound healing measures within treatments and within laboratories. This will help us assess variability both across treatments and across laboratory facilities.\n\nlibrary(dplyr)\n\n# Summarizing data by Treatment\nsummary_stats_treatment &lt;- data_block %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Summarizing data by Laboratory\nsummary_stats_laboratory &lt;- data_block %&gt;%\n  group_by(Laboratory) %&gt;%\n  summarise(\n    Mean_WoundHealing = mean(WoundHealing),\n    SD_WoundHealing = sd(WoundHealing)\n  )\n\n# Displaying the produced summary tables\nsummary_stats_treatment\n\n# A tibble: 3 × 3\n  Treatment Mean_WoundHealing SD_WoundHealing\n  &lt;fct&gt;                 &lt;dbl&gt;           &lt;dbl&gt;\n1 A                      54.4            3.15\n2 B                      57.5            1.89\n3 C                      56.0            2.11\n\nsummary_stats_laboratory\n\n# A tibble: 5 × 3\n  Laboratory   Mean_WoundHealing SD_WoundHealing\n  &lt;fct&gt;                    &lt;dbl&gt;           &lt;dbl&gt;\n1 Laboratory 1              53.5           1.51 \n2 Laboratory 2              57.5           1.26 \n3 Laboratory 3              58.9           0.888\n4 Laboratory 4              54.0           2.83 \n5 Laboratory 5              56.0           1.95 \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat patterns do you observe regarding the effects of treatment and laboratory based on the plot and summary statistics?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "href": "BLR_lab_randomized_block.html#a-mixed-effects-model-for-the-randomized-block-design",
    "title": "Beyond Linear Regression Lab 3: Randomized Block Designs",
    "section": "",
    "text": "In a mixed-effects model, both fixed effects and random effects are used to account for different sources of variation.\nIn the wound healing example, it is essential to account for the laboratory facility because differences between laboratories (such as variations in environmental conditions) could influence the outcome. By including laboratory as a blocking variable, we can more efficiently estimate the treatment effects by controlling for this source of variability. This can be statistically achieved by modeling laboratory as either a fixed effect or a random effect.\nWhile we could model laboratory as a fixed effect, treating it as a random effect is preferred in this case for two reasons: first, it better reflects reality, as the laboratories are considered a random sample of possible laboratory conditions; second, it reduces the number of parameters we need to estimate, making the model more parsimonious. Modeling the lab as random allows us to account for variability between laboratories without estimating a separate effect for each one, which ultimately helps to isolate the treatment effects more effectively.\nOn the other hand, treatment is modeled as a fixed effect because we are specifically interested in estimating and comparing the effectiveness of the three particular wound healing treatments (Treatment A, Treatment B, and Treatment C). These treatments are not considered random samples from a larger population of treatments; rather, they are the specific interventions under study. By modeling treatment as a fixed effect, we aim to draw conclusions about the differences between these particular treatments, and their impact on wound healing.\n\n\nThe mixed-effects model for our randomized block design can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + b_j + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The observed wound healing response for treatment \\(i\\) in laboratory \\(j\\).\n\\(\\mu\\): The overall mean response across all treatments and laboratories.\n\\(\\tau_i\\): The fixed effect of treatment \\(i\\), representing the deviation of treatment \\(i\\) from the overall mean \\(\\mu\\).\n\\(b_j\\): The random effect of laboratory \\(j\\), assumed to be normally distributed with mean zero and variance \\(\\sigma_b^2\\)).\n\\(\\epsilon_{ij}\\): The error term, assumed to be normally distributed with mean zero and variance \\(\\sigma^2\\).\n\n\n\n\nWe previously mentioned that the lme4 package does not provide p-values for the fixed effect estimates. One way around this is to fit the mixed effects model using the lmer() function from the lmeTest package, which extends to original lmer() function from the lme4 to include p-values for the fixed effect estimates. The lmerTest package achieves this by applying Satterthwaite’s approximation to calculate degrees of freedom, which are then used to derive the p-values.\n\nlibrary(lmerTest)\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nmodel_block &lt;- lmer(WoundHealing ~ Treatment + (1 | Laboratory), data = data_block)\nsummary(model_block)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: WoundHealing ~ Treatment + (1 | Laboratory)\n   Data: data_block\n\nREML criterion at convergence: 52.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.66569 -0.29976 -0.05942  0.48477  1.41990 \n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n Laboratory (Intercept) 4.874    2.208   \n Residual               1.086    1.042   \nNumber of obs: 15, groups:  Laboratory, 5\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  55.9693     1.0233  4.0000  54.692 6.69e-07 ***\nTreatment1   -1.5908     0.3806  8.0000  -4.180  0.00308 ** \nTreatment2    1.5170     0.3806  8.0000   3.986  0.00403 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) Trtmn1\nTreatment1  0.000       \nTreatment2  0.000 -0.500\n\n\n\n\nLet’s break down the model formula WoundHealing ~ Treatment + (1 | Laboratory)\n\nWoundHealing ~ Treatment: This specifies that WoundHealing is the outcome variable and that Treatment is included as a fixed effect to estimate differences between the three treatments. Note that the intercept is included by default in the model, so WoundHealing ~ Treatment is essentially a shortcut for WoundHealing ~ 1 + Treatment. Also remember that with effects coding, the intercept represents the overall mean across all levels of the treatment variable, and the treatment coefficients represent deviations from this mean.\n(1 | Laboratory): This specifies the random effect for Laboratory, representing laboratory-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_block), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean wound healing score averaged across all treatments and laboratories.\nTreatment: The differences in wound healing associated with each treatment relative to the overall mean.\n\nRandom Effects: Estimates of the variance components\n\nLaboratory - Intercept: Between-laboratory variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nCaution: Interpreting p-values in Mixed Effects Models\n\n\n\nWhile the lmerTest package provides p-values for fixed effects, it is important to use them with caution, primarily because methods for calculating degrees of freedom, such as Satterthwaite, are approximations that may not always be reliable, particularly in complex models fitted to imbalanced data. Generally, this sensitivity is not a concern for the randomized block design considered in this lab.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the estimated variance components, what can you conclude about the relative contributions of laboratory variability and residual error to the total variability in wound healing?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nConsidering these results, do you think that blocking by laboratory was necessary for this experiment?\n\n\n\n\n\nIn addition to providing p-values for the fixed effects estimates, the lmerTest package also implements the anova() function to test the overall significance of fixed effects in the model. Additionally, the ls_means() function can be used to calculate the estimated marginal means for the factors (i.e., variables that are defined as factors in the data frame or the model formula) included in the fixed effects structure of the model. Alternatively, these estimated marginal means can be calculated using the emmeans() function from the emmeans package, which provides more options and greater flexibility for advanced users.\n\n# Obtain ANOVA table for the fixed effects\nanova(model_block)\n\nType III Analysis of Variance Table with Satterthwaite's method\n          Sum Sq Mean Sq NumDF DenDF F value   Pr(&gt;F)   \nTreatment 24.187  12.093     2     8  11.132 0.004883 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Calculate estimated marginal means for the Treatment variable\nls_means(model_block)\n\nLeast Squares Means table:\n\n           Estimate Std. Error  df t value   lower   upper  Pr(&gt;|t|)    \nTreatmentA  54.3786     1.0918 5.1  49.805 51.5938 57.1633 4.302e-08 ***\nTreatmentB  57.4864     1.0918 5.1  52.651 54.7016 60.2711 3.236e-08 ***\nTreatmentC  56.0430     1.0918 5.1  51.329 53.2583 58.8278 3.686e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  Confidence level: 95%\n  Degrees of freedom method: Satterthwaite \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow to the estimated marginal means compare to the observed group means from the exploratory data analysis?\n\n\n\n\nSince we found a significant treatment effect, we proceed with computing pairwise differences of the estimated marginal means. This can be achieved by adding the argument pairwise=TRUE to the call to the ls_means() function. Unlike the emmmeans package, there is no multiplicity correction for pairwise comparisons in the lmerTest package. We therefore use the p.adjust() function from the base R stats package to compute the Bonferroni corrected p-values (i.e., the original p-values multiplied by the number of comparisons).\n\n# Compute pairwise differences of the estimated marginal means \nemms &lt;- ls_means(model_block, pairwise=TRUE)\nemms\n\nLeast Squares Means table:\n\n                         Estimate Std. Error df t value     lower     upper\nTreatmentA - TreatmentB -3.107786   0.659209  8 -4.7144 -4.627924 -1.587647\nTreatmentA - TreatmentC -1.664484   0.659209  8 -2.5250 -3.184623 -0.144345\nTreatmentB - TreatmentC  1.443302   0.659209  8  2.1894 -0.076837  2.963441\n                        Pr(&gt;|t|)   \nTreatmentA - TreatmentB 0.001513 **\nTreatmentA - TreatmentC 0.035533 * \nTreatmentB - TreatmentC 0.059973 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  Confidence level: 95%\n  Degrees of freedom method: Satterthwaite \n\n# Retrieve the p-values from the emms object and adjust them \n# for multiple testing using the Bonferroni correction\np.adjust(emms$`Pr(&gt;|t|)`, method=\"bonferroni\")\n\n[1] 0.004539079 0.106597860 0.179918675\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\n\nSimilar as in the previous lab, we will inspect the conditional residuals to check the model assumptions regarding the error term:\n\n# Extract conditional residuals\nresiduals_cond &lt;- resid(model_block)\n\n# Residuals vs Fitted\nplot(fitted(model_block), residuals_cond,\n     main = \"Residuals vs Fitted\",\n     xlab = \"Fitted values\",\n     ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n# Normal Q-Q Plot\nqqnorm(residuals_cond)\nqqline(residuals_cond, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "BLR_lab_randomized_block.html#reporting",
    "href": "BLR_lab_randomized_block.html#reporting",
    "title": "Beyond Linear Regression Lab 3: Randomized Block Designs",
    "section": "",
    "text": "A linear mixed-effects model was fitted to assess the effect of treatment on wound healing, with laboratory included as a random effect to account for variability across different laboratory settings. The treatment effect was statistically significant [F(2, 8) = 11.13, p = 0.0045], indicating differences among the treatments. Estimated marginal means analysis revealed that Treatment B had the highest wound healing score (M = 57.5, 95% CI = [54.7, 60.3]), significantly higher than Treatment A (M = 54.4, 95% CI = [51.6, 57.2], p = 0.0045). However, no significant differences were found between Treatment A and Treatment C (M = 56.0, 95% CI = [53.3, 58.8], p = 0.1066), nor between Treatment B and Treatment C (p = 0.1799). Degrees of freedom were calculated using Satterthwaite’s approximation. P-values were adjusted using the Bonferroni correction."
  },
  {
    "objectID": "BLR_lab_RE_oneway.html",
    "href": "BLR_lab_RE_oneway.html",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "Consider an observational study in which waist circumference measurements (in centimeters) are taken by multiple nurses. These nurses may have varying measurement techniques, levels of experience, or adherence to standardized protocols, leading to variability in recorded waist circumference measurements. Our aim is to assess the extent of variability in waist circumference measurements attributed to differences among nurses.\nTo facilitate our analysis, we will simulate a dataset where waist circumference measurements are recorded by four different nurses.\n\n# Setting seed for reproducibility\nset.seed(789)\n\n# Number of nurses and measurements per nurse\nnum_nurses &lt;- 4\nmeasurements_per_nurse &lt;- 50\n\n# Simulating nurse effects (random effects)\nnurse_effects &lt;- rnorm(num_nurses, mean = 0, sd = 1.5)  # Nurse-specific deviations\n\n# Simulating residual errors\nresidual_errors &lt;- rnorm(num_nurses * measurements_per_nurse, mean = 0, sd = 3)\n\n# Simulating Waist Circumference Measurements\nWaist_Circumference &lt;- 80 + rep(nurse_effects, each = measurements_per_nurse) + residual_errors\n\n# Creating Nurse factor\nNurse &lt;- factor(rep(paste(\"Nurse\", LETTERS[1:num_nurses]), each = measurements_per_nurse))\n\n# Combining into a data frame\ndata_waist_circumference &lt;- data.frame(\n  Nurse = Nurse,\n  Waist_Circumference = Waist_Circumference\n)\n\nThe above R chunk simulates 200 hypothetical waist circumference measurements for four different nurses (50 measurements per nurse) and stores the results in the data frame data_waist_circumference that consists of the following two columns:\n\nNurse: Factor variable indicating the nurse who performed the measurement (Nurse A, Nurse B, Nurse C, Nurse D).\nWaist_Circumference: Numeric variable representing the waist circumference measurement (in centimeters).\n\n\n\nBefore modeling, it’s important to visualize and summarize the data to identify any trends, patterns, or anomalies that may impact the analysis. In this case, we aim to explore the variability in waist circumference measurements across nurses and assess the consistency of these measurements.\nWe’ll use two main approaches:\n\nVisualizing the data: A boxplot will be created to compare waist circumference measurements across nurses, highlighting differences in measurement tendencies or variability.\nSummarizing the data: Summary statistics (mean and standard deviation) will be computed for each nurse, providing a numerical overview of central tendency and spread for the measurements.\n\n\n# Create a boxplot\nlibrary(ggplot2)\nggplot(data_waist_circumference, aes(x = Nurse, y = Waist_Circumference, fill = Nurse)) +\n  geom_boxplot() +\n  labs(title = \"Waist Circumference Measurements by Nurse\",\n       x = \"Nurse\", y = \"Waist Circumference (cm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n# Calculate summary statistics\nlibrary(dplyr)\nsummary_stats_random &lt;- data_waist_circumference %&gt;%\n  group_by(Nurse) %&gt;%\n  summarise(\n    Mean_Waist = mean(Waist_Circumference),\n    SD_Waist = sd(Waist_Circumference)\n  )\n\nsummary_stats_random\n\n# A tibble: 4 × 3\n  Nurse   Mean_Waist SD_Waist\n  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Nurse A       80.4     2.69\n2 Nurse B       76.9     3.01\n3 Nurse C       79.9     3.15\n4 Nurse D       79.7     3.56\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the boxplot and summary statistics, do you observe any systematic differences in waist circumference measurements across the nurses? If so, describe the differences and what they might suggest about the measurements.\n\n\n\n\n\nA random effects model represents variations assumed to arise from a larger population. Unlike fixed effects, which estimate specific differences between levels of a factor, random effects account for variability among factor levels by treating them as random samples from a broader population.\nIn the waist circumference example, the four nurses can be considered a random sample from a larger population of nurses. By modeling “Nurse” as a random effect, we aim to generalize the findings about measurement variability to the broader population of nurses, rather than focusing solely on the four in the study.\n\n\nThe random effects model can be specified as:\n\\[\nY_{ij} = \\mu + b_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The waist circumference measurement for the \\(j\\)-th observation by the \\(i\\)-th nurse.\n\\(\\mu\\): The overall mean waist circumference.\n\\(b_i\\): The random effect of the \\(i\\)-th nurse, assumed to be normally distributed with mean zero and variance \\(\\sigma^2_{b}\\).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and variance \\(\\sigma^2\\).\n\nThe use of random effects allows us to decompose the total variance in the outcome variable into distinct components, each associated with a different source of variation. In this example, the total variance in waist circumference measurements is split into two variance components:\n\nBetween-nurse variability (\\(\\sigma^2_{b}\\)): This component, represented by the variance of the random effect \\(b_{i}\\), captures the variability in waist circumference measurements attributable to differences among nurses. It reflects how much of the overall variability is due to systematic differences in measurement techniques or practices between nurses.\nResidual variance (\\(\\sigma^2\\)): This component, represented by the variance of the error term \\(\\epsilon_{ij}\\), captures the variability in waist circumference measurements that remains unexplained by nurse-related differences. It includes measurement error, patient-specific factors, and other unmeasured sources of variation.\n\n\n\n\n\n\n\nNotation convention\n\n\n\nIn mixed-effects models, fixed effects are typically represented by Greek letters, while random effects are represented by Roman letters. This helps differentiate between the two types of effects in model specification.\n\n\n\n\nThe Intraclass Correlation Coefficient (ICC) is a statistical measure that quantifies the proportion of the total variance in the outcome variable that can be attributed to differences between groups. In this context, the ICC measures the extent to which waist circumference measurements are more similar when taken by the same nurse (within-group), compared to the overall variability across all nurses (between-group). In other words, it tells us how strongly measurements are correlated within the same group.\nMathematically, the ICC is calculated as:\n\\[\nICC = \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2}\n\\]\nInterpretation of ICC:\n\nICC \\(\\approx\\) 0: Indicates that nearly all the variability in waist circumference measurements is due to residual factors (such as patient differences or measurement error). This suggests that nurse-level differences contribute minimally to the total variability, implying a high degree of consistency across nurses in their measurement practices.\nICC \\(\\approx\\) 1: Indicates that nearly all the variability is attributable to differences between nurses. This suggests substantial between-nurse variability, meaning different nurses consistently record different waist circumference measurements.\n\n\n\n\n\nWe will fit the random effects model using the lmer() function from the lme4 package.\n\n# Fitting the random effects model\nlibrary(lme4)\nmodel_random &lt;- lmer(Waist_Circumference ~ 1 + (1 | Nurse), data = data_waist_circumference)\nsummary(model_random)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Waist_Circumference ~ 1 + (1 | Nurse)\n   Data: data_waist_circumference\n\nREML criterion at convergence: 1030.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.83380 -0.59987  0.00698  0.66169  2.96673 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Nurse    (Intercept) 2.358    1.536   \n Residual             9.730    3.119   \nNumber of obs: 200, groups:  Nurse, 4\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  79.2094     0.7989   99.15\n\n\n\n\nLet’s break down the model formula Waist_Circumference ~ 1 + (1 | Nurse)\n\nWaist_Circumference ~ 1: This specifies that Waist_Circumference is the outcome variable and that the fixed effects structure consists of a single intercept, modeled by the term 1, that represents the overall mean waist circumference across all nurses.\n(1 | Nurse): This specifies the random effect for Nurse, representing nurse-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_random), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean waist circumference across all nurses.\n\nRandom Effects: Estimates of the two variance components\n\nNurse - Intercept: Between-nurse variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nNo p-values\n\n\n\nThe lme4 package does not provide p-values for fixed effect estimates. This is a deliberate choice by the package authors, based on concerns about the appropriateness of traditional hypothesis testing methods in the context of mixed effects models. In subsequent labs, we will use of the lmerTest package to calculate these p-values and add them to the summary output.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat proportion of the total variance is attributable to nurse differences (i.e., what is the value of the ICC)?\n\n\n\n\n\nIn mixed-effects models, model diagnostics involve analyzing different types of residuals to evaluate how well the model fits the data and to assess whether key assumptions are satisfied.\nThe default type of residuals used in these models are the conditional residuals, which are calculated based on predicted values that incorporate both fixed effects and estimated random effects. Conditional residuals represent the deviation of the observed data from the model’s predictions, accounting for variability from both sources: fixed effects and random effects. They can be considered estimates of the errors \\(\\epsilon_{ij}\\), which are assumed to be normally distributed with a mean of zero and constant variance.\nTo check these assumptions, we can generate diagnostic plots similar to those used in linear regression models:\n\nResiduals vs. Fitted Plot: This plot helps check for homoscedasticity (constant variance).\nNormal Q-Q Plot: This plot assesses whether the residuals follow a normal distribution.\n\n\n# Extract conditional residuals and predicted values\nresiduals_model_random &lt;- resid(model_random)\nfitted_model_random &lt;- fitted(model_random)\n\n# Residuals vs Fitted\nggplot(data.frame(Fitted = fitted_model_random, Residuals = residuals_model_random), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n# Normal Q-Q\nqqnorm(residuals_model_random, main = \"Normal Q-Q\")\nqqline(residuals_model_random)\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?\n\n\n\n\n\n\n\nA random effects model was fitted to assess the variability in waist circumference measurements across nurses. The overall mean waist circumference was estimated at 79.21 cm. The variance due to differences among nurses was 2.36 cm² and the residual variance was 9.73 cm², resulting in an Intraclass Correlation Coefficient (ICC) of 0.195."
  },
  {
    "objectID": "BLR_lab_RE_oneway.html#exploratory-data-analysis",
    "href": "BLR_lab_RE_oneway.html#exploratory-data-analysis",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "Before modeling, it’s important to visualize and summarize the data to identify any trends, patterns, or anomalies that may impact the analysis. In this case, we aim to explore the variability in waist circumference measurements across nurses and assess the consistency of these measurements.\nWe’ll use two main approaches:\n\nVisualizing the data: A boxplot will be created to compare waist circumference measurements across nurses, highlighting differences in measurement tendencies or variability.\nSummarizing the data: Summary statistics (mean and standard deviation) will be computed for each nurse, providing a numerical overview of central tendency and spread for the measurements.\n\n\n# Create a boxplot\nlibrary(ggplot2)\nggplot(data_waist_circumference, aes(x = Nurse, y = Waist_Circumference, fill = Nurse)) +\n  geom_boxplot() +\n  labs(title = \"Waist Circumference Measurements by Nurse\",\n       x = \"Nurse\", y = \"Waist Circumference (cm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n# Calculate summary statistics\nlibrary(dplyr)\nsummary_stats_random &lt;- data_waist_circumference %&gt;%\n  group_by(Nurse) %&gt;%\n  summarise(\n    Mean_Waist = mean(Waist_Circumference),\n    SD_Waist = sd(Waist_Circumference)\n  )\n\nsummary_stats_random\n\n# A tibble: 4 × 3\n  Nurse   Mean_Waist SD_Waist\n  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Nurse A       80.4     2.69\n2 Nurse B       76.9     3.01\n3 Nurse C       79.9     3.15\n4 Nurse D       79.7     3.56\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the boxplot and summary statistics, do you observe any systematic differences in waist circumference measurements across the nurses? If so, describe the differences and what they might suggest about the measurements."
  },
  {
    "objectID": "BLR_lab_RE_oneway.html#random-effects-model-for-the-one-way-layout",
    "href": "BLR_lab_RE_oneway.html#random-effects-model-for-the-one-way-layout",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "A random effects model represents variations assumed to arise from a larger population. Unlike fixed effects, which estimate specific differences between levels of a factor, random effects account for variability among factor levels by treating them as random samples from a broader population.\nIn the waist circumference example, the four nurses can be considered a random sample from a larger population of nurses. By modeling “Nurse” as a random effect, we aim to generalize the findings about measurement variability to the broader population of nurses, rather than focusing solely on the four in the study.\n\n\nThe random effects model can be specified as:\n\\[\nY_{ij} = \\mu + b_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The waist circumference measurement for the \\(j\\)-th observation by the \\(i\\)-th nurse.\n\\(\\mu\\): The overall mean waist circumference.\n\\(b_i\\): The random effect of the \\(i\\)-th nurse, assumed to be normally distributed with mean zero and variance \\(\\sigma^2_{b}\\).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and variance \\(\\sigma^2\\).\n\nThe use of random effects allows us to decompose the total variance in the outcome variable into distinct components, each associated with a different source of variation. In this example, the total variance in waist circumference measurements is split into two variance components:\n\nBetween-nurse variability (\\(\\sigma^2_{b}\\)): This component, represented by the variance of the random effect \\(b_{i}\\), captures the variability in waist circumference measurements attributable to differences among nurses. It reflects how much of the overall variability is due to systematic differences in measurement techniques or practices between nurses.\nResidual variance (\\(\\sigma^2\\)): This component, represented by the variance of the error term \\(\\epsilon_{ij}\\), captures the variability in waist circumference measurements that remains unexplained by nurse-related differences. It includes measurement error, patient-specific factors, and other unmeasured sources of variation.\n\n\n\n\n\n\n\nNotation convention\n\n\n\nIn mixed-effects models, fixed effects are typically represented by Greek letters, while random effects are represented by Roman letters. This helps differentiate between the two types of effects in model specification.\n\n\n\n\nThe Intraclass Correlation Coefficient (ICC) is a statistical measure that quantifies the proportion of the total variance in the outcome variable that can be attributed to differences between groups. In this context, the ICC measures the extent to which waist circumference measurements are more similar when taken by the same nurse (within-group), compared to the overall variability across all nurses (between-group). In other words, it tells us how strongly measurements are correlated within the same group.\nMathematically, the ICC is calculated as:\n\\[\nICC = \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2}\n\\]\nInterpretation of ICC:\n\nICC \\(\\approx\\) 0: Indicates that nearly all the variability in waist circumference measurements is due to residual factors (such as patient differences or measurement error). This suggests that nurse-level differences contribute minimally to the total variability, implying a high degree of consistency across nurses in their measurement practices.\nICC \\(\\approx\\) 1: Indicates that nearly all the variability is attributable to differences between nurses. This suggests substantial between-nurse variability, meaning different nurses consistently record different waist circumference measurements.\n\n\n\n\n\nWe will fit the random effects model using the lmer() function from the lme4 package.\n\n# Fitting the random effects model\nlibrary(lme4)\nmodel_random &lt;- lmer(Waist_Circumference ~ 1 + (1 | Nurse), data = data_waist_circumference)\nsummary(model_random)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Waist_Circumference ~ 1 + (1 | Nurse)\n   Data: data_waist_circumference\n\nREML criterion at convergence: 1030.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.83380 -0.59987  0.00698  0.66169  2.96673 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Nurse    (Intercept) 2.358    1.536   \n Residual             9.730    3.119   \nNumber of obs: 200, groups:  Nurse, 4\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  79.2094     0.7989   99.15\n\n\n\n\nLet’s break down the model formula Waist_Circumference ~ 1 + (1 | Nurse)\n\nWaist_Circumference ~ 1: This specifies that Waist_Circumference is the outcome variable and that the fixed effects structure consists of a single intercept, modeled by the term 1, that represents the overall mean waist circumference across all nurses.\n(1 | Nurse): This specifies the random effect for Nurse, representing nurse-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_random), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean waist circumference across all nurses.\n\nRandom Effects: Estimates of the two variance components\n\nNurse - Intercept: Between-nurse variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nNo p-values\n\n\n\nThe lme4 package does not provide p-values for fixed effect estimates. This is a deliberate choice by the package authors, based on concerns about the appropriateness of traditional hypothesis testing methods in the context of mixed effects models. In subsequent labs, we will use of the lmerTest package to calculate these p-values and add them to the summary output.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat proportion of the total variance is attributable to nurse differences (i.e., what is the value of the ICC)?\n\n\n\n\n\nIn mixed-effects models, model diagnostics involve analyzing different types of residuals to evaluate how well the model fits the data and to assess whether key assumptions are satisfied.\nThe default type of residuals used in these models are the conditional residuals, which are calculated based on predicted values that incorporate both fixed effects and estimated random effects. Conditional residuals represent the deviation of the observed data from the model’s predictions, accounting for variability from both sources: fixed effects and random effects. They can be considered estimates of the errors \\(\\epsilon_{ij}\\), which are assumed to be normally distributed with a mean of zero and constant variance.\nTo check these assumptions, we can generate diagnostic plots similar to those used in linear regression models:\n\nResiduals vs. Fitted Plot: This plot helps check for homoscedasticity (constant variance).\nNormal Q-Q Plot: This plot assesses whether the residuals follow a normal distribution.\n\n\n# Extract conditional residuals and predicted values\nresiduals_model_random &lt;- resid(model_random)\nfitted_model_random &lt;- fitted(model_random)\n\n# Residuals vs Fitted\nggplot(data.frame(Fitted = fitted_model_random, Residuals = residuals_model_random), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n# Normal Q-Q\nqqnorm(residuals_model_random, main = \"Normal Q-Q\")\nqqline(residuals_model_random)\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "BLR_lab_RE_oneway.html#reporting",
    "href": "BLR_lab_RE_oneway.html#reporting",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "A random effects model was fitted to assess the variability in waist circumference measurements across nurses. The overall mean waist circumference was estimated at 79.21 cm. The variance due to differences among nurses was 2.36 cm² and the residual variance was 9.73 cm², resulting in an Intraclass Correlation Coefficient (ICC) of 0.195."
  }
]